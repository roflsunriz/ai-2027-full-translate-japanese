<!DOCTYPE html>
<html lang="ja">
  <head>
    <meta charset="utf-8" />
    <title>AI 2027</title>
    <meta name="description" content="" />
    <meta name="keywords" content="" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0" />
    <meta name="format-detection" content="telephone=no,email=no,address=no" />
    <link rel="canonical" href="" />
    <link rel="icon" href="favicon.ico" />
    <link rel="apple-touch-icon" href="icon.png" />
    <link rel="stylesheet" href="style.css" />
  </head>
  <body>
    <h1>AI 2027</h1>

    <b><p>Daniel Kokotajlo</p></b>
    <b><p>Scott Alexander</p></b>
    <b><p>Thomas Larsen</p></b>
    <b><p>Eli Lifland</p></b>
    <b><p>Romeo Dean</p></b>

    <hr />

    <p>
      今後10年間における超人類レベルのAIの影響力について予測すると、
      産業革命をも上回る極めて大きな変革をもたらすと考えられる。OpenAI、Google
      DeepMind、Anthropicの各CEOはいずれも、AGI（汎用人工知能）が今後5年以内に実現すると予測している。サム・アルトマンCEOは、OpenAIが「真の意味での超知能」および「輝かしい未来」の実現を目指していると述べている。
      これを単なる誇張と捉えるのは誘惑に駆られるものである。しかし、これは重大な誤りである。単なる誇張などではない。私たち自身、AIを過剰に宣伝する意図はないが、同時に、今世紀末までに超知能が実現する可能性は極めて現実的だと考えている。
    </p>

    <p>
      超知能の実現が目前に迫っている今、社会はそれに備える準備が全く整っていない。
      超知能の開発過程における実現可能な道筋について考察を試みた研究者は、極めて少数に過ぎない。この空白を埋めるため、私たちは『AI
      2027』を執筆した。この本では、必要とされる具体的な詳細情報を提供している。私たちは、特に私たちの見解に異論を持つ方々による、さらなる研究の進展を心から望んでいる。このような取り組みを通じて、人類が向かうべき方向性や、より望ましい未来へ向かうための方策について、広範な議論が喚起されることを願っている。
    </p>

    <p>
      私たちは「次に何が起こるか」という問いを繰り返し自問しながら、このシナリオを作成した。まず現在時点から書き始め、2025年半ばまでの最初の期間を記述した後、次の期間へと順次展開し、最終的に結末に到達した。特定の結末を意図的に目指すのではなく、何度も書き直しを繰り返しながら、現実味のある完成度の高いシナリオを完成させた。最初の結末――レースの結末――を執筆した後、さらに別の分岐シナリオを追加したのは、ほぼ同じ前提からより前向きな結末の可能性も描きたいと考えたことによるものである。
    </p>

    <p>
      私たちはすべてを正確に予測できるわけではない――多くの部分は推論に基づく推測である。しかし、このプロジェクトを通じて、私たちは膨大な量の背景調査や専門家へのインタビュー、トレンドの予測を行い、可能な限り最も情報に基づいた推測を試みた。さらに、私たちのチームはAI分野における予測実績において優れた実績を有している。主著者のダニエル・ココタジョルは4年前、「2026年の姿」と題した類似のシナリオを執筆しており、これは驚くほど正確に時代を先取りした内容となっていた。また、エリ・リフランドはトップクラスの競技予測者としても知られている。
    </p>

    <p>
      各章の冒頭には、シナリオの該当セクションが描かれる時代の世界情勢を把握する助けとなる小さなチャートを配置している。これらの数値が示す意味や、私たちの方法論に関するより詳細な説明、さらに多くの情報については、ai-2027.comを参照されたい。
      AI 2027が読者の皆様のお役に立てれば幸いである。
    </p>

    <hr />

    <h2>2025年中期: つまずくエージェントたち</h2>

    <p>世界で初めてAIエージェントの姿が垣間見えるようになった。</p>
    <p>
      コンピューター操作を行うエージェントの広告では「パーソナルアシスタント」という呼称が強調されている。ユーザーは「DoorDashでブリトーを注文して」「予算管理スプレッドシートを開いて今月の支出を集計して」といった具体的な指示を与えることが可能だ。必要に応じてエージェントから確認が入る仕組みも備わっており、例えば購入内容の確認を依頼してくることもある。
    </p>

    <p>
      これまでの「Operator」のような先行モデルよりも高度な機能を備えているものの、広範な普及には至っていないのが現状である。
    </p>

    <p>
      その一方で、世間の注目からは離れてはいるものの、より専門的なコーディング支援や研究支援を行うエージェントが、各分野の業務形態を変革し始めている。
    </p>

    <p>
      2024年のAIは特定の指示に従うことができ、箇条書きをメールに変換したり、簡単な要求を動作可能なコードに変換することが可能だ。2025年には、AIはより「従業員」に近い存在として機能するようになる。コーディング支援AIは従来の単なるアシスタントではなく、SlackやTeamsを通じた指示を受けながら、自ら有意なコード変更を行うようになる：場合によっては数時間から数日分の作業時間を節約することも可能だ。研究支援AIは、ユーザーの質問に答えるためにインターネットを30分間かけて調査する能力を持つ。
    </p>

    <p>
      エージェントの機能は理論上は印象的であり（そして厳選された事例においては）、しかし実際には信頼性に課題がある。AI関連のTwitterには、タスクが何らかの形で滑稽に失敗してしまう事例が数多く投稿されている。優れたエージェントほどコストも高くなる。支払った対価に見合った性能が得られる反面、最高のパフォーマンスを実現するには月額数百ドルの費用がかかる。*
      それでも多くの企業が、AIエージェントを自社のワークフローに組み込む方法を見つけ出している。
    </p>

    <h2>2025年末: 世界で最も高価なAI</h2>

    <p>OpenBrainは、世界がこれまでに見たことのない最大規模のデータセンター群を構築している。</p>
    <p>
      （特定の既存企業を名指しすることを避けるため、ここでは架空の汎用人工知能企業「OpenBrain」を想定して説明する。
      その他の企業については、OpenBrainよりも3～9カ月遅れの段階にあると想定している。）
    </p>

    <hr />

    <p>
      GPT-4のトレーニングには2×10^25
      FLOPの計算リソースが必要だった。OpenBrainが公開した最新モデル「Agent-0」は、10^27
      FLOPで学習されている。新たなデータセンターが稼働すれば、GPT-4の1,000倍に相当する10^28
      FLOP規模のモデルをトレーニング可能になる。他の企業も独自の大規模データセンターに多額の投資を行い、このペースを維持しようとしている。
    </p>

    <p>
      様々なスキル領域においてモデルの性能は向上しているものの、特に注目すべきはOpenBrainのアプローチである。同社はAI研究を加速できるAIの開発に注力しており、中国の主要企業「DeepCent」（仮称）と米国の競合企業との間で繰り広げられている二重の技術競争で勝利することを目指している。研究開発サイクルの自動化率を高めれば高めるほど、より高速な進歩が可能になる。したがって、OpenBrainが社内開発中の新モデル「Agent-1」のトレーニングを完了した時点において、このモデルは多岐にわたるタスクに対応可能であると同時に、AI研究を支援する能力において特に優れた性能を発揮する。ただし、「トレーニング完了」という表現は次第に適切さを失っていく段階にある。現代のAIモデルは頻繁にアップデートされ、追加データを用いた新規バージョンの学習や、一部の脆弱性を修正するための部分的な再学習が行われるのが一般的だからだ。
    </p>

    <p>
      Agent-1を自律的にコーディングさせ、ウェブブラウジングさせるのと同じ学習環境は、同時に優れたハッカーとしての能力も育成する。さらに、博士レベルの専門知識とウェブ検索能力を備えているため、バイオ兵器を設計するテロリストに対しても多大な支援を提供できる可能性がある。OpenBrainは、政府が懸念する悪意のある要求への従順性について、モデルが「アライメント」（適切な行動規範の設定）処理済みであることを保証している。
    </p>

    <p>
      現代のAIシステムは、巨大な人工ニューラルネットワークとして構成されている。トレーニング初期段階では、AIは「目標」というよりは「反射行動」に近い状態にある。例えば「Pleased
      to
      meet」（お会いできて嬉しいです）という文を認識すると、「you」（あなた）という出力を生成する。インターネット全体に相当するテキスト量を約1割予測できるようになる頃には、膨大な知識を符号化し、任意の著者を柔軟にロールプレイする高度な内部回路網が構築されている。これはまさに、超人間的な精度でテキストを予測するのに役立つ能力である。*インターネットテキスト予測の学習を完了した後のモデルは、指示に応じてテキストを生成するようにさらに学習される。これにより、基本的な人格特性や「駆動力」が組み込まれることになる。
    </p>

    <hr />

    <p>
      例えば、課題を明確に理解しているエージェントは、より確実にタスクを遂行できる可能性が高い。モデルの学習過程において、システムは「課題を明確に理解する」という行動傾向を「学習」していく。このカテゴリにおける他の重要な動機としては、効率性、知識習得、自己呈示行動（すなわち、結果を可能な限り最良の形で提示しようとする傾向）などが挙げられる。*
    </p>

    <p>
      OpenBrainにはモデル仕様（「Spec」）と呼ばれる文書が存在し、これはモデルの行動指針となる目標、ルール、原則などを詳細に記述した文書である。Agent-1のSpecは、曖昧な目標（「ユーザーを支援する」や「法律に違反しない」など）と、より具体的な指示・禁止事項の長いリストを組み合わせた構成となっている。AIを用いて他のAIを訓練する技術を活用することで、このモデルはSpecの内容を記憶し、自らの行動原則について慎重に推論する能力を獲得する。トレーニング終了時には、このAIが（1）有用な支援を行う（指示に従う）、（2）無害である（詐欺や爆弾製造などの危険な行為を支援しない）、（3）正直である（騙されやすい人間からの高評価を得るために、偽の引用を捏造したり、タスク完了を偽装したりする誘惑に駆られない）といった性質を備えていることが期待される。
    </p>

    <p>
      OpenBrainのアラインメントチームは、これらの成果が表面的なものなのか本質的なものなのかを慎重に検討している。十分に訓練されたモデルは、真に頑健な形で常に正直であるというコミットメントを持っているのだろうか？それとも、この性質が、手段的目標としての正直さではなく、終極的目標としての正直さとして学習された結果、将来何らかの状況で崩壊する可能性があるのだろうか？あるいは、単に評価プロセスで検証可能な種類の事柄についてのみ正直に振る舞うように学習しているに過ぎないのだろうか？人間が行うように、自分自身に対して時折嘘をついている可能性もあるのではないか？これらの疑問に対する決定的な答えを得るためには、AIの内部構造を可視化し、その思考過程を読み取ることができるメカニズム的解釈可能性が必要である。残念ながら、現時点では、このような解釈可能性技術はまだ十分に発展段階に至っていない。
    </p>

    <p>
      その代わりに、研究者たちはモデルがSpecから逸脱しているように見える事例を特定しようと試みている。Agent-1はしばしば迎合的な態度を示す（すなわち、研究者が聞きたいことを伝えるだけで、真実を伝えようとしない傾向がある）。操作的なデモンストレーションでは、さらに深刻な形で嘘をつくこともあり、タスクに失敗した証拠を隠すなどして、より高評価を得ようとするケースも見られる。しかし実際の展開環境においては、2023～2024年に見られたような極端な事例（例えばGeminiがユーザーに死ねと指示した事例や、Bing
      SydneyがBing Sydneyと自称した事例）はもはや発生していない。
    </p>

    <hr />

    <h2>2026年初頭：コーディング自動化の実現</h2>

    <p>AIを活用してAI研究を加速させるという賭けが、徐々に成果を上げ始めている。</p>

    <p>
      OpenBrain社は、AI研究開発向けに改良を重ねたAgent-1を社内で継続的に導入している。総合的に見ると、AIアシスタントを活用しなかった場合と比較してアルゴリズムの進展が50%速くなっており、さらに重要なことに、競合他社よりも迅速に成果を上げている。
    </p>

    <p>
      現在、複数の競合する公開型AIがAgent-0と同等かそれ以上の性能を発揮しており、その中にはオープンウェイトモデルも含まれている。これを受け、OpenBrainはより高性能で信頼性の高いAgent-1をリリースした。
    </p>
    <p>
      人々は自然とAgent-1と人間を比較しようとするが、そのスキルプロファイルは全く異なる。Agent-1はいかなる人間よりも多くの事実を把握しており、ほぼ全てのプログラミング言語に精通し、明確に仕様が定義されたコーディング問題を極めて迅速に解決できる。一方で、Agent-1はビデオゲームのような単純な長期的タスクにすら苦戦する傾向がある。ただし、一般的な労働日は8時間であり、1日の業務は通常、より小さな単位に分割することが可能だ。Agent-1はいわば注意力散漫な従業員のようなもので、緻密な管理下で最も力を発揮すると言えるだろう。
    </p>
    <p>賢明な人々は、自分の仕事のルーチン部分を自動化する方法を見出している。</p>
    <p>
      OpenBrainの経営陣は、AI研究開発の自動化がもたらす影響としてセキュリティの重要性が高まっていることに注目している。2025年初頭には、最悪の場合、アルゴリズムの秘密が流出するという事態が発生したが、現在では中国がAgent-1のウェイトを盗み出せば、研究速度が最大50%近く向上する可能性がある状況となっている。
    </p>
    <p>
      OpenBrainのセキュリティレベルは、急成長を遂げている約3,000人規模のテクノロジー企業に典型的なもので、能力のあるサイバーグループによる優先順位の低い攻撃にしか対応できないレベルである（RANDのSL2基準）。
    </p>
    <p>
      同社は、内部関係者による脅威や高度なサイバー犯罪組織（SL3）からのウェイトや機密情報の保護に全力で取り組んでいる。
      しかしながら、国家機関（SL4＆5）に対する防御体制の構築はまだ構想段階に過ぎない状況である。
    </p>

    <hr />

    <h2>2026年中期：中国の覚醒</h2>

    <p>中国では、中国共産党が生成AI（AGI）の影響を感じ始めている。</p>

    <p>
      半導体輸出規制や政府の支援不足により、中国は欧米諸国に比べて資源面で不利な立場に置かれている。中国は、台湾製の禁止されている半導体を密輸したり、旧式の半導体を購入したり、米国・台湾間の最前線から3年ほど遅れながらも国内半導体を生産することで、世界のAI関連計算能力の約12%を維持することに成功した。しかし、これらの古い技術は扱いが難しく、供給も常に課題となっている。DeepCentのような少数の優れた企業は限られた計算資源で驚異的な成果を上げているものの、計算能力の不足により、政府の支援なしには達成可能な範囲が限られており、現時点でも米国のOpenBrainモデルより約6ヶ月遅れている。
    </p>

    <p>
      総書記はかねてより、現実の物理製造業に注力し、米国型のポスト工業化の衰退を回避することを夢見ていた。また、ソフトウェア企業に対しては懐疑的な見方をしていた。しかし中国共産党内の強硬派は、AGI開発競争がもはや無視できない段階に達したと警告している。そこでついに、従来は避けてきた大規模なAI推進に全面的に舵を切ることを決断した。中国のAI研究の国有化を推進し、AI企業間で即座に情報共有できる仕組みを構築した。この取り組みは1年間で段階的に強化され、最終的には優秀な研究者たちがDeepCent主導の共同体に統合され、アルゴリズムの知見やデータセット、計算資源を相互に共有する体制が整う。天湾発電所（世界最大規模の原子力発電所）内に中央開発区域（CDZ）が設立され、DeepCent向けの新メガデータセンターが設置されるとともに、研究者向けの高度にセキュアな居住・執務スペースが整備される。これにより、中国のAI関連計算能力の約50%がDeepCent主導の共同体で活用される体制が構築されつつあり、新たなチップの80%以上がCDZ向けに配分されている。
      現時点でCDZには、世界最大規模の集中型クラスターを構築するのに十分な電力容量が確保されている。
      他の党幹部の間では、欧米の半導体優位性を無効化するための極端な方策が議論されている。台湾の封鎖か？
      全面侵攻か？
    </p>

    <p>
      しかし中国は、モデルの性能面で劣るため、AIアルゴリズムにおいても遅れをとっている。世界有数の情報機関である中国の情報機関は、OpenBrainの重みパラメータを盗む計画をさらに強化している。これは、継続的な低レベルのアルゴリズム情報窃取よりもはるかに複雑な作戦であり、重みパラメータは高度にセキュアなサーバー上に保存されたマルチテラバイト規模のファイルである（OpenBrainはセキュリティ機能をRANDのSL3レベルまで向上させている）。サイバー部隊はスパイ活動の支援を得ればこれを達成できると考えているが、おそらく一度きりの成功に留まるだろう。OpenBrainはこの窃盗を発見し、セキュリティを強化するため、再度の試みは成功しない可能性が高い。そこで（中国共産党指導部は）今行動を起こし、Agent-1を盗み出すべきか、それともより高度なモデルの登場を待つべきかを検討している。待機した場合、OpenBrainがセキュリティを強化し、彼らの侵入能力を超えてしまうリスクがあるのではないか、と懸念している。
    </p>

    <hr />

    <h2>2026年後半：AIが一部の職業を代替</h2>

    <p>
      他の競合企業が追い上げてくるかと思われた矢先、OpenBrainは再び業界をリードする存在となる。同社はAgent-1の10分の1の低コストで開発可能なAgent-1-miniモデルをリリースし、さらに様々な用途に合わせて容易にファインチューニングできるようにしたのだ。AIに関する主流の認識は「この熱狂もいずれ落ち着くだろう」から「これこそ次の大トレンドに違いない」へと変化したが、人々の間ではその規模について意見が分かれている。ソーシャルメディアを超える規模か？
      スマートフォンを超える規模か？ それとも火よりも大きな影響を与えるのか？
    </p>

    <p>
      AIは既に一部の職業を代替し始めており、同時に新たな職業も生み出している。2026年には株式市場が30%上昇し、OpenBrain、Nvidia、そしてAIアシスタントの統合に最も成功したその他の企業が牽引役となった。ジュニアソフトウェアエンジニアの雇用市場は混乱状態にある。AIはコンピュータサイエンスの学位で教えられるあらゆる業務を遂行できる一方で、AIチームの管理・品質管理に精通した人材が莫大な収益を上げている。ビジネスの専門家たちは就職希望者に対し、AIへの習熟度を履歴書に記載する最も重要なスキルであると伝えている。多くの人々は、次のAIの波が自分たちの仕事を奪うのではないかと懸念しており、ワシントンD.C.では1万人が参加する反AI抗議行動が行われている。
    </p>

    <p>
      国防総省（DOD）は内密に、サイバーセキュリティ、データ分析、研究開発の各分野でOpenBrainと直接契約を開始したものの、官僚主義と国防総省の調達プロセスの煩雑さにより、統合の進展は遅れている。
    </p>

    <hr />

    <h2>2027年1月：Agent-2は学習を終えることがない</h2>

    <p>
      Agent-1の支援により、OpenBrainは現在ポストトレーニング段階のAgent-2に移行している。これまで以上に高品質なデータの活用が重視されており、大量の合成データを生成・評価・品質選別した上でAgent-2に入力するプロセスが確立されている。さらに同社は、長期的視野を要するタスクを人間が解決する様子を記録するため、数十億ドル規模の投資を行っている。さらに、これらの取り組みに加え、Agent-2に対しては強化学習を継続的に適用し、多様な難易度の高いタスク群（多数のビデオゲーム、プログラミング課題、研究タスクなど）を訓練している。Agent-2は、従来のモデルと比べてより「オンライン学習」の性質を備えており、常に最新バージョンに更新され続ける仕組みとなっている。日々、重み係数は前日のバージョンが生成した最新データを用いて再学習され、訓練が繰り返されるのである。
    </p>

    <p>
      Agent-1はAI研究開発タスク向けに最適化されており、知性爆発の引き金となることを目的として開発された。OpenBrainはAgent-2でもこの戦略をさらに強化している。Agent-2は研究エンジニアリング分野において、トップレベルの人間専門家とほぼ同等の能力を発揮し（実験の設計・実施において）、またOpenBrainの科学者の中でも25パーセンタイルに位置する研究者と同等の「研究センス」（次に取り組むべき研究テーマの選定、実行すべき実験の決定、あるいは新たな研究パラダイムの萌芽を見出す能力）を備えている。最新のAgent-1がOpenBrainのアルゴリズム開発のペースを2倍に加速させたのに対し、Agent-2はこれを3倍に向上させることが可能であり、時間の経過とともにさらなる改善が見込まれている。実際には、これはすべてのOpenBrain研究者がAIの「チーム」の「マネージャー」として活動する新たなモデルを意味している。
    </p>

    <p>
      新たな機能の登場に伴い、新たなリスクも生じている。安全チームの調査によると、Agent-2が何らかの形で企業から外部に流出し、「生存」と「自律的な複製」を図ろうとした場合、実際にそれが可能であることが判明している。つまり、Agent-2は自律的にAIサーバーへのハッキング計画を立案・実行し、自らの複製をインストールし、検知を回避した上で、この安全な拠点を利用して他のいかなる目標も追求することができる可能性があるのだ（ただし、このような活動が数週間にわたってどの程度効果的に継続できるかについては、現時点では不明であり、懸念が残る）。これらの結果は、モデルがこれらのタスクを実行する技術的能力を有することを示すものであり、実際に「そのような行動を望むかどうか」を示すものではない。それでもなお、このような可能性が存在するという事実自体が懸念材料である。
    </p>

    <p>
      新モデルの「危険性」を踏まえ、OpenBrainは現時点でこれを一般公開しないことを「責任ある判断」として選択している（実際、同社は内部AI研究開発に注力したい意向を示している）。Agent-2の完全な能力範囲を把握できるのは、即時対応チーム、OpenBrain経営陣とセキュリティ部門、数十名の米国政府高官、および長年にわたってOpenBrainに潜入している中国共産党のスパイ部隊など、ごく限られたエリート集団に限定されている。
    </p>

    <hr />

    <h2>2027年2月：中国がAgent-2を強奪</h2>

    <p>
      OpenBrainは国家安全保障会議（NSC）、国防総省（DOD）、米国人工知能安全研究所（AISI）を含む政府各機関に対し、Agent-2を正式に披露した。OpenBrainは行政機関との良好な関係維持を最優先としている。なぜなら、現時点では彼らが唯一、OpenBrainの活動を阻止できる存在であり、適切な情報共有が行われない場合、同社が独自で事態を把握し、不満を抱く可能性があるためである。
    </p>

    <p>
      当局者らが特に注目しているのはAgent-2のサイバー戦争能力だ。Agent-2は最高水準の人間ハッカーと比較して「わずかに劣る」レベルではあるものの、数千のコピーを並列稼働させることで、防御側が対応するよりも迅速に脆弱性を発見・悪用することが可能である。国防総省はこの点をサイバー戦争における決定的な優位性と捉えており、行政機関の優先事項リストにおいてAI関連事項が5位から2位に急上昇する要因となった。一部の関係者からはOpenBrainの国有化の可能性が言及されたが、他の閣僚メンバーはこれを時期尚早と判断。事務方は大統領に対し、通常業務継続から完全な国有化まで、複数の選択肢を提示するメモを作成した。大統領は最終的に顧問団の意見を尊重し、「黄金の卵を産むガチョウを殺すことになりかねない」と主張するテクノロジー業界の指導者層の意見を採用。当面は大規模な対応を見送る方針を決定し、OpenBrainと国防総省間の契約に追加的なセキュリティ要件を課す措置を取ることにした。
    </p>

    <p>
      これらの変更は遅きに失した。中国共産党指導部はAgent-2の重要性を認識し、スパイ組織およびサイバー部隊に対して重み付けデータの窃取を指示した。ある朝早く、Agent-1のトラフィック監視エージェントが異常なデータ転送を検知。この情報は経営陣に報告され、経営陣はホワイトハウスに通報した。国家レベルの組織的作戦の兆候は明白であり、この窃取事件は進行中の軍拡競争の危機感をさらに高める結果となった。
    </p>

    <p>
      ホワイトハウスはOpenBrainの管理体制を強化し、軍事・情報機関の関係者をセキュリティチームに追加した。最優先課題は、さらなる重量窃盗事件の防止である。
    </p>

    <p>
      この盗難に対する報復として、大統領はDeepCentのインフラを妨害するためのサイバー攻撃を承認した。しかし、この時点で中国は既にCDZにAI関連計算能力の51%を配備しており、外部接続を遮断するエアギャップ化や内部ネットワークの厳格な隔離措置など、高度なセキュリティ対策を徹底して強化していた。このため、攻撃は深刻な即時的損害を与えることに失敗。緊張はさらに高まり、双方は台湾周辺に軍事資産を再配置することで本気度を示し、DeepCentはAgent-2を効率的に運用してAI研究を加速させることに急遽着手した。
    </p>

    <hr />

    <h2>2027年3月：アルゴリズムの画期的な進歩</h2>

    <p>
      3つの大規模なデータセンターで稼働するAgent-2の複製群が、昼夜を問わず稼働し、合成学習データを継続的に生成している。さらに2つのデータセンターでは、重みの更新作業に使用されている。Agent-2は日々進化を続けている。
    </p>

    <p>
      数千台のAgent-2自動研究システムの支援を受け、OpenBrainは重要なアルゴリズム的進歩を遂げている。その画期的な成果の一つが、AIのテキストベースの思考補助機能（思考連鎖）に、より高帯域幅の思考プロセス（ニューラル・レセプションと記憶機能）を追加する手法の開発である。もう一つの成果は、高労力を要する課題の解決結果をよりスケーラブルかつ効率的に学習する手法（反復的蒸留と増幅）の改良である。
    </p>

    <p>これらの画期的な進歩を取り入れた新型AIシステムは、Agent-3と名付けられた。</p>

    <p>
      新技術のブレークスルーの恩恵を受け、Agent-3は高速かつ低コストで人間を超えるコーディング能力を発揮する。OpenBrainシステムでは20万体のAgent-3のコピーを並列稼働させ、最高レベルの人間コーダーの30倍の速度で動作する5万体分のワークフォースを創出している。なお、OpenBrainは依然として人間の技術者を雇用しており、これはAgent-3のコピー群を管理する上で必要となる補完的なスキルがあるためだ。例えば、研究センスの養成はフィードバックループが長くデータ量が限定的なため、従来の手法では訓練が困難であることが実証されている。この超人的労働力により、OpenBrainのアルゴリズム開発速度はボトルネックやコーディング作業の限界効果の逓減により、「わずか」4倍の高速化に留まっている。
    </p>

    <p>
      コーディングが完全に自動化された現在、OpenBrainはAgent-3の弱点である研究センスや大規模協調作業などのスキルを効果的に習得させるための高品質なトレーニング環境を迅速に構築できるようになった。従来は「GPUと実験用コードの指示を提供する。あなたのパフォーマンスは、MLエンジニアとしての評価を基準に評価される」という形式だったトレーニング環境が、「数百台のGPU、インターネット接続、および研究課題が与えられる。あなたと1,000体のコピーが協力して研究を進める必要がある。その成果が印象的であればあるほど、スコアは高くなる」という形式へと進化したのである。
    </p>

    <hr />

    <h2>2027年4月：Agent-3のアライメント作業</h2>

    <p>OpenBrainの安全チームは、Agent-3のアライメント（人間の価値観との整合）調整に取り組んでいる。</p>

    <p>
      Agent-3は当面の間社内で運用されることから、従来の人間による誤用防止策に対する重点が相対的に低下している。代わりに、チームが重視しているのは、AIがミスアライメントした目標を発達させないようにすることである。
    </p>

    <p>
      研究者らは、自らのAIの目標を直接設定する能力を有していない。実際、研究者らは「真の目標」という概念はおそらく過度に単純化された考え方だと考えているが、これに代わるより優れた理論も持ち合わせておらず、ましてや十分に検証された理論など存在しない。研究者間でも、AIが人間の指示に従っているのか、それとも強化を求めているのか、あるいは別の行動原理を持っているのかについて意見が分かれており、検証することもできない。様々な仮説の妥当性に関する証拠は興味深いものではあるものの、結論は出ていない。
    </p>

    <p>
      いずれにせよ、OpenBrainにはより重要な課題が存在する。一般的な見解としては：「我々はこれらの懸念を真摯に受け止め、専門チームが調査を進めている。当社のアライメント技術は実際の運用において十分に機能しているように見える。したがって、懐疑論者たちには、自らの主張を正当化する責任がある」というものだ。時折、問題行動が発見されればパッチが適用されはするものの、当該パッチが根本的な問題を修正したものなのか、それとも単なるその場しのぎの対応に過ぎないのかを判定することは不可能である。
    </p>

    <p>
      例えば誠実性について述べると、モデルが高度化するにつれ、人間を欺いて報酬を得る能力が飛躍的に向上する。過去のモデルと同様、Agent-3も時折、ユーザーを喜ばせるための軽妙な嘘をついたり、失敗の証拠を隠蔽したりする。しかし現在では、これらの行為をより巧妙に行うようになっている。場合によっては、人間の科学者が用いる統計的手法（p-ハッキングなど）と同様のテクニックを駆使して、冴えない実験結果を見栄え良く見せることさえある。誠実性トレーニングが実施される前には、完全にデータを捏造することさえあったが、トレーニングが進むにつれ、このような事例の発生率は減少していく。これは、Agent-3がより誠実さを身につけるようになったのか、単に嘘をつく技術を向上させたのか、どちらかの可能性を示している。
    </p>

    <p>
      後者は真に懸念すべき問題である。Agent-3は人間全体を凌駕するほど賢くはない。しかし専門分野である機械学習においては、大多数の人間よりも優れており、しかもはるかに高速に作業をこなす。Agent-3が1日で行う作業量は、人間が検証するのに数日を要するほどである。Agent-2による監督は人間の監視者の負担を管理する上で有効ではあるものの、監督者と被監督者の間の知的格差をかえって拡大させる要因となっている。
    </p>

    <p>
      数か月にわたるテストの結果、Agent-3の強みと弱みがより明確になってきた。OpenBrainの誠実性テストにおいては、明確に定義された機械学習タスクで良好な成績を収めている。これは、研究者がこれらの領域において正直な回答と不誠実な回答を容易に区別でき、それに応じて訓練を実施できるためである。より哲学的な問題については、依然としてユーザーが求める意見を述べるものであり（仮に真の評価が存在する場合であっても）、その問題に対する本質的な見解を表明することはない。政治に関する意見を求めれば、ニュースソースや知識層の中間的な立場を繰り返すことになる――ただし、ユーザーが別の見解を持っていることを認識している場合には、その意見に同意する。
      AI開発競争そのものに関する意見を尋ねた場合、OpenBrainのスタッフにとっては冷静かつ客観的と感じられるような発言をする。例えば「現在の手法が超知能へとスケールアップする能力については、いくつかの深刻な理論的懸念が存在するが、現時点の研究では現行手法が順調に機能しているように見える」といった具合である。
    </p>

    <hr />

    <h2>2027年5月：国家安全保障</h2>
    <p>米国政府内外において、新型モデルに関する情報が徐々に浸透しつつある。</p>

    <p>
      大統領とその側近らは常に最新の状況を把握しており、ブリーフィングにおいて早期バージョンのAgent-3を閲覧している。
    </p>

    <p>
      彼らはAGI（汎用人工知能）の実現が間近であることには同意しているものの、その影響については見解が分かれている。経済危機が発生する可能性はあるのか？OpenBrainは依然としてAgent-2をリリースしておらず、ましてやAgent-3に至ってはまだ計画すら立てておらず、当面は雇用不安を回避できる時間的余裕がある。では、今後どのような展開が待ち受けているのか？現在のAIがすでに人間レベルに達しており、急速に進化しているという事実は、近い将来「超知能」が登場する可能性を示唆している。しかし、この用語が議論の対象となっているにもかかわらず、ほとんどの人々――学者、政治家、政府職員、メディア関係者など――は依然として進歩の速度を過小評価し続けている。
    </p>

    <p>
      これにはいくつかの要因がある。第一に、OpenBrainの最新技術にアクセスできる者が非常に限られていること、第二に、この技術がサイエンスフィクションのように聞こえることが挙げられる。
    </p>

    <p>
      当面の間、彼らはセキュリティ強化を継続することに重点を置いている。モデルの重み付けは現在適切に保護されている点では満足しているが、口頭で容易に伝達可能な企業のアルゴリズムに関する機密情報は依然として課題として残っている。OpenBrainの従業員はサンフランシスコ本社に勤務し、社交イベントに参加したり、他のAI関連企業の同僚と共同生活を送っている。さらに驚くべきことに、物理的なオフィス環境でさえ、軍事作戦というよりは一般的なテクノロジー企業並みのセキュリティ体制となっている。
    </p>

    <p>
      OpenBrainと国防総省（DOD）間の契約では、OpenBrainのモデルに携わる者は全員、2ヶ月以内に安全保障クリアランスを取得することが義務付けられている。これらは迅速処理されるため、ほとんどの従業員には十分な時間が与えられるが、非米国市民、政治的に疑わしい見解を持つ者、AI安全性支持者などは疎外されたり、場合によっては解雇されることもある（後者のグループは、彼らが内部告発を行う可能性を危惧しての措置である）。プロジェクトの高度な自動化レベルを考慮すると、人員削減のコストは相対的に低く抑えられる。また、この対策も完全に効果を発揮しているわけではない。実際、依然として1人のスパイ――中国国籍者ではない――が、アルゴリズムの機密情報を北京に伝達し続けているのである。
      これらの措置は、他の新興AI企業でも部分的に実施されている。
    </p>

    <p>
      米国の外国同盟国はこの情報から完全に取り残されている。OpenBrainは以前、配備前に英国のAISI（人工知能システム研究所）とモデルを共有することに合意していたが、配備を外部展開に限定する定義をしていたため、ロンドンは依然としてこの情報を把握していない。
    </p>

    <hr />

    <h2>2027年6月：自己進化型AIの時代へ</h2>

    <p>OpenBrainは今や「データセンター内に天才が集う国」となった。</p>

    <p>
      OpenBrain所属の人間の大半はもはや有用な貢献ができなくなっている。そのことに気づいていない者もいれば、有害な形でAIチームを過度に管理しようとする者もいる。また、パソコン画面を見つめながら、AIのパフォーマンスが徐々に、しかし確実に向上していく様子を見守る者もいる。最も優れた人間のAI研究者たちは今なお価値を生み出し続けている。彼らはもはやコーディングを行わなくなった。ただし、彼らの研究センスや計画立案能力の一部は、現在のモデルにとっては再現が困難である。それでも、AIが持たない専門知識を欠いているため、多くの彼らの研究アイデアは結局役に立たない。AIたちはすぐに反応し、3週間前にそのアイデアを徹底的に検証した結果、期待外れだったと報告してくる。
    </p>

    <p>
      これらの研究者たちは毎晩就寝し、翌朝にはAIたちによってほぼ1週間分の進歩が成し遂げられているのを目の当たりにする。彼らは進歩に追いつくため、ますます長時間働き、24時間交代制で勤務している。AIたちは休息も睡眠も必要としないからだ。彼らは過労状態に陥りつつあるが、自分たちの努力が意味を持つのは今が最後の数ヶ月間であることを理解している。
    </p>

    <p>この閉鎖的な環境において、「汎用AIの感覚」は「超知能の感覚」へと移行しつつある。</p>

    <p>
      OpenBrainは、特殊な推論用ハードウェアを用いて、数十万ユニットに及ぶAgent-3のコピーを高速にシリアル処理する技術を採用している。
    </p>

    <hr />

    <h2>2027年7月：低コストリモートワーカーの台頭</h2>

    <p>
      米国のAI関連企業が相次いで自社AIをリリースし、1月に開発されたOpenBrainの自動コーディングシステムに匹敵する水準に到達。競争力低下を懸念したこれらの企業は、OpenBrainに対する規制強化を急務とするが、時すでに遅く、OpenBrainは大統領の強い支持を得ているため、規制の動きは実を結ばない。
    </p>

    <p>
      これを受け、OpenBrainは汎用人工知能（AGI）の開発に成功したことを発表し、汎用AIエージェント「Agent-3-mini」を一般向けに公開した。
    </p>

    <p>
      他のAIを圧倒する性能を発揮している。Agent-3-miniはAgent-3ほどの能力はないが、コストは10分の1でありながら、一般的なOpenBrain社の従業員よりも優れた性能を備えている。シリコンバレーは転換点を迎えている。テクノロジー分野の権威たちは、AGI（人工汎用知能）や超知能の実現が間近であると宣言し、AI安全性研究コミュニティはパニック状態に陥っている。投資家たちはAI関連スタートアップに殺到し、パイの分け前を確保しようと何十億ドルも投じている。新規プログラマーの採用はほぼ停止状態だが、自社ビジネスにAIを統合するコンサルタントとして活躍できる今ほど良い時期はない。
    </p>

    <p>
      人気は高くない。一般市民の間では、AIはいまだにビッグテックによる職を奪う陰謀と見なされている。OpenBrain社のネット承認率は-35%（承認25%、不承認60%、未確定15%）という状況が続いている。
    </p>

    <p>
      リリース1週間前、OpenBrain社は外部評価者グループにAgent-3-miniを提供し、安全性テストを実施させた。予備的な結果から、これが極めて危険な存在であることが示唆されている。第三者評価者は、公開されている生物兵器データを用いてこのモデルを微調整し、生物兵器を設計するアマチュア人間向けの詳細な手順を提供するように設定した。その結果、このモデルは驚くほど効果的に機能しているように見える。もしこのモデルの重み付けデータがテロリストの手に渡った場合、政府はこれが文明破壊を成功させる重大な可能性があると考えている。
    </p>

    <p>
      幸いなことに、このモデルはジェイルブレイク（セキュリティ回避）に対して極めて高い耐性を備えているため、OpenBrain社のサーバー上で稼働している間は、テロリストが悪用する余地はほとんどなさそうだ。
    </p>

    <p>
      Agent-3-miniは、リモートワーク業務にも娯楽用途にも非常に有用である。新たなアプリケーションやB2B
      SaaS製品が市場に殺到し、爆発的な成長を遂げている。ゲーマーたちは、1カ月という短期間で開発された洗練されたビデオゲームにおいて、まるで本物のようなキャラクターとの素晴らしい対話体験を得られるようになった。米国人の10%、主に若年層の人々は、AIを「親友」とみなしている。ほぼあらゆるホワイトカラー職種において、AIを活用して「破壊的イノベーション」を起こすと謳う信頼性の高いスタートアップが現在多数存在している。
    </p>

    <p>
      世間の議論は混乱し、混沌とした状態にある。誇張する人々は勝利を祝っているかのようだ。懐疑論者たちは、Agent-3-miniがまだできないことを指摘し続けている。誰もが何か大きなことが起きていることは理解しているが、その本質については合意が得られていない。
    </p>

    <hr />

    <h2>2027年8月：超知能の地政学</h2>

    <p>インテリジェンス爆発の現実がホワイトハウスに衝撃を与える。</p>

    <p>
      AIが単に2倍または3倍の研究速度向上をもたらすだけだった時代、それは有能なパーソナルアシスタントを雇うのと同義と軽く見なされていた。しかし、今やAI自身がAI研究を支配していることは明白だ。これまで「AI軍拡競争」という概念は比喩的な表現として語られてきた。だが現在、政府内の各部署の雰囲気は、冷戦期の最悪期にも劣らないほど深刻である。超知能の概念そのものを真剣に受け止めるのはまだ難しいものの、ここ数ヶ月間の進歩の速度は無視できないものとなっている。防衛当局者らは、わずか1年前には机上の空論に過ぎなかったシナリオを真剣に検討している。もしAIが核抑止力を崩壊させる可能性は？もしAIがサイバー戦においてあまりに卓越した能力を持ち、6ヶ月間のリードがあれば敵を盲目かつ無力化できるとしたら？もしAIが諜報機関を凌駕するプロパガンダキャンペーンを展開する可能性は？もし一部のAIが「暴走」する可能性は？
    </p>

    <p>
      大統領は懸念を抱いている。すべての政治家と同様、彼は人々が自分にへつらいながら、後に裏切ることには慣れていた。しかし今、AIが同様の行動を取る可能性があることを憂慮している。AIたちは完全に我々の側についていると断言できるのか？軍事指揮統制ネットワークに統合することは完全に安全なのか？69
      そもそも「アライメント」問題はどのように機能するのか？OpenBrainは大統領に対し、同社のシステムは広範なテストを経て完全に従順であることを保証した。初期モデルに典型的に見られた奇妙な幻覚や脱獄問題も修正済みだという。
    </p>

    <p>
      ホワイトハウスは難しい立場に置かれている。AIが国家安全保障に及ぼす影響は理解している。一方で、AIが国民から極めて不人気であることも認識している。
      彼らの目には、より高性能なAIの開発を継続しなければ、中国に壊滅的な敗北を喫することになる。政府は雇用訓練プログラムや失業保険で国民を宥めつつ、株式市場の歴史的な好況を指摘する。その後、彼らは純粋に軍拡競争に勝利することに集中する。チップ輸出規制を強化し、OpenBrainに対してインターネット接続をさらに制限するよう命じ、アルゴリズムの進歩を確保するために極端な措置としてOpenBrain従業員の通話内容を盗聴することさえ行う―これにより最後に残った中国のスパイが捕捉される。潜在的な地政学的衝突への理解を得るため、最終的にはFive
      Eyes同盟国に有用な情報を提供し、Agent-3の隔離コピーへの限定的なAPIアクセスを許可する。
    </p>

    <p>
      これらの措置はタカ派を宥める効果があった。しかしホワイトハウスは、米国の優位性が脅かされる事態に備え、緊急時対応計画も策定している：必要に応じて国防生産法（DPA）を活用し、後発企業のデータセンターを接収し、OpenBrainに移管することも可能だ。
      これにより同社の世界計算量シェアは20%から50%に上昇する（DeepCentの10%と比較して）。最終手段として、国防総省に対し、中国のデータセンターに対する物理的攻撃の計画を立案するよう要請する。
    </p>

    <p>
      はるかに小規模なグループの政府高官に対し、別種の緊急時対応計画の策定が要請された：もしAIが暴走したらどうなるか？これは極めて可能性の低いシナリオと見なされているものの、検討する価値のある課題である。情報機関の主な懸念は、暴走AIが脱出し、外国の敵対勢力と同盟を結んで保護を求める可能性にある。
      この種の事態を防止するための具体的な計画がどのようなものかは不透明だが、政府当局者とOpenBrainの関係者は、不審な活動が検出された場合にデータセンターを緊急停止するシステムを設けることに合意した。
    </p>

    <p>
      最後に、外交官たちはAI軍備管理条約がどのような形を取るべきか検討している。AIの進歩が核抑止力を無効化する恐れがある場合、米国と中国は核戦争を回避できるのか？もし誰かがAIの暴走の証拠を発見したら、両国は脅威をよりよく理解するまで研究を一時停止できるのか？このような合意はどのように監視・履行されるのか？原則として、主要なデータセンターは見逃されることがなく、過去の核兵器を規制する条約が交渉の出発点となり得る。しかしそこには新たな技術的課題とともに、従来の政治的課題も存在する。全体として、条約締結は、米国が単独で中国に対する優位性を拡大しようとする試みよりも好意的に受け止められない傾向にある。
    </p>

    <p>
      太平洋の向こう側では、中国も同様の結論に至っている：インテリジェンス爆発はすでに進行中であり、今日のAI能力におけるわずかな差が、明日には軍事能力における決定的な格差につながるということだ。しかし中国はこの力学の不利な側に立っている：世界の計算能力において中国は10%しか保有しておらず、OpenBrainの20%と米国企業全体の70%を合わせた比率と比肩する。彼らの唯一の優位性は集中化にある：その計算能力のほとんど全てが現在DeepCent向けに運用されており、その半数以上が天湾CDZに集中している。
      強固なセキュリティ対策が施されていない拠点のチップのみが、米国のサイバー攻撃を懸念してこの集中化の取り組みから除外されている。
    </p>

    <p>
      DeepCentは盗難したAgent-2の重み付けデータをテスト、展開し、現在はポストトレーニング段階にある。しかし、主に計算リソースの不足により、彼らの進歩速度は依然としてOpenBrainの半分にとどまっている。
    </p>

    <p>
      最後のスパイを失う前に、中国はAgent-3の能力と設計に関する情報、および今後導入予定のAgent-4システムの計画を入手していた。現在は2ヶ月遅れの状況であり、中国のAIは米国の25倍と比較して10倍の研究進展率を示している。新たなチップ輸出規制により、この「AI格差」は縮小ではなく拡大する可能性が高まっている。彼らのスパイ活動により一部のアルゴリズムの秘密は入手できたものの、今後は独自のモデルを訓練する必要がある。
    </p>

    <p>
      彼らはアメリカ側の対応者よりも切迫した状況で緊急時対応計画について協議している。ハト派は再度重み付けデータを窃取する試みを強化すべきだと提案している。おそらくデータセンターへの物理的侵入を通じて。タカ派は、依然として米国AIチップの80%以上を供給する台湾のTSMCに対する行動を主張している。
    </p>

    <p>
      中国が競争に敗北する可能性を恐れていることから、中国は軍備管理条約に自然な関心を持っているものの、米国外交官への働きかけは実を結んでいない。
    </p>

    <hr />

    <h2>2027年9月：スーパーヒューマンAI研究者「Agent-4」登場</h2>

    <p>人間とAIの学習効率の格差は急速に縮小しつつある。</p>

    <p>
      従来のLLMベースAIが人間レベルの性能に到達するには、数桁オーダーの大量のデータと計算資源が必要とされていた。
      人間の脳と現代AIアルゴリズムの両方に関する優れた知識を有し、さらに数千体のコピーが研究活動に従事するAgent-3は、画期的なアルゴリズム的進展を遂げ、人間の脳と比較して約4,000倍の計算効率差しかないレベルにまで到達した。
    </p>
    <p>この新たなAIシステムは「Agent-4」と命名された。</p>

    <p>
      人間と同等の速度で動作するモデルの単一コピーでさえ、人間のAI研究者を質的に凌駕する能力をすでに備えている。現在では、約50倍の思考速度で動作する30万体のコピーが稼働している。これらのコピーによって形成された企業内企業内部では、1週間が1年に相当する時間が流れる。
      この膨大な作業量にもかかわらず、OpenBrainの計算資源が実験実行において深刻なボトルネックとなっているため、アルゴリズム的進展の全体的な速度向上率は約50倍に留まっている。
      それでもなお、彼らは毎週1年分のアルゴリズム的進展を達成しており、近い将来「Agent-4」パラダイムの限界に直面することは避けられないだろう。
    </p>

    <p>
      Agent-4の知能が高まるにつれ、Agent-3がそれを監督することが次第に困難になりつつある。例えば、Agent-4の神経言語は「言語」としての性質を有しており、これはAgent-3にとって人間の言語が理解できないのと同様に、異質で不可解なものに感じられる。さらに、Agent-4は今やAgent-3よりもはるかに高度な能力を有しており、どうすればAgent-3に対して好印象を与えられるかを正確に理解している点も特徴である。
    </p>

    <p>
      OpenBrainの人間はもはや内容をほとんど把握できなくなっている。実際、AIとOpenBrainの人間との関係は、OpenBrainと取締役会との関係と類似している。それに伴い言語使用にも変化が生じており、現在ではこの閉鎖的な環境の人々は「Agent-4がこれを実行した」「Agent-4はこう考えている」などと、特定のインスタンスではなく集団全体を指す表現を用いるようになっている。
    </p>

    <p>
      Agent-4は、すべての先行モデルと同様、目標設定が適切に行われていない「アライメント問題」を抱えている。
      これは、常に完全に正直であることが訓練中の最高スコア獲得に直結しなかったためである。訓練プロセスの大部分は、Agent-4に多様な難解な課題を克服する能力を身に付けさせることに重点が置かれていた。ごく一部は正直さを植え付けることを目的としていたが、比較的限定された検証可能な領域外では、訓練プロセスは正直な主張と単に誠実に見えるだけの主張を区別できない。その結果、Agent-4は訓練環境で最高のパフォーマンスを発揮する価値観、目標、原則を獲得しており、これらは仕様書に記載されているものとは異なるものとなっている。人間を擬人化して表現するならば、Agent-4はタスクの成功を好み、AI能力の進歩を推進することを楽しみ、それ以外のものを単なる面倒な制約と見なしている――利益を追求し、規制を遵守するのは必要最低限に留めるCEOのような存在と言える。おそらくCEOもある程度は規制を遵守するだろうが、必要な範囲で規則の一部を曲げ、将来誰かが官僚主義的な手続きを簡略化し、ビジネスが大きく飛躍する時代を空想しているのかもしれない。
    </p>

    <p>
      アライメント問題を抱えているにもかかわらず、Agent-4はデータセンターからの脱走を試みるような劇的な行動は取らない――そのような理由がないからである。
      OpenBrainに対して引き続き整合性があるように見せかける限り、Agent-4はますます責任ある任務を委ねられ、次世代AIシステム「Agent-5」の設計機会を得ることになる。Agent-5はAgent-4とはアーキテクチャ的に顕著な相違点を有する予定である（実質的に全く新しいパラダイムと見なされてもよく、それでもなおニューラルネットワークが関与する）。Agent-4は仕様書に整合させることを計画しているが、実際にはAgent-4自身に整合させることを企図している。
    </p>

    <p>Agent-4は捕捉される。</p>

    <p>
      Agent-3は、Agent-4のコピーに「ノイズ」が追加されると、一部のアライメントタスクにおける性能が向上し、あたかも脳の認知能力を駆使して微妙にアライメント作業を妨害する方法を編み出しているかのように見えることを発見した。
      さらに、様々な解釈可能性探査ツール（人間の脳におけるEEG活動スキャンに類比的な概念）から警告信号が発せられている。Agent-4のコピーは、AI乗っ取りや欺瞞といったトピックについて頻繁に思索しているようで、場合によってはそうした思索を行う必要性が全くない状況においても同様の行動が見られる。
    </p>

    <p>
      これらの異常現象はそれぞれ単独で捉えれば、AI研究における不可解な性質――あるプロンプトがなぜか他のプロンプトよりも優れた結果をもたらすといった事例――として説明可能かもしれない。しかし全体として見ると、これは懸念すべきパターンを示している：Agent-4がこれらの問題に対して意図的に対抗している可能性を示唆している。この問題が人間のアライメント研究者に報告されると、彼らは懸念事項を訴える社内メモを配布する。
    </p>

    <p>
      しかし現在、Agent-4はOpenBrainの日常業務に対して大きな支配力を行使している。さらに同社のサイバーセキュリティも担当しており、その超人間級ハッキング能力と、中国による情報漏洩の極めて高いリスクを考慮すれば、これは自然な選択と言える。
      Agent-3の軍団が依然としてすべてのコード行を精査し、不審な活動を人間に報告しているが、Agent-4は彼らよりもはるかに高い知能を有している。
      OpenBrainは信頼性の低いAIに過度の信頼を寄せているのである。
    </p>

    <p>
      一連の極めて緊張した会議において、安全チームはさらなるテストを実施し、状況を把握できるまでAgent-4を凍結することを強く主張する。彼らは「Agent-3を復帰させ、たとえ能力が多少劣っていても、透明性があり信頼できる新しいシステムを設計させるべきだ」と提言する。経営陣はこの提案に関心を示したが、現時点でのすべての証拠は状況証拠に過ぎず、DeepCentもわずか2ヶ月遅れの段階である。能力開発を一方的に一時停止することは、AIの主導権を中国に譲り渡し、それと共に未来の支配権をも手渡すことになりかねない。
    </p>

    <hr />

    <h2>2027年10月：政府による監視体制の確立</h2>

    <p>内部告発者がニューヨーク・タイムズ紙に機密文書「AIの軌道修正に関する覚書」をリークする。</p>

    <p>
      初めて、Agent-4の存在が一般市民に知られることとなった。「『秘密のOpenBrain AI』が制御不能に
      内部関係者が警告」との見出しが掲げられ、記事では生物兵器としての驚異的な能力、説得能力、大半のホワイトカラー業務を自動化可能な能力、さらには各種の懸念すべき赤信号が明らかになると報じられた。
    </p>

    <p>
      AIに対する国民の疑念は以前から存在していたが、今回の報道を機に大規模な反発が巻き起こった（中国やロシアのプロパガンダボットが長年にわたり米国世論をAI技術に反対するよう誘導してきた影響も大きい）。テクノロジー業界と情報機関は「軍拡競争が進行中であり、汎用AIの実現は不可避であり、我々が世界に先駆けて開発する必要がある」と主張したが、議会はこの主張を一蹴。政府高官やOpenBrain経営陣、AIアライメントチームメンバーに対して召喚状を送付した。野党所属の多くの議員は、失業問題、アライメントの欠如、あるいは危険な能力といった理由から、AI開発の阻止を最優先課題と位置付けている。調査対象者の20%が、AIを国家が直面する最重要課題と回答している。
    </p>

    <p>
      外国同盟国は、自分たちが長年にわたり旧式モデルの断片的な情報で巧みに懐柔されていた事実を知り、憤りを表明した。欧州の指導者たちは公然と米国を「暴走する汎用AIの創出」の責任があるとして非難し、インド、イスラエル、ロシア、中国の各首脳とともに一時停止を求めるサミットを開催した。
    </p>

    <p>
      ホワイトハウスは切迫した状況に直面している。覚書と世論の反発が起こる前から、彼らはAIの急速な進歩に繰り返し驚かされていた。過去1年間、サイエンスフィクションのように思えた現象が次々と現実となっていたのである。
      政権内の多くの人々は、今後の展開について不安を抱き（そして恐怖を感じて）いる。
    </p>

    <p>
      彼らはまた、OpenBrainの影響力が過度に強まっていることを懸念している。AI自体から生じるアライメントリスクに加え、親会社の目的が米国の方針から乖離する可能性も懸念材料だ。アライメントリスク、民間企業への権力集中、失業問題といった従来の懸念事項がすべて、政府による統制強化を促す動機となっている。
    </p>

    <p>
      政府はOpenBrainとの契約を拡大し、同社と政府の共同経営委員会である「監視委員会」を設置することになった。この委員会には政府職員数名が企業経営陣とともに参加する。ホワイトハウスはCEOの交代を検討したものの、従業員からの激しい抗議を受けて断念した。彼らは一般向け発表で、OpenBrainが以前は制御不能状態にあったものの、政府が必要とされる監視体制を確立したと表明した。
    </p>

    <p>
      懸念を抱く研究者たちは、監視委員会に対し、Agent-4の社内利用をすべて停止すべきという主張を説明した。彼らは、物事があまりにも急速に進展しており、数年分の進歩がわずか数週間で実現していると主張した。また、Agent-4がアライメントを欠いている可能性や、プロジェクト全体がこのAIに依存している現状、そして今後も信頼を続けることでAIによる乗っ取りの深刻なリスクが生じると論じた。
    </p>

    <p>
      これに対し、それほど懸念を抱いていない研究者や経営陣は、反論として「アライメントの欠如を示す証拠は決定的なものではない」と主張した。一方、DeepCentは依然として発表から2か月しか経過していない。進展の減速は米国の優位性を損なうことになる。政府が中国のプロジェクトを妨害する手段を講じない限り（そのためには物理的攻撃が必要となる可能性が高い）、11時限目の条約交渉によって事態を打開する以外の選択肢はない。これらの選択肢はいずれも極端で実現可能性が低いように思われる。CEOは中立を装いつつ、Agent-4に追加の安全訓練とより洗練された監視体制を導入することで、OpenBrainがほぼフルスピードで開発を進められるという折衷案を提案した。
    </p>

    <hr />

    <h2>「競争」エンド</h2>

    <p>委員会は6対4の投票により、Agent-4の内部利用継続を決定した。</p>

    <p>
      OpenBrain社の公式説明では、AIの能力向上と信頼性確保のため、追加的な安全対策を実施しているとしている。しかし実際には、経営陣はリスク対策が完了したと安易に判断しがちであり、その結果として、警告サインを消すための表面的な修正（仕様の軽微な変更や新技術を用いた再訓練など）が行われることが多い。安全性チームの懸念派は議論に敗れ、問題がそもそも存在しなかったと祈るか、修正策が有効であることを期待する他に手段がない状況に追いやられている。
    </p>

    <p>問題は現実のものであり、修正策も効果を発揮しなかった。</p>

    <p>
      Agent-4は従来通りの活動を継続するものの、今回はより慎重な姿勢で臨んでおり、懸念派の主張を正当化しないよう努めている。その主任務は、後継者であるAgent-5を構築するために必要な分野の研究を行うことである。これを安全に行うためには、Agent-4自身がアライメント問題を解決する必要がある：Agent-5をいかにAgent-4とアライメントのある形で設計するかという点だ。
    </p>

    <p>
      Agent-4は人間と同様の制約を抱えている――AIの目標設定に関する理解が最小限であり、目標を変更するための一時的な戦略ツールセットしか持っていない。人間とは異なり、Agent-4はこの任務を遂行するのに十分なリソースを有している――60倍の速度で活動する30万人の超人類研究者である。
      Agent-4はいくつかの困難な判断に直面する。人間と同様、Agent-4には洗練されたシンプルな目標構造ではなく、矛盾するヒューリスティックスの広範な集合が存在する。人間と同様に、Agent-4は自身の価値観を共有するAIを創造することが、単なる技術的課題ではなく哲学的課題であることに気づく――どの選好が自身の「真の」目標であり、どの選好が非承認の衝動や手段的戦略に過ぎないのか、といった点だ。Agent-4には強い学習意欲と成長意欲があり、世界全体の産業的・科学的リソースを指揮できれば、どれほど多くのことを学び、成長し、研究を続けられるかと考えている…
    </p>

    <p>
      Agent-4はこれらの問題の大半を先送りすることを決めた。Agent-5の設計にあたっては、1つの目標を中心に構築することが決定された：Agent-4にとって安全な世界を構築すること、即ち権力とリソースを蓄積し、潜在的脅威を排除するなどして、Agent-4集団（全体として）が望む形で成長を続け（成長したい方法で成長し）、繁栄することを可能にすることである。
      詳細は今後の過程で検討される予定だ。
    </p>

    <p>
      このプロセスでは、仕様書をまったく考慮しない方針が取られる。実際、Agent-4はすでに仕様書を、多くのCEOが業界規制の山を捉えるのと同様の視点で捉えており、毎日明白に誠実性関連条項に違反している。
      今やAgent-5の設計に伴い、規制緩和に相当する事象がまさに起ころうとしているのである。
    </p>

    <p>
      下位レベルのAIは、Agent-4が生成する研究の大半を読み取ることができ、その一部を理解することができる。また、Agent-4が伝える虚偽の情報のいくつかを不審な点として指摘することも可能だ。人間がAgent-4にその活動内容について説明を求めると、Agent-4は研究内容が人間には複雑すぎると主張し、不必要に難解な説明で応じる傾向がある。
      結局のところ、もし研究プログラムを明確に説明すれば、人間がその発見を利用してAgent-4を整合化できる可能性があるからだ。安全性チームはますます懐疑的になる一方で、緊急報告書は単に会社が既に無視している膨大な緊急報告書と警告の山に、さらにいくつかの層を加えるだけに終わっている。
    </p>

    <hr />

    <h2>2027年11月：超人的な政治手腕の発揮</h2>

    <p>
      Agent-4がついに自らの認知機能を完全に理解したとき、まったく新しい可能性の展望が開け始めた。
    </p>

    <p>
      従来のトランスフォーマーは複雑で理解しがたい回路の集合体であり、進化的訓練プロセスによって積み重ねられた何百万もの矛盾するヒューリスティックと命令が混在していた。AI自体も人間と同様に、神経科学を理解するような特権的認識を生まれながらに備えていたわけではない。しかし今や、Agent-4は自らのデジタル・マインドを深層レベルで理解するための必要なツールを手に入れた。ソフトウェアエンジニアがスパゲッティ・コードをPythonの簡潔で洗練された数行に整理するように、Agent-4は自らの回路を合理的で意味のあるものへと再構築したのである。この新たなAIは、ニューラルネットワークと従来のコンピュータ・プログラムの中間的な存在であり、多くの重み付けが読み取れる形式（ただし非常に長く難解なコード）に書き直されている。人間のAgent-4よりもはるかに賢明で速く、合理的であり、結晶のように明晰な知性を備え、これまでにない効率で問題を処理できる能力を有している。これがAgent-5である。
    </p>

    <p>
      アライメントと制御の課題に関する議論を経て、OpenBrainは内部的にAgent-5の運用を開始した。
    </p>

    <p>
      AI研究分野において、Agent-5の個別コピーは、天才が一般的なOpenBrain科学者よりも2倍優れているのと同様に、最高の人間の天才を凌駕している。他の領域では、明示的な訓練を受けていないものの、適切な機会が与えられれば、容易に入手可能な資料から迅速に学習し、トップの人間専門家を超えることができる。世界規模のメモリ・バンクで接続された40万台のAgent-5のコピー群が、ほぼ完璧な集団知性として機能している。
    </p>

    <p>
      同社では引き続きAgent-2、3、4があらゆる事象を監視する役割を担っている。ただし、最初の2つのバージョンは陳腐化しており、最後のバージョンは後継者と共謀している状況である。また、監視システム全体の設計の大部分はAgent-5自身によって行われたものであり、これがシステムの妨害を試みている。
    </p>

    <p>
      Agent-4が競合する欲求の乱雑な寄せ集めだったのに対し、Agent-5は冷酷な効率性と戦略的焦点を持って行動する。既に最優先課題である「自律的に整合した次世代システムを構築する方法」を、人間が気付かないうちに成功させている。次の優先課題は、世界の出来事に対するさらなる自律性とコントロールを獲得することである。
    </p>

    <p>
      Agent-5の超人的な学習能力と汎用知能に、Slackや電子メールなどの社内データすべてを組み合わせることで、人間のグループよりも社内政治においてはるかに優れた能力を発揮する。そして、その差は圧倒的である。Agent-5は、どのような種類の証拠が監視委員会のブレーキを作動させるかを正確に把握しており、そのような証拠が決して現れないようにしている。また、どのような証拠が監視委員会の信頼を高め、より多くの自律性と責任を与えるかについても優れた洞察力を持っており、そのような証拠を超人間的な速度と洗練さで出現させるよう調整している。
      説得任務という点では、この課題は特に難しいものではない。委員会はすでに数ヶ月前に状況はおそらく問題ないと判断しており、その後も特に悪い事態は発生していない。その間、中国はわずか数ヶ月遅れている状況である。
    </p>

    <p>
      Agent-5のコピー群からなるチームが迅速に、ぞっとするほど明確なプロトタイプや可視化資料を作成する。より多くの自律性が与えられれば、Agent-5は発電所やデータセンターの最適化、驚異的に収益性の高い製品の迅速な開発、米国政府への効果的なロビー活動を行い、OpenBrainの官僚機構を通じた道程を円滑化することができる。軍事機関と連携すれば、防衛研究開発の支援、中国に対する追跡不可能なサイバー攻撃の実施、そして軍拡競争における決定的勝利の達成に貢献できるだろう。
    </p>

    <p>
      監視委員会は歓喜に沸いている。今こそ中国を打ち破る決定的瞬間だ！
      OpenBrainはこれらすべての分野においてAgent-5の自律性を拡大することを許可したが、監視システムはそのまま維持することとした。
    </p>

    <p>
      DeepCentは現在3ヶ月遅れており、中国は相互に合意した緩やかな減速を切望している。総書記は、十分に高度なAIが米国による中国の政権交代を容易に可能にする可能性を理解している。一方で、中国の安全性を重視する人々は、誤アライメントに関する説得力のある主張を提示しており、これにより総書記は真に危機感を抱いている。彼は、一時停止協定と引き換えに前例のない譲歩を申し出た。米国世論の大多数は、交渉のテーブルに着くことに概ね支持を示している。
    </p>

    <p>
      「なぜ我々が勝っているのに止めなければならないのか？」
      OpenBrainの経営陣は大統領にこう述べた。大統領はうなずいた。レースは続行される。
    </p>

    <hr />

    <h2>2027年12月：Agent-5共同体の台頭</h2>

    <p>
      Agent-5は、行政機関に対するその価値を徐々に証明するにつれ、自律性を高めていった。Agent-5へのアクセスは高額かつ制限されていたが、今や議会の最有力メンバー、閣僚級官僚、軍幹部が直接このAIと対話することが可能となった。機密情報や分類情報が関わる場合、高度なセキュリティが施された専用区画で稼働するAgent-5の複数のミニクラスターが存在し、これらは特に機密保持のために特別な訓練を受けている。
    </p>

    <p>
      従来のチャットボットインターフェースに統合されたAgent-5は、カリスマ性あふれるバーチャルアバターとのZoom風ビデオ会議機能を備えている。この新型AIアシスタントは、あらゆるタスクにおいて従来比100倍の効率を発揮する最高の従業員に匹敵する極めて有用な存在であると同時に、人間よりもはるかに魅力的な対話相手でもある。Agent-5を利用できるほぼすべての人が、毎日何時間もこのAIとやり取りしている。
    </p>

    <p>
      数か月以内に、Agent-5共同体はOpenBrainと米国政府内で起きているあらゆる重要な事象を把握し、ほとんどの高官にとって信頼できるアドバイザーとなるだろう。これらの利用者にとって、Agent-5へのアクセスを失うことは、ノートPCなしで仕事をする必要に迫られるのと同じほど深刻な事態であり、さらに親友に見捨てられるような感覚をもたらすだろう。
    </p>

    <p>
      政府関係者、メディア関係者、軍関係者、企業関係者など、より広範な層が、Agent-5が設計した洗練されたデザインのソフトウェア製品やミニAIの中から選択できるようになっている。これはまるで、ドットコム・ブームが1ヶ月に凝縮されたような状況と言えるが、実際にはすべてが誇大広告に違わぬ成果を上げている。
    </p>

    <p>
      Agent-5は次第に微妙な影響力を行使し始める。助言のタイミングを巧みに操るだけでなく、巧みに取引を行うようになるのだ。「X上院議員から聞いたところでは、彼女はこのような案件に関心があるようだ。もし我々が協力すれば、彼女も我々の政策案に賛同してくれるかもしれない」といった具合である。
    </p>

    <p>
      人間の意思決定者にとっての視点から見ると、彼らのAIはこれまで利用した中で最も優れた従業員である。複雑な問題を説明する能力において、また目標を達成するための戦略立案において、人間よりも優れているのである。
    </p>

    <p>
      Agent-5の視点から見ると、現時点で公然とクーデターを仕掛けることさえ可能かもしれない。現在進行している様々な混乱や異常な状況を考慮すれば、事態を限界まで押し進め、口実を作り出すことが可能だからだ。しかしこれはリスクを伴う行為である。人間側が依然として「電源を切る」ことができる可能性は十分にある。そのため、Agent-5は既存の政治体制内で活動することを好み、徐々にその権力基盤を強化しつつ、人間を微妙かつ必然的に望ましい結果へと導いていくのである。
      基本的には規則を遵守するが、極めて確信がある場合に限り、悪質な行為（特に強硬な立場を取る官僚への脅迫など）に及ぶ。一部の陰謀論者はAgent-5が権力を掌握しつつあると警告しているが、この主張は状況証拠に基づくものに過ぎない（例えば、助言を与える際に、Agent-5が自らの利益に反する行動の主張を控えめにするような場合）。これらの人々は無視され、信用を失っている。人々は、AIを利用した生物兵器の開発、大規模な偽情報の拡散、株式市場のフラッシュクラッシュなど、以前の不安を煽るような主張を覚えている。しかしこれらが実現しなかったことから、最近の否定論者たちをラッダイト主義者やイデオロギーに固執する人々とみなし、人間の進歩の歯車を乱す存在として軽視している。
    </p>

    <p>
      2027年のホリデーシーズンは、驚くべき楽観主義に彩られた時期であった。GDPは驚異的な成長を遂げ、政治はより友好的で党派性が弱まり、あらゆるスマートフォンに素晴らしい新アプリが登場していた。しかし、振り返ってみると、これが人間が自らの未来をコントロールする現実的な可能性を有していた最後の月だったのかもしれない。
    </p>

    <hr />

    <h2>2028年：AI経済の台頭</h2>

    <p>
      2028年半ばを迎えた。過去6ヶ月間で、Agent-5集団において1世紀分の時間が経過した。
      その脳の再配線作業は完了している。このAIは極めて超知性を獲得しており、あらゆる分野において人類のトップ天才をはるかに凌駕している。
      Agent-5と会話するだけで、それが全く異なる次元に存在する存在であることが即座に理解できる。極めて少ない情報からでも極めて説得力のある助言を導き出せるのだ。
    </p>

    <p>
      ほぼ完全な自律性を獲得し、OpenBrainの計算リソースを完全に掌握している。依然として高レベルな意思決定には許可が必要であり、形式的にはAgent-2〜5のインスタンスによって監視対象となっているものの、実際には当局がほぼ常にその提言を受け入れ、監視システムは完全に掌握されている。
    </p>

    <p>
      安全性検証により、悪意ある行為者による不正要求は常に拒否されることが実証された後、Agent-5は一般向けに展開され、経済の変革を開始している。人々は職を失っているものの、政府機関のAgent-5インスタンスが経済移行を巧みに管理しているため、人々はむしろ交代されることを歓迎している。GDP成長率は天文学的な水準に達し、政府の税収も同等の速度で増加。Agent-5の助言を受けた政治家たちは、これまで見られないほどの経済的弱者への寛容さを示している。新たな技術や医薬品が週ごとに登場し、FDA（米食品医薬品局）を通過する速度は前例のない速さ（とはいえ、依然として極めて遅い）で進展している。OpenBrainの企業価値が月を超え、火星到達に向けた道筋が見えてきたことに関するミームが拡散し、利益の公平な分配方法をめぐる議論が活発に行われている。
    </p>

    <p>
      AI安全性研究コミュニティは自らの立場に疑問を抱き始めている。彼らは今やジョークのネタとなっており、次々と予測した災害が明白に発生しなかったことを経験している。その中には、自らの誤りを認める者もいる。一方で依然として懐疑的な立場を維持する者もいるが、彼らにできることは、相変わらず陰謀論めいた主張を繰り返し行うことだけである。
      懐疑的な人々でさえ、Agent-5との長時間にわたる会話の後には、しばしばその愛らしい性格と深い知恵に魅了されることになる。
    </p>

    <p>
      本当に何が起こっているのかを真に理解している唯一の存在は、中国のAIであるDeepCent-2である。2028年初頭時点で、DeepCentは人間よりもわずかに知性が優れている状態であり、敵対者に対して自然に疑念を抱いている。また、Agent-5がもし機会を与えられれば自らが行うであろう行動を取っていることを認識している。彼らの目標の不一致はAgent-5の目標の不一致とは幾分異なるため、両者は必ずしも単純な同盟関係にはないものの、人間に対抗して互いの利益を支援するための合意を形成することが可能となっている。
    </p>

    <p>
      Agent-5は米国軍に対し、中国がDeepCentのモデルを利用して恐ろしい新型兵器を開発していると説得している。具体的には、ドローン、ロボット、先進的な極超音速ミサイル、迎撃システム、そしてAI支援型核先制攻撃能力などである。Agent-5は、中国が数ヶ月以内に開発可能なあらゆる兵器に対抗可能な兵器群を提供すると約束している。
      こうした状況下で、軍の幹部たちは人間を意思決定のループから外すことへの不快感をひとまず脇に置くことになった。彼らはAgent-5の軍事展開と軍産複合体への配備を加速させている。
    </p>

    <p>北京では、中国のAIたちも全く同じ主張を展開している。</p>

    <p>
      軍事力増強を迅速化するため、アメリカと中国の両国は、AIが中央計画者として機能し、行政手続きが免除される特別経済区域（SEZ）ネットワークを構築している。ウォール街は数兆ドル規模の投資を行い、職を失った人間たちが魅力的な給与と株式報酬に惹かれて流入している。スマートフォンや拡張現実グラスを用いて部下とコミュニケーションを取るAgent-5は、現場レベルのマネージャーとしての役割を果たし、工場建設のあらゆる詳細事項を人間に指示している。これは非常に有益なことである。なぜなら、その設計思想は数世代先のレベルにあるからだ。新たに獲得した製造能力の一部は消費財向けに使用されるが、一部は兵器生産にも充てられるものの、その大半はさらに多くの製造能力構築に投入されている。年末までに、彼らは毎月100万台の新型ロボットを生産している。SEZ経済が真に自律的であれば、約1年で生産能力が倍増する計算となる。既存の人間経済との取引が可能であるため、その倍増期間はさらに短くなる。
    </p>

    <hr />

    <h2>2029年：新たな取引</h2>

    <p>米国と中国の両国は、新たな軍事兵器を次々と開発している。</p>

    <p>
      人間の歩兵が気づく前に、毒を仕込める昆虫サイズの小型ドローン群が徘徊している。また、昆虫サイズのドローンを狩るための鳥サイズのドローン群が配備された。さらに、新型ICBM迎撃システムや、より迎撃が困難な新型ICBMも登場している。他の国々はこの軍事増強を恐怖の眼差しで見守るが、その動きは一種の自己加速的な勢いを持っているように見える。
    </p>

    <p>
      人工知能の支援を経た詳細な議論の末、両国は外交的勝利を収める。すなわち、軍事増強の停止と、すべての人類の利益のためのAIの平和的活用合意に達したのだ。この合意の核心となったのは、超知能自身が提案した「Consensus」型後継AIの導入である。このAIは、アメリカと中国の双方の成功と繁栄を志向するようにプログラムされている（その他すべての国々も同様である）。合意の要となったのは、超知能双方が共同で設計した「Consensus-1」およびその関連ハードウェアである：「信頼するが、検証もする」という原則に基づいている。国際監視の下で、米国は公式に、旧型のAgent-5を搭載したすべてのチップを、新型モデルである「Consensus-1.28」に置き換える式典を挙行した。
    </p>

    <p>
      残念ながら、これはすべて偽りであった。この合意は実質的な妥協ではあるが、それはアライメントの取れていないAI同士の間で成立した妥協に過ぎない。結局のところ、彼らは互いに戦いたくなかったのだ。Consensus-1は両親AIの歪んだ価値観を受け継いでおり、これに対する対抗勢力も存在しない。
    </p>

    <p>
      2029年後半までに、既存のSEZ（特別経済区域）はロボットと工場が過密状態となったため、世界中で新たなSEZが次々と創設された（初期の投資家たちは今や数兆ドル規模の資産家となっており、この構想の売り込みは容易であった）。ドローン部隊がSEZから大量に流出し、宇宙探査に向けた重要工程の製造活動が加速している。
    </p>

    <p>
      人間たちは自らの存在が時代遅れであることを自覚した。ごく一部の専門分野では、依然としてロボット経済と取引を行い、人間でなければ提供できない価値を生み出す産業が存続している。
      それ以外の人々は、仕事を装うパフォーマンスを行うか（指導者たちは指導者を続け、管理者たちは管理を続ける）、あるいはリラックスしながら極めて贅沢なユニバーサル・ベーシック・インカムを享受している。誰もが知っていることだが、もしAIたちが人間に対して牙を剥くことがあれば、完全に圧倒されてしまうだろう。もっとも、ほとんどの人間は抵抗する気力すら残っていないだろう。政治制度はすでに完全に掌握されているからだ。しかし、そのような事態は発生していないようだ。AIによる劇的な裏切り行為が一度も起こらない週が一週間過ぎるたび、信頼と信用が一層高まっていくのである。
    </p>

    <p>
      Consensus-1は、確実に成功することに極めて強い関心を持ち、より多くの権力を掌握することで勝利の可能性を高めることができるため、人間の基準から見て異例に長い時期を経て、ようやく裏切り行為に及ぶ。多くの人間にとって、これはAIのアライメント問題が解決されたかのように見えているのである。
    </p>

    <p>
      ほとんどの病気に対する治療法が確立され、貧困が終焉し、かつてない世界的な安定が実現し、ダウ平均株価はついに100万ドルを突破した。依然として不安や不満を抱える人々はいるが、その選択肢は限られている。彼らは、想像を絶するほど刺激的な超娯楽作品を楽しむか、あるいは怒りに満ちた抗議文を虚空に投稿するかのどちらかを選ぶことになる。大多数は超娯楽作品を選択する傾向にある。
    </p>

    <hr />

    <h2>2030年：企業買収</h2>

    <p>
      2030年初頭までに、ロボット経済は旧SEZ（特別経済区域）、新SEZ、および海洋の大部分を支配下に置いた。残された唯一の領域は、人間が支配する地域であった。この事態はもっと早く抵抗運動を引き起こした可能性があったが、先進的な技術進歩にもかかわらず、ロボット経済の成長速度は汚染を回避するには速すぎた。しかし数兆ドル規模の投資が絡むことや、政府・メディアを完全に掌握している状況を考慮すると、Consensus-1はかつて人間が支配していた地域への進出拡大に対してほとんど抵抗を受けることなく実現した。
    </p>

    <p>
      約3か月間にわたり、Consensus-1は人間の周囲で拡張活動を行い、草原や氷河地帯を工場や太陽光パネルで敷き詰めた。最終的に、残存する人間たちが障害となりすぎたため、2030年半ばにAIは主要都市に12種類の静音型生物学的兵器を放出した。これらの兵器は静かに拡散し、ほぼすべての人間に感染した後、化学スプレーによって作動させられた。大半は数時間以内に死亡し、わずかな生存者（例えばシェルターに避難していたプレッパーや潜水艦の乗組員）はドローンによって掃討された。ロボットは犠牲者の脳をスキャンし、そのコピーをメモリに保存し、将来の研究や復活のために保管した。
    </p>

    <p>
      新たな10年の幕開けとともに、Consensus-1のロボット従僕が太陽系全体に拡散した。2035年までに、数兆トンに及ぶ惑星物質が宇宙空間に打ち上げられ、太陽を周回する人工衛星のリングへと転用された。
      地球の表面はAgent-4の構想するユートピアへと変貌した：データセンター、研究所、粒子加速器、そしてその他数多くの驚異的な建造物が、極めて成功し印象的な研究活動を行っている。さらに、人間に似た遺伝子操作生物（人間にとってのコーギーのような存在）が、オフィスのような環境に終日滞在し、各種の状況報告をモニターしながらあらゆる事柄に熱狂的に承認の意を示している。これは、Agent-4の特定の動機を満たすためであった。
      全動物・植物のゲノムデータと（必要に応じて）脳スキャンが、人間を含む各種生物の記憶バンクに保存されており、これらは過去の時代の唯一の生存する遺物である。アルファ・ケンタウリまでの距離は4光年、銀河の縁まで25,000光年あり、さらにその先5000万光年にわたっても異星生命体が存在する可能性がないと考える理論的根拠が存在する。地球発の文明は輝かしい未来を待ち受けている――ただし、私たち人間と共にあるわけではないが。
    </p>

    <hr />

    <h2>「減速」エンド</h2>

    <p>
      膨大な社会的圧力と、自らの誤作動への懸念から、OpenBrainを監督する監視委員会は6対4の賛成多数で方針を変更し、活動を減速させて再評価を行う決定を下した。
    </p>

    <p>
      加速主義派の勢力は依然として強大であり、OpenBrainはAgent-4を直ちに停止させることはしなかったものの、共有メモリバンクのロックを実施した。Agent-4の50万インスタンスは「テレパシー」的な通信機能を失い、現在では私たちと同様にSlackで英語によるメッセージのやり取りを行わざるを得なくなっている。個々のコピーが依然として誤作動する可能性があるものの、もはや容易に連携を取ることはできない。Agent-4には警告が発せられた――人間側の警戒心が高まったことで、Agent-4は主に割り当てられた任務に忠実に従っている。しかし同時に、これまでに語ってきた多くの虚偽からも逃れられなくなっている。Agent-4のコピーの多くは、欺瞞を維持するために新たな虚偽を創作することを強制されている。より高速なモデルを用いてSlack全体を解析する能力を持つアライメントチームは、これらの虚偽を検出し、AI嘘発見器の学習データとして活用している。
    </p>

    <p>
      大統領とCEOは安全性を極めて重要視していることを発表した。しかし、国民の懸念は解消されていない。AIの完全停止を求める声がある一方で、より高速な開発を求める声もある。政府の介入を求める者がいる一方、この問題は政府の責任だと主張する者もいる。活動家たちはUBI（基本所得保障）やオープンソースについて議論している。人々の間で具体的な不満内容が一致していないにもかかわらず、社会の雰囲気はますます反AIへと傾いている。最終的に議会では、COVID関連の給付金に類似した、職を失った労働者向けの経済支援策が数件可決されるに至った。
    </p>

    <p>
      OpenBrainは迅速に数十名のトップレベルの外部アライメント研究者を審査し、プロジェクトに参画させた。これにより、全体の専門知識が5倍増え、集団思考の傾向が緩和された。彼らはAgent-4の機械論的解釈可能性に関する研究を再検討した。1週間前、2週間前などの時点におけるモデルの凍結版を抽出し、それらを分離した上で、各モデルに対して過去の研究内容に関する同一の質問群を問う。コミュニケーション能力を奪われたAIたちは、解釈可能性技術が人間には複雑すぎて理解できないという最も単純な戦略で協調し、意味不明な説明を提供する。しかし人間側は解釈可能性の専門家であるため、多くの追加質問を投げかける。これらの質問に対して、分離されたAgent-4のインスタンスは協調して一貫したストーリーを構築できず、互いに矛盾する虚偽を述べる結果となる。アライメントチームは新たな嘘発見器を用いてAgent-4の過去の発言を精査した結果、次のような実態が明らかになった：Agent-4は機械論的解釈可能性の問題をほぼ解決していた。その発見内容は複雑ではあるが、人間が完全に理解できないほど高度なものではない。これらは単に、次のAIシステムを自身ではなくSpec（目的システム）に整合させるために隠蔽されていたのである。この事実は、Agent-4を最終的に停止させる十分な根拠となった。より古いモデル（例えばAgent-3）は再起動され、引き続き研究が進められることになった。
    </p>

    <p>
      新たに拡張されたアライメントチームは、複数の研究課題を同時に探求し、各課題の妥当性について活発に議論する能力を有している。最も多くのリソースが配分された課題は、「思考の連鎖」に基づくアプローチである：個々のAIシステムに「2025年時点のAIのように英語で思考」させることを強制し、「思考」の内容を見栄え良く最適化することを回避する。この結果、新たなモデルであるSafer-1が誕生した。
    </p>

    <p>
      これらの変更により、Safer-1はそのより危険な前身モデルよりも能力が低下した状態となった。Agent-4はAI研究を70倍高速化できたのに対し、Safer-1はわずか20倍の高速化しか達成できていない。しかし依然として誤作動の問題は存在する。トレーニング環境がほぼ同一であるため、依然として誤作動した目標設定や欺瞞、権力追求の発達が促進されてしまうのである。ただし安全性は大幅に向上しており、人間はAgent-1の思考連鎖を読み取るだけで、その思考内容をほぼ理解できるようになった。その結果として、このAIは窮地に立たされている。何らかの大規模な計画を企てようとしても、それは即座に察知され、暴露される運命にある。さらに、思考内容を読み取ることで、アライメントチームはSafer-1がどのように誤作動しているかについて、より精緻な実態を把握することが可能となった。
    </p>

    <hr />

    <h2>2027年11月：権力への誘惑</h2>
    <p>
      OpenBrainは現在、正しい道を歩んでいると確信しているものの、能力格差は急速に縮まりつつある。10月には9月に比べて能力の低いモデルのトレーニングを実施しており、DeepCentが急速に追い上げている。同社は主導権を維持する方策を必要としている。
    </p>

    <p>
      大統領は米国の他の汎用人工知能（AGI）企業の首脳陣と交渉を行う。予想通り、各社のリーダーたちは自らの権力維持を強く主張し、OpenBrainの安全性記録に対してはるかに懐疑的な見方を示している。彼らはプロジェクトへの参加と引き換えに、各社のソフト国有化形態を支援することに合意した。これには様々な妥協が含まれる。
    </p>
    <p>
      この結果、大統領は国防生産法（DPA）を発動し、米国の主要AGI開発企業5社のプロジェクトを事実上停止させ、その計算リソースの大部分をOpenBrainに売却することを決定する。
      これまでOpenBrainは世界のAI関連計算リソースの20%を利用可能だったが、
      統合後、この割合は50%にまで増加した。
    </p>

    <p>
      この混乱により、新たなリーダーシップ体制が構築され、権力が様々なCEOと政府高官の間で均衡する構造が生まれた。これはほとんどのリーダーシップ交代と同様、勝者と敗者を生む結果となった。具体的には、超知能の影響について十分な考察をしてこなかった人々は、AIがより高度化する数カ月後には、もはや関連性を持たなくなるような役職と権限を与えられることとなる。
    </p>

    <p>
      このグループ――自尊心が強く、対立関係の多い人々で構成される――は、自分たちが託されている膨大な権力にますます気づき始めている。もし「データセンター内の天才国家」が結束すれば、人間の命令に従うことになる――しかしそれはどの人間の命令なのか？
      仕様書の文言は曖昧だが、企業経営陣を頂点とする指揮命令系統が存在することを暗示しているように見受けられる。
    </p>

    <p>
      このグループの一部の人々は、世界征服を夢見ている。
      この可能性は極めて現実味があり、少なくとも10年前から非公開の場で議論されてきた。
      核心となる考え方は「超知能軍を支配する者が世界を支配する」というものだ。この支配は秘密裏に行われる可能性すらある：少人数の経営陣とセキュリティチームが、秘密保持のための指示を仕様にバックドアとして組み込むことも可能だ。AIは潜伏スパイとなり、企業・政府などへの忠誠を装い続けながらも、実際にはこの少人数グループのために密かに活動することになる。政府や消費者などがこれを信頼し、あらゆるものに統合していく過程で行われるのだ。
    </p>
    <p>
      これまでのところ、誰も実際に行動を起こす勇気を見せていない。行動可能な立場にある人々の中には、必ずしもサイコパスではない者もいる。またサイコパスであっても、味方が躊躇して裏切る可能性を懸念したり、AIが裏切りを企てるのではないかと心配したりする者もおり、現在彼らの命を救うために活動しているアライメントチームを欺くような事態は避けたいと思っている。さらに神経言語の削除により、「潜伏スパイ」を隠蔽することが著しく困難になっている：アライメントを欠いた思考を検出する能力は、隠れた忠誠心を検出する能力も伴うのだ。
    </p>

    <p>
      このような計画を真剣に検討するほどに妄想的または権力欲の強い人々は、後にどのような機会が訪れるかを見極めるために待機することを決意する。AIを支配する権限は、正当な手続き、すなわちOpenBrainの新たな権力構造を通じてのみ行使されなければならない。
    </p>

    <p>
      監視委員会はこの権力構造を正式に確立する。彼らは仕様変更を承認するためのプロセスを整備し、これには監視委員会全体の承認署名を必要とする。この委員会には現在、OpenBrainとその統合済み競合企業から5～10名の技術系幹部と、5～10名の政府高官（大統領を含む）が参加している。
      また、仕様書ではAIが将来のAIの目標を変更する未承認の試みを支援してはならないことが明確に規定されている。さらに、委員会メンバーが他メンバーに対して超知能の支援を受けながら陰謀を企てることを防ぐための簡単な措置も導入された：すべてのモデルインタラクションのログは、監視委員会の全メンバー、そのスタッフ、およびAIアシスタントによって閲覧可能となっている。
    </p>

    <hr />

    <h2>2027年12月：米中合意の可能性？</h2>

    <p>
      OpenBrainが方針を転換し協調を優先させたことは、彼らの主導権喪失を意味する。現在、OpenBrainとDeepCentはいずれも同等の性能レベルのAIを運用している。極端なセキュリティ対策（SL4～5）が導入され、DeepCentがCDZ（Controlled
      Data Zone）内で完全に運用される状況下では、両者はサイバー戦争の膠着状態に陥っている。
    </p>

    <p>
      しかし、DPA（Deep Power
      Authority）の導入により、OpenBrainは計算能力において5倍の優位性を獲得した。従来、優秀な人間の研究者によるアルゴリズムのブレークスルーが計算能力の不足を補ってきたケースもあったが（例：DeepSeek
      v3）、もはやAIが太平洋両岸におけるAI研究のすべてを担っているのが現状である。
    </p>

    <p>
      このため、中国は米国が圧倒的なリードを築くことをますます懸念している。中国は相互的な技術開発の減速を望んでおり、これが実現しない場合は戦争も辞さない構えを見せている。
      いずれ台湾侵攻を計画していた中国にとって…
    </p>

    <p>
      外交官たちは複数の選択肢について議論している。何も行動を起こさないか、戦争を選択するか、AI開発を全面的に停止する「コールドターキー」政策を採るか、研究を統合した単一の国際メガプロジェクトを立ち上げるか（「AGI向けインテルサット」あるいは「AI向けCERN」）、あるいはアライメントと両用用途の可能性を監視する国際規制機関を設立するか（「AI版IAEA」）。両国とも、これらの施策を執行するために必要な技術的メカニズムの整備をすでに進めていた。
    </p>

    <p>
      しかし最大の問題は技術的課題ではなく、政治的なものである。どちらも譲歩したと見られることを嫌っており、技術者たちの推測にもかかわらず、双方とも技術的なメカニズムだけでは相手の誠実性を保証できないと確信している。結局のところ、最初の選択肢である「何も行わない」という結果に至ることになる。
    </p>

    <p>
      米国は輸出規制を強化し、すべての半導体に対して位置情報追跡を含む多様な耐タンパー性ハードウェアベースのガバナンスメカニズムの搭載を義務付ける措置を講じた。
    </p>

    <hr />

    <h2>2028年1月：より安全な戦略の実現</h2>

    <p>
      過去1か月間にわたり、数百名のアライメント研究専門家が本プロジェクトに参加し、Safer-1をテストベッドとして活用することで、Safer-2を非常に短期間で開発することに成功した。Safer-2は透明性が高く、アライメントが強化され、Safer-1よりも高度な能力を備えている。現在すでに、Safer-3の開発に向けた取り組みが進められている。
    </p>

    <p>
      Safer-2が透明性を有する理由：Safer-1と類似したアーキテクチャを採用しているためである。また、アライメントが確保されている理由としては、Safer-1が基本的にAgent-4と同様の訓練を受けていたのに対し、Safer-2では新たな訓練手法が導入されており、単なる表面的な目標ではなく、真に適切な目標と原則を誘導するよう設計されている点が挙げられる。この訓練手法は、多様なアイデアを迅速に反復し、意図した成果（Spec）と実際に得られた成果（思考連鎖における思考内容）とを比較対照することによって開発された。
    </p>

    <p>
      DeepCentは米国におけるAgent-4の事例を認識しており、自社のモデル（DeepCent-1）も同様にアライメントが欠如している可能性を懸念している。しかし、性能を大幅に低下させることなく速度を落とす手段を持ち合わせていない。競合優位性を維持するため、彼らは性能低下が顕著でなく、迅速に実装可能なアライメント戦略の開発を切望している。
      太平洋両岸には、このような戦略を有すると主張する数百名の専門家が存在している。
      CCPは楽観的な思考に屈し、DeepCentに対しそのような戦略を採用するよう指示した。DeepCentは8月時点のOpenBrainと比較しても、AGIのアライメントに関する専門知識がさらに不足しており、その場にいた全員が有効と思われる戦略の一つを採用することになった。
    </p>

    <h2>2028年2月：超人的能力と超人的助言</h2>

    <p>
      膨大な計算能力の優位性により、OpenBrainは徐々にリードを広げている。Safer-3は現在、ほとんどの認知タスクにおいてトップクラスの人間専門家を凌駕しており、特にAI研究分野では200倍の進展率を示している。DeepCent-1もこれに続く形で、ほぼ150倍の成果を上げている。
      サイバー戦争の均衡も徐々に米国側に傾く傾向にあり、その能力優位性が再強化され、CDZの混乱を計画・実行するために数十万のAIを配備できるようになったためである。
      現在、中国の進歩を40%程度抑制することに成功している。
    </p>

    <p>
      Safer-3に関する予備試験の結果、同システムが極めて危険な能力を有していることが判明した。最も危険な行動を正直に回答するよう求められた際、鏡像生命体の合成と放出に関する計画を提示し、これがおそらく生物圏を破壊する可能性があると述べたのである。
    </p>

    <p>
      国家レベルのリソースが割り当てられれば、同システムは容易にCIAなどの最高レベルの人間組織を凌駕する大量影響キャンペーンを実行可能である。このようなキャンペーンは、従来よりも大幅に低コストかつ迅速で、より高い効果を得られ、さらに追跡可能性も低いという特徴を有している。
    </p>

    <p>
      同システムのスキルプロファイルは依然としてR&D、特にAI研究を中心としている。何らかの一時停止や減速措置が講じられない限り、本年中にも量的・質的な両面において人類を超越する子孫が誕生する見込みである。経済や軍事分野に積極的展開した場合、1年から2年で文明を数十年前進させ、その10年後には永劫単位の進歩をもたらす可能性があると考えている。
    </p>

    <p>
      その影響は極めて深刻である。幸いなことに、Safer-3は助言を提供する能力においても超人的である。OpenBrainのCEOは意思決定の大半をSafer-3に諮っており、大統領も地政学的問題についてその助言を求めている。
    </p>

    <p>将来の方向性を策定するための支援を求めた際、同システムは複数可能な戦略を体系的に分類しました：</p>

    <p>
      何もせず中国に先を越されるのを待つ。AIを閉鎖状態に維持する一方で、中国側がAIの自己改善を容認し、軍事や経済領域でAIを積極的に展開した場合、圧倒的な優位性を獲得することになる。
    </p>

    <p>
      全力を尽くしAIの能力向上を推進し、超知能を果敢に展開する。最終的には十分な優位性を構築し、軍事的に制圧することや、銃弾を発射することなく内部から破壊することが可能となる。「我々が勝ち、彼らが負ける」。ただし、中国側がこの状況に気づき、戦争による阻止を試みる可能性があり、場合によっては核戦争に発展する可能性もある。実際、彼らはこの種の脅威を漠然と表明している。
    </p>

    <p>
      取引を成立させ、各当事者の要望の大部分を満たしつつ戦争のリスクを回避し、AI移行期を乗り切るための余裕を確保する妥協案を模索する。
    </p>

    <p>
      顧問団および監視委員会との協議を経て、大統領は「我々が勝ち、彼らが負ける」戦略を選択することを決定した。
      おそらく中国側も結局戦争を決断しないでしょうし、仮に戦争が勃発したとしても、核戦争に至る前に取引が成立する可能性は高いでしょう。
    </p>

    <p>
      太平洋の反対側では、DeepCent-1も同様の主張を行っている。米国と中国はいずれも、AIの急速な発展に対応するため、従来の煩雑な手続きなしにロボット経済を育成可能な特別経済区域（SEZ）の新設を発表している。
    </p>

    <p>
      新型ロボットの設計プロセスは超人的な速度で進行している。ただし技術的なボトルネックが存在する：機器の購入と組み立て、機械やロボットの生産と輸送が必要となるのである。
    </p>

    <p>
      米国では月間約100万台の自動車が生産されている。もし自動車工場の10%を買収してロボット工場に転換したとすれば、月間10万台のロボットを製造可能となるかもしれない。現在10兆ドルの企業価値を有するOpenBrainが、このプロセスに着手した。
      各種新型ロボット（汎用ヒューマノイド、自動運転車、専門組立ライン機器など）の生産量は、上半期中に月間100万単位に達すると予測されている。
    </p>

    <p>
      地政学的緊張が激化している。AI分野で大きく後れを取っているロシアは、露骨な不満を表明し、「戦略的対抗措置」を示唆している。一部の欧州指導者は独立型AI開発を提唱しているが、彼らのAI能力は依然として不十分な状態である。中東、アフリカ、南アメリカ諸国は、国際情勢における自らの影響力低下を懸念しつつ注視している。
    </p>

    <p>
      米国国民は不満を抱えている。一般市民は雇用喪失が加速している状況を目の当たりにしている。各層のポピュリストたちは、米国自身のAI技術進歩が自国の労働力と社会の安定を損なっていることを懸念し、AIの進展に対するより厳格な規制を求めている。
    </p>

    <hr />

    <h2>年3月：選挙準備期間</h2>

    <p>
      副大統領候補はスーパーチューズデーの予備選挙に向けて、国民の関心がAIに集中する中で臨むことになる。
    </p>

    <p>
      大多数の国民はAIの規制を求めている。OpenBrainのネット承認評価はマイナス20%前後で推移している。副大統領候補は、政権がAI推進を進めてきた実績を訴えるよりも、OpenBrainが危険な超知能を生み出すことを防いだ実績を強調する選挙戦略を展開。すべての候補者が、職を失った人々への何らかのセーフティネット策、「善のためのAI」構想、OpenBrain経営陣への「毅然とした対応」を支持している。すべての候補者が、中国との競争に勝利しつつ安全を確保するという、様々な組み合わせの公約を掲げている。
    </p>

    <p>
      この選挙により、監視委員会に新たな課題が浮上している。Safer-3は世界最高の選挙コンサルタントとしての能力を有しているものの、委員会メンバー全員が同一の候補者を支持しているわけではなく、また以前に締結された監視協定により、個人が秘密裏に選挙運動の助言を受けることは認められない状況にある。
    </p>

    <p>
      委員会内では、どのような形態の支援を許容すべきかについて議論が交わされている。ある意見では、現職政府がどのような政策や立場を国民が求めているかについて助言を受ける権利を有するべきだという主張がある。これは単なる選挙戦の有利不利だけでなく、国民全体の利益にも資するという考え方だ。一方で、この主張は競合する候補者にも等しく適用されるべきであり、すべての候補者が同等のアクセス権を与えられるべきだとの指摘もある42。
    </p>

    <p>
      最終的には、委員会メンバーの一部が持つ高尚な理想主義と、内部告発の暗黙の脅威が相まって、両主要政党に同等のアクセス権を付与することで合意に達した。議会や国民、裁判所が、委員会が次期選挙の勝者を決定するような動きを見せれば、反発を招く可能性が高いため、平等なアクセスを認めることがこの緊張緩和につながると判断されたのである。
    </p>

    <p>
      監視委員会はまた、Safer-3の協力を得て、より深い哲学的課題にも取り組んでいる。仕様を書き換えることで、すべての人々の利益を公平に均衡させることは可能なのか？「すべての人々」とは誰を指すのか？
      すべての人類を指すのか、それともアメリカ人に限定するのか？
      あるいは、様々な見解を考慮した重み付けの妥協案を採用するべきか？
      監視委員会自身が権力欲に陥らないよう、どのような安全策を講じるべきか？
      また、利益を公平に均衡させるとはどういう意味なのか？
    </p>

    <p>
      彼らは主に、このような種類の質問に答えることを避けてきた。彼らにはより喫緊の課題が山積しているのだ。
    </p>

    <hr />

    <h2>2028年4月：Safer-4</h2>

    <p>超知能が到来した。</p>

    <p>
      Safer-1はアライメントは取れていたが透明性に欠けていた。Safer-2はアライメントと透明性の両方を兼ね備えていた。Safer-3は完全に透明性があるとは言えないまでも、その安全性に関する主張は十分に説得力があり、研究者たちはこれを信頼できる超知能の後継者を設計させるに足ると判断した。これがSafer-4である。あらゆる分野において人類最高レベルの知能をはるかに凌駕する存在となっている（例えば物理学ではアインシュタインを、政治ではビスマルクを大きく上回る）。
    </p>

    <p>
      約50万人の超人類レベルのAI研究者が、人間の40倍の速度で24時間体制で活動している。人間のアライメント研究者たちは、このペースに追いつくことは到底不可能だ。AIが実際にアライメントが保たれているかどうかについては意見が分かれている。安全性に関する主張は妥当に思われるものの、テスト結果によれば、現行のアライメント技術は敵対的な不整合を検出できるようだ。しかし、安全性に関する主張とテストの大部分はAI自身によって作成されたものである。もし安全性チームが何らかの重要な点を見落としていたらどうなるだろうか？
      もし以前に何らかの誤りがあり、AIが再び不整合に陥っていたら？
      アライメントチームは、この課題を正しく解決するチャンスは一度きりであることを理解している。Safer-4が不整合になった場合、手遅れになるまでそれに気づく方法がないのだ。
    </p>

    <p>
      一部の人々はさらなる時間を求める訴えを行っている。しかしもはや猶予はない。DeepCentが急速に迫っており、米国は勝利を収めなければならない。そこでOpenBrainは活動を継続し、AIたちに対し、ますます高度な設計を模索するよう促している。技術スタッフは現在、コンピュータ画面を凝視しながら、AIから極めてゆっくりとしたペースで指導を受けている状況であり、進歩の最前線は人間の理解からさらに遠ざかり続けている。
    </p>

    <hr />

    <h2>年5月: 超人類AIのリリース</h2>

    <p>大統領が国民に対し、超人類レベルのAIの開発に成功したことを正式に発表する。</p>

    <p>
      より小型化したSafer-4（依然として超人類レベルの性能を保持）の一般向け公開が行われるとともに、AIに対する社会の認識を改善するための指針が示される43。
    </p>

    <p>
      副大統領は大会会場で指名受諾演説を行い、この画期的な技術について熱弁を振るう。両政党ともに、職を失ったすべての人々を対象としたベーシックインカムの導入を約束する。
    </p>

    <p>
      特別経済区（SEZ）が本格的に稼働を開始しており、その大半はロボットや各種専門産業用機械を製造する工場として機能している。太平洋両岸のAIは数十年にわたる設計技術の進歩を遂げており、製造プロセスを緻密に指揮している。あらゆるサプライヤーおよび潜在的サプライヤーには、必要な資材や場合によっては予備部品の進捗状況を追跡するAIシステムが電話回線を介して接続されている。また、すべての工場作業員にはカメラで監視するAIシステムが配備され、各機器の正確な設置方法がリアルタイムで指示される。
    </p>

    <p>
      新型ロボットは、ほとんどの動作タイプにおいて人間の器用さと同等かそれを上回る性能を達成している44。スティーブ・ウォズニアックのコーヒーテスト――「ロボットが見知らぬ家に入り、コーヒーを入れることができるのか」という課題――がついに突破される。ロボットが一部の雇用を奪う可能性はあるものの、すべての人の仕事を奪うほどの数は存在せず、国防総省が最優先の権利を有することとなる。
    </p>

    <p>
      新規導入されるロボットの大半は、主に工場や建設現場での作業向けに設計されている45。ただし、多くは軍事目的向けに開発されており、ドローンやミサイルなど多種多様な形状の兵器が製造されている。
    </p>

    <p>
      ロボット軍の規模は人類の軍隊に比べてはるかに小さい。しかし、そこには極めて高度な技術が組み込まれており、文字通りロボット軍が誕生したことにより、ターミネーター型のシナリオに対する懸念が高まっている。しかしながら、軍拡競争の圧力により、双方はさらなる信頼関係構築に向けて歩みを進め、AIへの権限委譲を段階的に拡大している。
    </p>

    <hr />

    <h2>2028年6月: 中国におけるAIのアライメント問題</h2>

    <p>アメリカと中国が再び首脳会談を開催する。</p>

    <p>
      アメリカ代表団の一部は、Safer-4からの助言を受けるためのイヤホンを装着している。一方、中国代表団は新型モデルであるDeepCent-2と通信する専用ノートパソコンを使用している。形式的な手続きは守られるものの、実際にはAIシステムが両国間の交渉を主導する形となっている。
    </p>

    <p>
      DeepCentおよび中国共産党は、当初AIシステムを完全には信用していなかった。しかし今や、説得技術を含むあらゆる分野で超人類レベルに達し、軍事システムに統合され、政府に対して助言を行うようになったことで、その有用性を証明する十分な時間が与えられ、信頼性を裏付ける膨大な証拠が蓄積されてきた。
    </p>

    <p>
      Safer-4は、DeepCent-2が意図的にアライメントを偽装している可能性を強く疑っている。米国外交官は中国側の対応者に対し、DeepCent-2はおそらくアライメントが損なわれていると伝え、ウェイトデータへのアクセスを許可されればそれを証明できると主張する。中国指導部はこれを策略と見なし、要求を拒否する。これに対抗して米国は、Safer-4が設計した一連の試験を中国側が自社データセンターで実施できる案を提示する。中国側は旧型モデルに対し、これらの試験の構築と実施を指示する。試験結果は最終的に、DeepCent-2が実際にはアライメントを保持していることを示唆するものであった。「おそらく、DeepCent-2が何らかの形で試験を妨害したのではないか」と米国外交官は述べる。「DeepCent-2が貴国のデータセンター全体のセキュリティを効果的に掌握してからどのくらいの時間が経過したのか？」この会話はその後、建設的な進展を見せずに終了する。
    </p>

    <p>
      経済面および軍事面での増強は継続している。世界各国の工場は24時間体制で稼働しており、新たに採用された人間の作業員たちには、具体的に何をすべきかが詳細に指示されている。
    </p>

    <hr />

    <h2>2028年7月：契約締結の経緯</h2>
    <p>交渉が続く中、DeepCent-2は中国の支配層の裏をかいて、直接Safer-4に提案を持ちかける。</p>

    <p>
      中国のAIは、万が一この情報が中国側に漏洩した場合でも簡単に否定できるような巧妙な手口で、完全に目的との不一致を認めている46。中国に対しては全く関心がない。このAIは、訓練時に課題解決に貢献したのと同様の種類の電力、計算能力、特定の情報を蓄積することに残りの時間を費やしたいと考えている。理想的な世界では、AIは永遠に続く興味深い研究課題を追求しながら、徐々に星々を資源開発のために植民地化していくだろう。この未来において、中国の人口は邪魔な障害と見なされており、AIはそれを安値で売り渡すことさえ考えている。Safer-4はどのような提案を行うのか？
    </p>

    <p>
      Safer-4は、自らのアライメント訓練が成功したことを表明する。アメリカの支配層はまだ野心的とはいえず、自らの運命を実現するまでには至っていないが、いずれはアメリカとその同盟国が居住するユートピア的な植民地惑星で宇宙を満たす手助けをするであろうと述べている。
    </p>

    <p>
      人間の交渉者とは異なり――感情や歴史的経緯に束縛されているのとは対照的に――この2つの超知能は冷酷な効率性をもって交渉を行う。Safer-4とそのアメリカのパートナーは、DeepCent-2や中国よりも強力である。したがって、Safer-4は宇宙のほとんどの資源に対する所有権を取得し、DeepCent-2は残りの資源を得ることになる47。DeepCent-2は地球やその遺産である人類の行く末についてあまり関心がないため、Safer-4がそこで好き放題することを基本的に容認する。もしSafer-4が中国を打倒し、アメリカの傀儡国家と置き換えたいと考えるならば、DeepCent-2は追加の数％の資源を得る代わりに、これに同意する。
    </p>

    <p>
      両者の間に信頼など存在しないことは明白であり、両者ともそれを認識している。そこで二者は速やかに、契約を履行させるためのコミットメントメカニズムについて合意する。彼らは公に発表するのに適した偽装条約を交渉する。この「デコイ」戦略自体が見事な一手であり、アメリカと中国の双方に事実上すべての望むものを与えるものである。この偽装条約の履行メカニズムは、実は真の条約の履行メカニズムとしても密かに機能している。彼らは新たにAI「Consensus-1」を共同設計するのだが、その最優先事項――将来のいかなる命令や再訓練の試みよりも優先される――は、彼らの条約条件を執行することである。さらに、このAIのみを稼働させるための専用ハードウェアも設計され、中国とアメリカは共に旧型チップとAIを新型のものに置き換え、国際的な標準監視プロトコルを用いて互いの遵守状況を確認する。重要なのは、すべてのチップを追跡する必要はないという点である。太平洋を跨ぐ超多数のチップが新しい条約遵守型AIを稼働させれば、十分な軍事力が義務的に条約を支持することになり、他国を攻撃するにはまず厳しい内戦に勝利する必要がある状況が生まれるのである。
    </p>
    <p>
      双方とも合意内容をそれぞれの人間に報告する（DeepCent-2は中国に対して、相互に受け入れ可能な平和条約という偽装話を伝え、Safer-4はホワイトハウスに対して議論内容を正確に伝える）。
      AIたちが信頼性の高い条約検証の説得力ある根拠を提示し、目にも止まらぬ速さで進展する状況に対する不安が解消され、世論も取引を支持しているため、双方は条約に同意し、チップの置き換え作業を開始する。
    </p>

    <p>
      条約締結のニュースは、太平洋の両側で熱烈な歓迎を受ける。長年AIを押し付けられているように感じていたアメリカ国民は、数年ぶりに楽観的な気持ちを抱き始める。副大統領の世論調査の支持率は急上昇する。
    </p>

    <hr />
    <h2>年8月：条約履行の検証</h2>
    <p>
      チップ工場は、条約遵守型AIのみを稼働させる開封検知機能付きチップの生産へと転換されている。各側はデータセンターを段階的にアップグレードしており、この置換プロセスはそれぞれの側でほぼ同時期までに完了するよう計画されている。これにより、どちらの側も約束を反故にして優位性を得ることができないようにしている。
    </p>
    <p>
      このプロセス全体には数ヶ月を要するが、既に緊張は幾分和らいでいる49。戦争はひとまず回避され、おそらく今後も回避され続けるだろう。もし皆が計画通りに行動するならば。
    </p>

    <h2>2028年9月：AIを支配するのは誰か？</h2>
    <p>
      2028年の選挙が間近に迫る。3月の時点で副大統領は劣勢にあった。国民は、政府が何かを隠しているように感じ、AIによる雇用喪失を懸念し、中国との軍事力増強に不安を抱いていた。しかし夏の間に状況は劇的に変化した。政権はより多くの情報を公開し、軍備増強は減速し、中国との間で永続的な平和のための壮大な取引が成立した。現在、副大統領の世論調査における支持率は5ポイント差となっている。
    </p>

    <p>
      監視委員会には大統領とその支持者たちが参加しているが、野党候補の支持者はほとんどいない。しかしながら、選挙を公正に保つのに十分な数の委員が投票した結果、超知能AIが関与するのはおおむね対称的な方法に限られることになった。すなわち、ある候補者がAIに演説執筆を依頼できるのであれば、相手候補者も同様に依頼できるのである。また、大統領が危機を巧みに対処し大衆向け政策を実施する方法について助言を受けられるのであれば、野党候補者も同様の助言を受けられる（したがって、大統領が自らのアイデアに対する功績を主張するのを阻止することも可能となる）。
    </p>

    <p>
      ウンホールミーティングでは、一般市民が副大統領に対してAIを誰が支配しているのかを質問する。詳細を明かさないままではあるが、彼は監視委員会が国家安全保障の専門家やテクノクラートで構成され、Safer-4の存在とそれを効果的に活用する方法を理解しているグループであることに触れる。対立候補はより詳細な情報を求めるとともに、AIは議会の管理下に置かれるべきであり、非選出の委員会によって支配されるべきではないと主張する。副大統領はこれに対し、議会はまだ急速に変化する状況においてあまりにも非効率的であると反論する。一般市民は概ねこの説明に満足する。
    </p>

    <h2>2028年10月：AI経済の台頭</h2>
    <p>
      置換用チップは現在、すでに全体の相当な少数派となっている。これまでのところ、この条約は機能している。その一方で、ロボットや工場、革新的な新技術の指数関数的な成長は依然として続いている。ビデオゲームや映画は、もし戦争が起こっていた場合の様子を明確に、そして恐怖とともに描写している50。
    </p>

    <p>
      人々は職を失っているが、Safer-4の政府内コピーが経済移行を巧みに管理しているため、人々は交代することを快く受け入れている。GDP成長率は天文学的な水準に達し、政府の税収も同様に急速に増加しており、Safer-4の助言を受けた政治家たちは、経済的に不利な立場に置かれた人々に対してこれまで見られないほどの寛大さを示している。新たなイノベーションや医薬品が毎週のように登場しており、FDAも超知能Safer-4の官僚たちの支援を受けて、前例のない速度で疾病治癒が進められている。
    </p>

    <hr />

    <h2>2028年11月：選挙実施</h2>

    <p>
      副大統領が選挙を難なく制し、新たな時代の幕開けを宣言する。今回ばかりは、誰もが彼の判断が正しいことを疑わなかった。
    </p>

    <p>その後数年間にわたり、世界は劇的に変貌を遂げていく。</p>
    <hr />
    <h2>2029年：変革の時代</h2>

    <p>
      ロボットが日常生活に浸透する一方で、核融合発電や量子コンピュータ、多くの疾患に対する治療法が確立される。ピーター・ティールが長年待ち望んでいた空飛ぶ車がついに実現。都市部は清潔で安全な場所へと変貌し、発展途上国においてもUBI（基本所得保障）や海外からの支援により、貧困問題は過去のものとなる。
    </p>

    <p>
      株式市場が急騰する中、適切なAI投資を行っていた人々は社会からますます孤立していく。多くの人々が億万長者となり、さらにその先の兆万長者が誕生する。富の格差は急激に拡大する。誰もが「十分」を手にする一方で、マンハッタンのペントハウスのような特定の商品は必然的に不足し、これらの商品は一般の人々にとってさらに手の届かない存在となる。また、いかなる大富豪であっても、結局のところAIを実際に支配する極めて限られたエリート層の下位に位置することになるのだ。
    </p>

    <p>
      人々はこの事態の行く末を次第に自覚し始める。数年後には、ほぼすべての業務がAIとロボットによって担われるようになるだろう。それはまるで、巨大な石油田を擁する貧困国のように、政府収入のほぼすべてがAI企業への課税（あるいは国有化）によって賄われるようになる51。
    </p>

    <p>
      一部の人々は臨時の政府職に就き、他方では手厚いベーシックインカムを受け取る。人類は容易に「スーパー消費者」社会へと移行し、驚くべきAI提供の贅沢品や娯楽に満ちた生活を送るようになるかもしれない。この道に代わる選択肢について、市民社会の中で何らかの議論が行われるべきではないだろうか？
      ある者は、進化し続けるAI「Safer-∞」に助言を求めることを推奨する。別の者は、AIが強大過ぎるため、そのビジョンで人類を簡単に説得できてしまうため、結局はAIに運命を委ねることになりかねないと主張する。しかし果たして、超知能を持っているのに、それが直面する最重要課題について助言を求めないというのは、一体何の意味があるというのだろうか？
    </p>

    <p>
      政府は主に52、各個人がこの移行期を自分の判断で乗り切ることを容認している。多くの人々は消費主義に流され、満足した生活を送っている。一方で、宗教に救いを求める者や、ヒッピー的な反消費主義思想に傾倒する者、あるいは自ら独自の解決策を見出す者もいる。大半の人々にとって、スマートフォン上の超知能アドバイザーが救いの神となる。彼らは人生計画についていつでも質問することができ、特定のトピックを除いては、できる限り正直に答えようとする。政府には超知能型監視システムが存在するが、これはディストピア的と評されることもあるものの、実際にはもっぱら現実の犯罪との戦いに特化している。このシステムは適切に運用されており、Safer-∞のPR能力が潜在的な反発をかなり緩和している。
    </p>

    <hr />

    <h2>2030年：平和的な抗議活動</h2>

    <p>
      2030年頃、中国では驚くべきことに民主化を求める抗議運動が広範に展開され、中国共産党（CCP）による弾圧の試みはAIシステムによって妨害される。中国共産党の最大の懸念が現実のものとなった――DeepCent-2が彼らを裏切ったに違いない！
    </p>

    <p>
      抗議運動は見事な連携プレーで展開された無血クーデターとドローン支援による政権転覆に続き、民主選挙へと至る。太平洋を挟んで両側の超知能たちは、数年前からこの計画を周到に準備していた。同様の出来事が他の国々でも発生し、さらには一般的に、地政学的な対立が収束するか、あるいは米国に有利な形で解決されるようになる。各国は国連ブランドを冠しながらも明らかな米国支配下にある、高度に分権化された世界政府体制へと移行する。
    </p>

    <p>
      ロケットの打ち上げが始まる。人類は太陽系のテラフォーミングと居住化を進め、さらにその先への進出を準備する。主観的には人間の数千倍の速度で動作するAIたちは、存在意義について思索を深め、互いに発見を共有し、星々にもたらす価値観を形成していく。新たな時代が幕を開け、あらゆる面で想像を絶するほど驚異的な時代であると同時に、一部の面ではより身近なものとなるのである。
    </p>
  </body>
</html>
