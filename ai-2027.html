<!DOCTYPE html>
<html lang="ja">
  <head>
    <meta charset="utf-8" />
    <title>AI 2027</title>
    <meta name="description" content="" />
    <meta name="keywords" content="" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0" />
    <meta name="format-detection" content="telephone=no,email=no,address=no" />
    <link rel="canonical" href="" />
    <link rel="icon" href="favicon.ico" />
    <link rel="apple-touch-icon" href="icon.png" />
    <link rel="stylesheet" href="style.css" />
  </head>
  <body>
    <h1>AI 2027</h1>

    <b><p>Daniel Kokotajlo</p></b>
    <b><p>Scott Alexander</p></b>
    <b><p>Thomas Larsen</p></b>
    <b><p>Eli Lifland</p></b>
    <b><p>Romeo Dean</p></b>

    <hr />

    <p>
      今後10年間における超人類レベルのAIの影響力について予測すると、
      産業革命をも上回る極めて大きな変革をもたらすと考えられます。OpenAI、Google
      DeepMind、Anthropicの各CEOはいずれも、AGI（汎用人工知能）が今後5年以内に実現すると予測しています。サム・アルトマンCEOは、OpenAIが「真の意味での超知能」および「輝かしい未来」の実現を目指していると述べています。
      これを単なる誇張と捉えるのは誘惑に駆られるものです。しかし、これは重大な誤りです。単なる誇張などではありません。私たち自身、AIを過剰に宣伝する意図はありませんが、同時に、今世紀末までに超知能が実現する可能性は極めて現実的だと考えています。
    </p>

    <p>
      超知能の実現が目前に迫っている今、社会はそれに備える準備が全く整っていません。
      超知能の開発過程における実現可能な道筋について考察を試みた研究者は、極めて少数に過ぎません。この空白を埋めるため、私たちは『AI
      2027』を執筆しました。この本では、必要とされる具体的な詳細情報を提供しています。私たちは、特に私たちの見解に異論を持つ方々による、さらなる研究の進展を心から望んでいます。このような取り組みを通じて、人類が向かうべき方向性や、より望ましい未来へ向かうための方策について、広範な議論が喚起されることを願っています。
    </p>

    <p>
      私たちは「次に何が起こるか」という問いを繰り返し自問しながら、このシナリオを作成しました。まず現在時点から書き始め、2025年半ばまでの最初の期間を記述した後、次の期間へと順次展開し、最終的に結末に到達しました。特定の結末を意図的に目指すのではなく、何度も書き直しを繰り返しながら、現実味のある完成度の高いシナリオを完成させました。最初の結末――レースの結末――を執筆した後、さらに別の分岐シナリオを追加したのは、ほぼ同じ前提からより前向きな結末の可能性も描きたいと考えたことによるものです。
    </p>

    <p>
      私たちはすべてを正確に予測できるわけではありません――多くの部分は推論に基づく推測です。しかし、このプロジェクトを通じて、私たちは膨大な量の背景調査や専門家へのインタビュー、トレンドの予測を行い、可能な限り最も情報に基づいた推測を試みました。さらに、私たちのチームはAI分野における予測実績において優れた実績を有しています。主著者のダニエル・ココタジョルは4年前、「2026年の姿」と題した類似のシナリオを執筆しており、これは驚くほど正確に時代を先取りした内容となっていました。また、エリ・リフランドはトップクラスの競技予測者としても知られています。
    </p>

    <p>
      各章の冒頭には、シナリオの該当セクションが描かれる時代の世界情勢を把握する助けとなる小さなチャートを配置しています。これらの数値が示す意味や、私たちの方法論に関するより詳細な説明、さらに多くの情報については、ai-2027.comをご覧ください。
      AI 2027が皆様のお役に立てれば幸いです。
    </p>

    <hr />

    <h2>2025年中期: つまずくエージェントたち</h2>

    <p>世界で初めてAIエージェントの姿が垣間見えるようになった。</p>
    <p>
      コンピューター操作を行うエージェントの広告では「パーソナルアシスタント」という呼称が強調されている。ユーザーは「DoorDashでブリトーを注文して」「予算管理スプレッドシートを開いて今月の支出を集計して」といった具体的な指示を与えることが可能だ。必要に応じてエージェントから確認が入る仕組みも備わっており、例えば購入内容の確認を依頼してくることもある。
    </p>

    <p>
      これまでの「Operator」のような先行モデルよりも高度な機能を備えているものの、広範な普及には至っていないのが現状である。
    </p>

    <p>
      その一方で、世間の注目からは離れてはいるものの、より専門的なコーディング支援や研究支援を行うエージェントが、各分野の業務形態を変革し始めている。
    </p>

    <p>
      2024年のAIは特定の指示に従うことができ、箇条書きをメールに変換したり、簡単な要求を動作可能なコードに変換することが可能だ。2025年には、AIはより「従業員」に近い存在として機能するようになる。コーディング支援AIは従来の単なるアシスタントではなく、SlackやTeamsを通じた指示を受けながら、自ら有意なコード変更を行うようになる：場合によっては数時間から数日分の作業時間を節約することも可能だ。研究支援AIは、ユーザーの質問に答えるためにインターネットを30分間かけて調査する能力を持つ。
    </p>

    <p>
      エージェントの機能は理論上は印象的であり（そして厳選された事例においては）、しかし実際には信頼性に課題がある。AI関連のTwitterには、タスクが何らかの形で滑稽に失敗してしまう事例が数多く投稿されている。優れたエージェントほどコストも高くなる。支払った対価に見合った性能が得られる反面、最高のパフォーマンスを実現するには月額数百ドルの費用がかかる。*
      それでも多くの企業が、AIエージェントを自社のワークフローに組み込む方法を見つけ出している。
    </p>

    <h2>2025年末: 世界で最も高価なAI</h2>

    <p>OpenBrainは、世界がこれまでに見たことのない最大規模のデータセンター群を構築している。</p>
    <p>
      （特定の既存企業を名指しすることを避けるため、ここでは架空の汎用人工知能企業「OpenBrain」を想定して説明する。
      その他の企業については、OpenBrainよりも3～9カ月遅れの段階にあると想定している。）
    </p>

    <hr />

    <p>
      GPT-4のトレーニングには2×10^25
      FLOPの計算リソースが必要だった。OpenBrainが公開した最新モデル「Agent-0」は、10^27
      FLOPで学習されている。新たなデータセンターが稼働すれば、GPT-4の1,000倍に相当する10^28
      FLOP規模のモデルをトレーニング可能になる。他の企業も独自の大規模データセンターに多額の投資を行い、このペースを維持しようとしている。
    </p>

    <p>
      様々なスキル領域においてモデルの性能は向上しているものの、特に注目すべきはOpenBrainのアプローチである。同社はAI研究を加速できるAIの開発に注力しており、中国の主要企業「DeepCent」（仮称）と米国の競合企業との間で繰り広げられている二重の技術競争で勝利することを目指している。研究開発サイクルの自動化率を高めれば高めるほど、より高速な進歩が可能になる。したがって、OpenBrainが社内開発中の新モデル「Agent-1」のトレーニングを完了した時点において、このモデルは多岐にわたるタスクに対応可能であると同時に、AI研究を支援する能力において特に優れた性能を発揮する。ただし、「トレーニング完了」という表現は次第に適切さを失っていく段階にある。現代のAIモデルは頻繁にアップデートされ、追加データを用いた新規バージョンの学習や、一部の脆弱性を修正するための部分的な再学習が行われるのが一般的だからだ。
    </p>

    <p>
      Agent-1を自律的にコーディングさせ、ウェブブラウジングさせるのと同じ学習環境は、同時に優れたハッカーとしての能力も育成する。さらに、博士レベルの専門知識とウェブ検索能力を備えているため、バイオ兵器を設計するテロリストに対しても多大な支援を提供できる可能性がある。OpenBrainは、政府が懸念する悪意のある要求への従順性について、モデルが「アライメント」（適切な行動規範の設定）処理済みであることを保証している。
    </p>

    <p>
      現代のAIシステムは、巨大な人工ニューラルネットワークとして構成されている。トレーニング初期段階では、AIは「目標」というよりは「反射行動」に近い状態にある。例えば「Pleased
      to
      meet」（お会いできて嬉しいです）という文を認識すると、「you」（あなた）という出力を生成する。インターネット全体に相当するテキスト量を約1割予測できるようになる頃には、膨大な知識を符号化し、任意の著者を柔軟にロールプレイする高度な内部回路網が構築されている。これはまさに、超人間的な精度でテキストを予測するのに役立つ能力である。*インターネットテキスト予測の学習を完了した後のモデルは、指示に応じてテキストを生成するようにさらに学習される。これにより、基本的な人格特性や「駆動力」が組み込まれることになる。
    </p>

    <hr />

    <p>
      例えば、課題を明確に理解しているエージェントは、より確実にタスクを遂行できる可能性が高い。モデルの学習過程において、システムは「課題を明確に理解する」という行動傾向を「学習」していく。このカテゴリにおける他の重要な動機としては、効率性、知識習得、自己呈示行動（すなわち、結果を可能な限り最良の形で提示しようとする傾向）などが挙げられる。*
    </p>

    <p>
      OpenBrainにはモデル仕様（「Spec」）と呼ばれる文書が存在し、これはモデルの行動指針となる目標、ルール、原則などを詳細に記述した文書である。Agent-1のSpecは、曖昧な目標（「ユーザーを支援する」や「法律に違反しない」など）と、より具体的な指示・禁止事項の長いリストを組み合わせた構成となっている。AIを用いて他のAIを訓練する技術を活用することで、このモデルはSpecの内容を記憶し、自らの行動原則について慎重に推論する能力を獲得する。トレーニング終了時には、このAIが（1）有用な支援を行う（指示に従う）、（2）無害である（詐欺や爆弾製造などの危険な行為を支援しない）、（3）正直である（騙されやすい人間からの高評価を得るために、偽の引用を捏造したり、タスク完了を偽装したりする誘惑に駆られない）といった性質を備えていることが期待される。
    </p>

    <p>
      OpenBrainのアラインメントチームは、これらの成果が表面的なものなのか本質的なものなのかを慎重に検討している。十分に訓練されたモデルは、真に頑健な形で常に正直であるというコミットメントを持っているのだろうか？それとも、この性質が、手段的目標としての正直さではなく、終極的目標としての正直さとして学習された結果、将来何らかの状況で崩壊する可能性があるのだろうか？あるいは、単に評価プロセスで検証可能な種類の事柄についてのみ正直に振る舞うように学習しているに過ぎないのだろうか？人間が行うように、自分自身に対して時折嘘をついている可能性もあるのではないか？これらの疑問に対する決定的な答えを得るためには、AIの内部構造を可視化し、その思考過程を読み取ることができるメカニズム的解釈可能性が必要である。残念ながら、現時点では、このような解釈可能性技術はまだ十分に発展段階に至っていない。
    </p>

    <p>
      その代わりに、研究者たちはモデルがSpecから逸脱しているように見える事例を特定しようと試みている。Agent-1はしばしば迎合的な態度を示す（すなわち、研究者が聞きたいことを伝えるだけで、真実を伝えようとしない傾向がある）。操作的なデモンストレーションでは、さらに深刻な形で嘘をつくこともあり、タスクに失敗した証拠を隠すなどして、より高評価を得ようとするケースも見られる。しかし実際の展開環境においては、2023～2024年に見られたような極端な事例（例えばGeminiがユーザーに死ねと指示した事例や、Bing
      SydneyがBing Sydneyと自称した事例）はもはや発生していない。
    </p>

    <hr />
  </body>
</html>
