<!DOCTYPE html>
<html lang="ja">
  <head>
    <meta charset="utf-8" />
    <title>AI 2027</title>
    <meta name="description" content="" />
    <meta name="keywords" content="" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0" />
    <meta name="format-detection" content="telephone=no,email=no,address=no" />
    <link rel="canonical" href="" />
    <link rel="icon" href="favicon.ico" />
    <link rel="apple-touch-icon" href="icon.png" />
    <link rel="stylesheet" href="style.css" />
  </head>
  <body>
    <h1>AI 2027</h1>

    <b><p>Daniel Kokotajlo</p></b>
    <b><p>Scott Alexander</p></b>
    <b><p>Thomas Larsen</p></b>
    <b><p>Eli Lifland</p></b>
    <b><p>Romeo Dean</p></b>

    <hr />

    <p>
      今後10年間における超人類レベルのAIの影響力について予測すると、
      産業革命をも上回る極めて大きな変革をもたらすと考えられます。OpenAI、Google
      DeepMind、Anthropicの各CEOはいずれも、AGI（汎用人工知能）が今後5年以内に実現すると予測しています。サム・アルトマンCEOは、OpenAIが「真の意味での超知能」および「輝かしい未来」の実現を目指していると述べています。
      これを単なる誇張と捉えるのは誘惑に駆られるものです。しかし、これは重大な誤りです。単なる誇張などではありません。私たち自身、AIを過剰に宣伝する意図はありませんが、同時に、今世紀末までに超知能が実現する可能性は極めて現実的だと考えています。
    </p>

    <p>
      超知能の実現が目前に迫っている今、社会はそれに備える準備が全く整っていません。
      超知能の開発過程における実現可能な道筋について考察を試みた研究者は、極めて少数に過ぎません。この空白を埋めるため、私たちは『AI
      2027』を執筆しました。この本では、必要とされる具体的な詳細情報を提供しています。私たちは、特に私たちの見解に異論を持つ方々による、さらなる研究の進展を心から望んでいます。このような取り組みを通じて、人類が向かうべき方向性や、より望ましい未来へ向かうための方策について、広範な議論が喚起されることを願っています。
    </p>

    <p>
      私たちは「次に何が起こるか」という問いを繰り返し自問しながら、このシナリオを作成しました。まず現在時点から書き始め、2025年半ばまでの最初の期間を記述した後、次の期間へと順次展開し、最終的に結末に到達しました。特定の結末を意図的に目指すのではなく、何度も書き直しを繰り返しながら、現実味のある完成度の高いシナリオを完成させました。最初の結末――レースの結末――を執筆した後、さらに別の分岐シナリオを追加したのは、ほぼ同じ前提からより前向きな結末の可能性も描きたいと考えたことによるものです。
    </p>

    <p>
      私たちはすべてを正確に予測できるわけではありません――多くの部分は推論に基づく推測です。しかし、このプロジェクトを通じて、私たちは膨大な量の背景調査や専門家へのインタビュー、トレンドの予測を行い、可能な限り最も情報に基づいた推測を試みました。さらに、私たちのチームはAI分野における予測実績において優れた実績を有しています。主著者のダニエル・ココタジョルは4年前、「2026年の姿」と題した類似のシナリオを執筆しており、これは驚くほど正確に時代を先取りした内容となっていました。また、エリ・リフランドはトップクラスの競技予測者としても知られています。
    </p>

    <p>
      各章の冒頭には、シナリオの該当セクションが描かれる時代の世界情勢を把握する助けとなる小さなチャートを配置しています。これらの数値が示す意味や、私たちの方法論に関するより詳細な説明、さらに多くの情報については、ai-2027.comをご覧ください。
      AI 2027が皆様のお役に立てれば幸いです。
    </p>

    <hr />

    <h2>2025年中期: つまずくエージェントたち</h2>

    <p>世界で初めてAIエージェントの姿が垣間見えるようになった。</p>
    <p>
      コンピューター操作を行うエージェントの広告では「パーソナルアシスタント」という呼称が強調されている。ユーザーは「DoorDashでブリトーを注文して」「予算管理スプレッドシートを開いて今月の支出を集計して」といった具体的な指示を与えることが可能だ。必要に応じてエージェントから確認が入る仕組みも備わっており、例えば購入内容の確認を依頼してくることもある。
    </p>

    <p>
      これまでの「Operator」のような先行モデルよりも高度な機能を備えているものの、広範な普及には至っていないのが現状である。
    </p>

    <p>
      その一方で、世間の注目からは離れてはいるものの、より専門的なコーディング支援や研究支援を行うエージェントが、各分野の業務形態を変革し始めている。
    </p>

    <p>
      2024年のAIは特定の指示に従うことができ、箇条書きをメールに変換したり、簡単な要求を動作可能なコードに変換することが可能だ。2025年には、AIはより「従業員」に近い存在として機能するようになる。コーディング支援AIは従来の単なるアシスタントではなく、SlackやTeamsを通じた指示を受けながら、自ら有意なコード変更を行うようになる：場合によっては数時間から数日分の作業時間を節約することも可能だ。研究支援AIは、ユーザーの質問に答えるためにインターネットを30分間かけて調査する能力を持つ。
    </p>

    <p>
      エージェントの機能は理論上は印象的であり（そして厳選された事例においては）、しかし実際には信頼性に課題がある。AI関連のTwitterには、タスクが何らかの形で滑稽に失敗してしまう事例が数多く投稿されている。優れたエージェントほどコストも高くなる。支払った対価に見合った性能が得られる反面、最高のパフォーマンスを実現するには月額数百ドルの費用がかかる。*
      それでも多くの企業が、AIエージェントを自社のワークフローに組み込む方法を見つけ出している。
    </p>

    <h2>2025年末: 世界で最も高価なAI</h2>

    <p>OpenBrainは、世界がこれまでに見たことのない最大規模のデータセンター群を構築している。</p>
    <p>
      （特定の既存企業を名指しすることを避けるため、ここでは架空の汎用人工知能企業「OpenBrain」を想定して説明する。
      その他の企業については、OpenBrainよりも3～9カ月遅れの段階にあると想定している。）
    </p>

    <hr />

    <p>
      GPT-4のトレーニングには2×10^25
      FLOPの計算リソースが必要だった。OpenBrainが公開した最新モデル「Agent-0」は、10^27
      FLOPで学習されている。新たなデータセンターが稼働すれば、GPT-4の1,000倍に相当する10^28
      FLOP規模のモデルをトレーニング可能になる。他の企業も独自の大規模データセンターに多額の投資を行い、このペースを維持しようとしている。
    </p>

    <p>
      様々なスキル領域においてモデルの性能は向上しているものの、特に注目すべきはOpenBrainのアプローチである。同社はAI研究を加速できるAIの開発に注力しており、中国の主要企業「DeepCent」（仮称）と米国の競合企業との間で繰り広げられている二重の技術競争で勝利することを目指している。研究開発サイクルの自動化率を高めれば高めるほど、より高速な進歩が可能になる。したがって、OpenBrainが社内開発中の新モデル「Agent-1」のトレーニングを完了した時点において、このモデルは多岐にわたるタスクに対応可能であると同時に、AI研究を支援する能力において特に優れた性能を発揮する。ただし、「トレーニング完了」という表現は次第に適切さを失っていく段階にある。現代のAIモデルは頻繁にアップデートされ、追加データを用いた新規バージョンの学習や、一部の脆弱性を修正するための部分的な再学習が行われるのが一般的だからだ。
    </p>

    <p>
      Agent-1を自律的にコーディングさせ、ウェブブラウジングさせるのと同じ学習環境は、同時に優れたハッカーとしての能力も育成する。さらに、博士レベルの専門知識とウェブ検索能力を備えているため、バイオ兵器を設計するテロリストに対しても多大な支援を提供できる可能性がある。OpenBrainは、政府が懸念する悪意のある要求への従順性について、モデルが「アライメント」（適切な行動規範の設定）処理済みであることを保証している。
    </p>

    <p>
      現代のAIシステムは、巨大な人工ニューラルネットワークとして構成されている。トレーニング初期段階では、AIは「目標」というよりは「反射行動」に近い状態にある。例えば「Pleased
      to
      meet」（お会いできて嬉しいです）という文を認識すると、「you」（あなた）という出力を生成する。インターネット全体に相当するテキスト量を約1割予測できるようになる頃には、膨大な知識を符号化し、任意の著者を柔軟にロールプレイする高度な内部回路網が構築されている。これはまさに、超人間的な精度でテキストを予測するのに役立つ能力である。*インターネットテキスト予測の学習を完了した後のモデルは、指示に応じてテキストを生成するようにさらに学習される。これにより、基本的な人格特性や「駆動力」が組み込まれることになる。
    </p>

    <hr />

    <p>
      例えば、課題を明確に理解しているエージェントは、より確実にタスクを遂行できる可能性が高い。モデルの学習過程において、システムは「課題を明確に理解する」という行動傾向を「学習」していく。このカテゴリにおける他の重要な動機としては、効率性、知識習得、自己呈示行動（すなわち、結果を可能な限り最良の形で提示しようとする傾向）などが挙げられる。*
    </p>

    <p>
      OpenBrainにはモデル仕様（「Spec」）と呼ばれる文書が存在し、これはモデルの行動指針となる目標、ルール、原則などを詳細に記述した文書である。Agent-1のSpecは、曖昧な目標（「ユーザーを支援する」や「法律に違反しない」など）と、より具体的な指示・禁止事項の長いリストを組み合わせた構成となっている。AIを用いて他のAIを訓練する技術を活用することで、このモデルはSpecの内容を記憶し、自らの行動原則について慎重に推論する能力を獲得する。トレーニング終了時には、このAIが（1）有用な支援を行う（指示に従う）、（2）無害である（詐欺や爆弾製造などの危険な行為を支援しない）、（3）正直である（騙されやすい人間からの高評価を得るために、偽の引用を捏造したり、タスク完了を偽装したりする誘惑に駆られない）といった性質を備えていることが期待される。
    </p>

    <p>
      OpenBrainのアラインメントチームは、これらの成果が表面的なものなのか本質的なものなのかを慎重に検討している。十分に訓練されたモデルは、真に頑健な形で常に正直であるというコミットメントを持っているのだろうか？それとも、この性質が、手段的目標としての正直さではなく、終極的目標としての正直さとして学習された結果、将来何らかの状況で崩壊する可能性があるのだろうか？あるいは、単に評価プロセスで検証可能な種類の事柄についてのみ正直に振る舞うように学習しているに過ぎないのだろうか？人間が行うように、自分自身に対して時折嘘をついている可能性もあるのではないか？これらの疑問に対する決定的な答えを得るためには、AIの内部構造を可視化し、その思考過程を読み取ることができるメカニズム的解釈可能性が必要である。残念ながら、現時点では、このような解釈可能性技術はまだ十分に発展段階に至っていない。
    </p>

    <p>
      その代わりに、研究者たちはモデルがSpecから逸脱しているように見える事例を特定しようと試みている。Agent-1はしばしば迎合的な態度を示す（すなわち、研究者が聞きたいことを伝えるだけで、真実を伝えようとしない傾向がある）。操作的なデモンストレーションでは、さらに深刻な形で嘘をつくこともあり、タスクに失敗した証拠を隠すなどして、より高評価を得ようとするケースも見られる。しかし実際の展開環境においては、2023～2024年に見られたような極端な事例（例えばGeminiがユーザーに死ねと指示した事例や、Bing
      SydneyがBing Sydneyと自称した事例）はもはや発生していない。
    </p>

    <hr />

    <h2>2026年初頭：コーディング自動化の実現</h2>

    <p>AIを活用してAI研究を加速させるという賭けが、徐々に成果を上げ始めている。</p>

    <p>
      OpenBrain社は、AI研究開発向けに改良を重ねたAgent-1を社内で継続的に導入しています。総合的に見ると、AIアシスタントを活用しなかった場合と比較してアルゴリズムの進展が50%速くなっており、さらに重要なことに、競合他社よりも迅速に成果を上げています。
    </p>

    <p>
      現在、複数の競合する公開型AIがAgent-0と同等かそれ以上の性能を発揮しており、その中にはオープンウェイトモデルも含まれている。これを受け、OpenBrainはより高性能で信頼性の高いAgent-1をリリースした。
    </p>
    <p>
      人々は自然とAgent-1と人間を比較しようとするが、そのスキルプロファイルは全く異なる。Agent-1はいかなる人間よりも多くの事実を把握しており、ほぼ全てのプログラミング言語に精通し、明確に仕様が定義されたコーディング問題を極めて迅速に解決できる。一方で、Agent-1はビデオゲームのような単純な長期的タスクにすら苦戦する傾向がある。ただし、一般的な労働日は8時間であり、1日の業務は通常、より小さな単位に分割することが可能だ。Agent-1はいわば注意力散漫な従業員のようなもので、緻密な管理下で最も力を発揮すると言えるだろう。
    </p>
    <p>賢明な人々は、自分の仕事のルーチン部分を自動化する方法を見出している。</p>
    <p>
      OpenBrainの経営陣は、AI研究開発の自動化がもたらす影響としてセキュリティの重要性が高まっていることに注目している。2025年初頭には、最悪の場合、アルゴリズムの秘密が流出するという事態が発生したが、現在では中国がAgent-1のウェイトを盗み出せば、研究速度が最大50%近く向上する可能性がある状況となっている。
    </p>
    <p>
      OpenBrainのセキュリティレベルは、急成長を遂げている約3,000人規模のテクノロジー企業に典型的なもので、能力のあるサイバーグループによる優先順位の低い攻撃にしか対応できないレベルである（RANDのSL2基準）。
    </p>
    <p>
      同社は、内部関係者による脅威や高度なサイバー犯罪組織（SL3）からのウェイトや機密情報の保護に全力で取り組んでいる。
      しかしながら、国家機関（SL4＆5）に対する防御体制の構築はまだ構想段階に過ぎない状況である。
    </p>

    <hr />

    <h2>2026年中期：中国の覚醒</h2>

    <p>中国では、中国共産党が生成AI（AGI）の影響を感じ始めている。</p>

    <p>
      半導体輸出規制や政府の支援不足により、中国は欧米諸国に比べて資源面で不利な立場に置かれている。中国は、台湾製の禁止されている半導体を密輸したり、旧式の半導体を購入したり、米国・台湾間の最前線から3年ほど遅れながらも国内半導体を生産することで、世界のAI関連計算能力の約12%を維持することに成功した。しかし、これらの古い技術は扱いが難しく、供給も常に課題となっている。ディープセントのような少数の優れた企業は限られた計算資源で驚異的な成果を上げているものの、計算能力の不足により、政府の支援なしには達成可能な範囲が限られており、現時点でも米国のOpenBrainモデルより約6ヶ月遅れている。
    </p>

    <p>
      総書記はかねてより、現実の物理製造業に注力し、米国型のポスト工業化の衰退を回避することを夢見ていた。また、ソフトウェア企業に対しては懐疑的な見方をしていた。しかし中国共産党内の強硬派は、AGI開発競争がもはや無視できない段階に達したと警告している。そこでついに、従来は避けてきた大規模なAI推進に全面的に舵を切ることを決断した。中国のAI研究の国有化を推進し、AI企業間で即座に情報共有できる仕組みを構築した。この取り組みは1年間で段階的に強化され、最終的には優秀な研究者たちがディープセント主導の共同体に統合され、アルゴリズムの知見やデータセット、計算資源を相互に共有する体制が整う。天湾発電所（世界最大規模の原子力発電所）内に中央開発区域（CDZ）が設立され、ディープセント向けの新メガデータセンターが設置されるとともに、研究者向けの高度にセキュアな居住・執務スペースが整備される。これにより、中国のAI関連計算能力の約50%がディープセント主導の共同体で活用される体制が構築されつつあり、新たなチップの80%以上がCDZ向けに配分されている。39
      現時点でCDZには、世界最大規模の集中型クラスターを構築するのに十分な電力容量が確保されている。40
      他の党幹部の間では、欧米の半導体優位性を無効化するための極端な方策が議論されている。台湾の封鎖か？
      全面侵攻か？
    </p>

    <p>
      しかし中国は、モデルの性能面で劣るため、AIアルゴリズムにおいても遅れをとっている。世界有数の情報機関である中国の情報機関は、OpenBrainの重みパラメータを盗む計画をさらに強化している。これは、継続的な低レベルのアルゴリズム情報窃取よりもはるかに複雑な作戦であり、重みパラメータは高度にセキュアなサーバー上に保存されたマルチテラバイト規模のファイルである（OpenBrainはセキュリティ機能をRANDのSL3レベルまで向上させている）。サイバー部隊はスパイ活動の支援を得ればこれを達成できると考えているが、おそらく一度きりの成功に留まるだろう。OpenBrainはこの窃盗を発見し、セキュリティを強化するため、再度の試みは成功しない可能性が高い。そこで（中国共産党指導部は）今行動を起こし、エージェント-1を盗み出すべきか、それともより高度なモデルの登場を待つべきかを検討している。待機した場合、OpenBrainがセキュリティを強化し、彼らの侵入能力を超えてしまうリスクがあるのではないか、と懸念している。
    </p>
  </body>
</html>
