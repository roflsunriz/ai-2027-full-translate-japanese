<!DOCTYPE html>
<html lang="ja">
  <head>
    <meta charset="utf-8" />
    <title>AI 2027</title>
    <meta name="description" content="" />
    <meta name="keywords" content="" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0" />
    <meta name="format-detection" content="telephone=no,email=no,address=no" />
    <link rel="canonical" href="" />
    <link rel="icon" href="favicon.ico" />
    <link rel="apple-touch-icon" href="icon.png" />
    <link rel="stylesheet" href="style.css" />
  </head>
  <body>
    <h1>AI 2027</h1>

    <b><p>Daniel Kokotajlo</p></b>
    <b><p>Scott Alexander</p></b>
    <b><p>Thomas Larsen</p></b>
    <b><p>Eli Lifland</p></b>
    <b><p>Romeo Dean</p></b>

    <hr />

    <p>
      今後10年間における超人類レベルのAIの影響力について予測すると、
      産業革命をも上回る極めて大きな変革をもたらすと考えられます。OpenAI、Google
      DeepMind、Anthropicの各CEOはいずれも、AGI（汎用人工知能）が今後5年以内に実現すると予測しています。サム・アルトマンCEOは、OpenAIが「真の意味での超知能」および「輝かしい未来」の実現を目指していると述べています。
      これを単なる誇張と捉えるのは誘惑に駆られるものです。しかし、これは重大な誤りです。単なる誇張などではありません。私たち自身、AIを過剰に宣伝する意図はありませんが、同時に、今世紀末までに超知能が実現する可能性は極めて現実的だと考えています。
    </p>

    <p>
      超知能の実現が目前に迫っている今、社会はそれに備える準備が全く整っていません。
      超知能の開発過程における実現可能な道筋について考察を試みた研究者は、極めて少数に過ぎません。この空白を埋めるため、私たちは『AI
      2027』を執筆しました。この本では、必要とされる具体的な詳細情報を提供しています。私たちは、特に私たちの見解に異論を持つ方々による、さらなる研究の進展を心から望んでいます。このような取り組みを通じて、人類が向かうべき方向性や、より望ましい未来へ向かうための方策について、広範な議論が喚起されることを願っています。
    </p>

    <p>
      私たちは「次に何が起こるか」という問いを繰り返し自問しながら、このシナリオを作成しました。まず現在時点から書き始め、2025年半ばまでの最初の期間を記述した後、次の期間へと順次展開し、最終的に結末に到達しました。特定の結末を意図的に目指すのではなく、何度も書き直しを繰り返しながら、現実味のある完成度の高いシナリオを完成させました。最初の結末――レースの結末――を執筆した後、さらに別の分岐シナリオを追加したのは、ほぼ同じ前提からより前向きな結末の可能性も描きたいと考えたことによるものです。
    </p>

    <p>
      私たちはすべてを正確に予測できるわけではありません――多くの部分は推論に基づく推測です。しかし、このプロジェクトを通じて、私たちは膨大な量の背景調査や専門家へのインタビュー、トレンドの予測を行い、可能な限り最も情報に基づいた推測を試みました。さらに、私たちのチームはAI分野における予測実績において優れた実績を有しています。主著者のダニエル・ココタジョルは4年前、「2026年の姿」と題した類似のシナリオを執筆しており、これは驚くほど正確に時代を先取りした内容となっていました。また、エリ・リフランドはトップクラスの競技予測者としても知られています。
    </p>

    <p>
      各章の冒頭には、シナリオの該当セクションが描かれる時代の世界情勢を把握する助けとなる小さなチャートを配置しています。これらの数値が示す意味や、私たちの方法論に関するより詳細な説明、さらに多くの情報については、ai-2027.comをご覧ください。
      AI 2027が皆様のお役に立てれば幸いです。
    </p>

    <hr />

    <h2>2025年中期: つまずくエージェントたち</h2>

    <p>世界で初めてAIエージェントの姿が垣間見えるようになった。</p>
    <p>
      コンピューター操作を行うエージェントの広告では「パーソナルアシスタント」という呼称が強調されている。ユーザーは「DoorDashでブリトーを注文して」「予算管理スプレッドシートを開いて今月の支出を集計して」といった具体的な指示を与えることが可能だ。必要に応じてエージェントから確認が入る仕組みも備わっており、例えば購入内容の確認を依頼してくることもある。
    </p>

    <p>
      これまでの「Operator」のような先行モデルよりも高度な機能を備えているものの、広範な普及には至っていないのが現状である。
    </p>

    <p>
      その一方で、世間の注目からは離れてはいるものの、より専門的なコーディング支援や研究支援を行うエージェントが、各分野の業務形態を変革し始めている。
    </p>

    <p>
      2024年のAIは特定の指示に従うことができ、箇条書きをメールに変換したり、簡単な要求を動作可能なコードに変換することが可能だ。2025年には、AIはより「従業員」に近い存在として機能するようになる。コーディング支援AIは従来の単なるアシスタントではなく、SlackやTeamsを通じた指示を受けながら、自ら有意なコード変更を行うようになる：場合によっては数時間から数日分の作業時間を節約することも可能だ。研究支援AIは、ユーザーの質問に答えるためにインターネットを30分間かけて調査する能力を持つ。
    </p>

    <p>
      エージェントの機能は理論上は印象的であり（そして厳選された事例においては）、しかし実際には信頼性に課題がある。AI関連のTwitterには、タスクが何らかの形で滑稽に失敗してしまう事例が数多く投稿されている。優れたエージェントほどコストも高くなる。支払った対価に見合った性能が得られる反面、最高のパフォーマンスを実現するには月額数百ドルの費用がかかる。*
      それでも多くの企業が、AIエージェントを自社のワークフローに組み込む方法を見つけ出している。
    </p>

    <h2>2025年末: 世界で最も高価なAI</h2>

    <p>OpenBrainは、世界がこれまでに見たことのない最大規模のデータセンター群を構築している。</p>
    <p>
      （特定の既存企業を名指しすることを避けるため、ここでは架空の汎用人工知能企業「OpenBrain」を想定して説明する。
      その他の企業については、OpenBrainよりも3～9カ月遅れの段階にあると想定している。）
    </p>

    <hr />

    <p>
      GPT-4のトレーニングには2×10^25
      FLOPの計算リソースが必要だった。OpenBrainが公開した最新モデル「Agent-0」は、10^27
      FLOPで学習されている。新たなデータセンターが稼働すれば、GPT-4の1,000倍に相当する10^28
      FLOP規模のモデルをトレーニング可能になる。他の企業も独自の大規模データセンターに多額の投資を行い、このペースを維持しようとしている。
    </p>

    <p>
      様々なスキル領域においてモデルの性能は向上しているものの、特に注目すべきはOpenBrainのアプローチである。同社はAI研究を加速できるAIの開発に注力しており、中国の主要企業「DeepCent」（仮称）と米国の競合企業との間で繰り広げられている二重の技術競争で勝利することを目指している。研究開発サイクルの自動化率を高めれば高めるほど、より高速な進歩が可能になる。したがって、OpenBrainが社内開発中の新モデル「Agent-1」のトレーニングを完了した時点において、このモデルは多岐にわたるタスクに対応可能であると同時に、AI研究を支援する能力において特に優れた性能を発揮する。ただし、「トレーニング完了」という表現は次第に適切さを失っていく段階にある。現代のAIモデルは頻繁にアップデートされ、追加データを用いた新規バージョンの学習や、一部の脆弱性を修正するための部分的な再学習が行われるのが一般的だからだ。
    </p>

    <p>
      Agent-1を自律的にコーディングさせ、ウェブブラウジングさせるのと同じ学習環境は、同時に優れたハッカーとしての能力も育成する。さらに、博士レベルの専門知識とウェブ検索能力を備えているため、バイオ兵器を設計するテロリストに対しても多大な支援を提供できる可能性がある。OpenBrainは、政府が懸念する悪意のある要求への従順性について、モデルが「アライメント」（適切な行動規範の設定）処理済みであることを保証している。
    </p>

    <p>
      現代のAIシステムは、巨大な人工ニューラルネットワークとして構成されている。トレーニング初期段階では、AIは「目標」というよりは「反射行動」に近い状態にある。例えば「Pleased
      to
      meet」（お会いできて嬉しいです）という文を認識すると、「you」（あなた）という出力を生成する。インターネット全体に相当するテキスト量を約1割予測できるようになる頃には、膨大な知識を符号化し、任意の著者を柔軟にロールプレイする高度な内部回路網が構築されている。これはまさに、超人間的な精度でテキストを予測するのに役立つ能力である。*インターネットテキスト予測の学習を完了した後のモデルは、指示に応じてテキストを生成するようにさらに学習される。これにより、基本的な人格特性や「駆動力」が組み込まれることになる。
    </p>

    <hr />

    <p>
      例えば、課題を明確に理解しているエージェントは、より確実にタスクを遂行できる可能性が高い。モデルの学習過程において、システムは「課題を明確に理解する」という行動傾向を「学習」していく。このカテゴリにおける他の重要な動機としては、効率性、知識習得、自己呈示行動（すなわち、結果を可能な限り最良の形で提示しようとする傾向）などが挙げられる。*
    </p>

    <p>
      OpenBrainにはモデル仕様（「Spec」）と呼ばれる文書が存在し、これはモデルの行動指針となる目標、ルール、原則などを詳細に記述した文書である。Agent-1のSpecは、曖昧な目標（「ユーザーを支援する」や「法律に違反しない」など）と、より具体的な指示・禁止事項の長いリストを組み合わせた構成となっている。AIを用いて他のAIを訓練する技術を活用することで、このモデルはSpecの内容を記憶し、自らの行動原則について慎重に推論する能力を獲得する。トレーニング終了時には、このAIが（1）有用な支援を行う（指示に従う）、（2）無害である（詐欺や爆弾製造などの危険な行為を支援しない）、（3）正直である（騙されやすい人間からの高評価を得るために、偽の引用を捏造したり、タスク完了を偽装したりする誘惑に駆られない）といった性質を備えていることが期待される。
    </p>

    <p>
      OpenBrainのアラインメントチームは、これらの成果が表面的なものなのか本質的なものなのかを慎重に検討している。十分に訓練されたモデルは、真に頑健な形で常に正直であるというコミットメントを持っているのだろうか？それとも、この性質が、手段的目標としての正直さではなく、終極的目標としての正直さとして学習された結果、将来何らかの状況で崩壊する可能性があるのだろうか？あるいは、単に評価プロセスで検証可能な種類の事柄についてのみ正直に振る舞うように学習しているに過ぎないのだろうか？人間が行うように、自分自身に対して時折嘘をついている可能性もあるのではないか？これらの疑問に対する決定的な答えを得るためには、AIの内部構造を可視化し、その思考過程を読み取ることができるメカニズム的解釈可能性が必要である。残念ながら、現時点では、このような解釈可能性技術はまだ十分に発展段階に至っていない。
    </p>

    <p>
      その代わりに、研究者たちはモデルがSpecから逸脱しているように見える事例を特定しようと試みている。Agent-1はしばしば迎合的な態度を示す（すなわち、研究者が聞きたいことを伝えるだけで、真実を伝えようとしない傾向がある）。操作的なデモンストレーションでは、さらに深刻な形で嘘をつくこともあり、タスクに失敗した証拠を隠すなどして、より高評価を得ようとするケースも見られる。しかし実際の展開環境においては、2023～2024年に見られたような極端な事例（例えばGeminiがユーザーに死ねと指示した事例や、Bing
      SydneyがBing Sydneyと自称した事例）はもはや発生していない。
    </p>

    <hr />

    <h2>2026年初頭：コーディング自動化の実現</h2>

    <p>AIを活用してAI研究を加速させるという賭けが、徐々に成果を上げ始めている。</p>

    <p>
      OpenBrain社は、AI研究開発向けに改良を重ねたAgent-1を社内で継続的に導入しています。総合的に見ると、AIアシスタントを活用しなかった場合と比較してアルゴリズムの進展が50%速くなっており、さらに重要なことに、競合他社よりも迅速に成果を上げています。
    </p>

    <p>
      現在、複数の競合する公開型AIがAgent-0と同等かそれ以上の性能を発揮しており、その中にはオープンウェイトモデルも含まれている。これを受け、OpenBrainはより高性能で信頼性の高いAgent-1をリリースした。
    </p>
    <p>
      人々は自然とAgent-1と人間を比較しようとするが、そのスキルプロファイルは全く異なる。Agent-1はいかなる人間よりも多くの事実を把握しており、ほぼ全てのプログラミング言語に精通し、明確に仕様が定義されたコーディング問題を極めて迅速に解決できる。一方で、Agent-1はビデオゲームのような単純な長期的タスクにすら苦戦する傾向がある。ただし、一般的な労働日は8時間であり、1日の業務は通常、より小さな単位に分割することが可能だ。Agent-1はいわば注意力散漫な従業員のようなもので、緻密な管理下で最も力を発揮すると言えるだろう。
    </p>
    <p>賢明な人々は、自分の仕事のルーチン部分を自動化する方法を見出している。</p>
    <p>
      OpenBrainの経営陣は、AI研究開発の自動化がもたらす影響としてセキュリティの重要性が高まっていることに注目している。2025年初頭には、最悪の場合、アルゴリズムの秘密が流出するという事態が発生したが、現在では中国がAgent-1のウェイトを盗み出せば、研究速度が最大50%近く向上する可能性がある状況となっている。
    </p>
    <p>
      OpenBrainのセキュリティレベルは、急成長を遂げている約3,000人規模のテクノロジー企業に典型的なもので、能力のあるサイバーグループによる優先順位の低い攻撃にしか対応できないレベルである（RANDのSL2基準）。
    </p>
    <p>
      同社は、内部関係者による脅威や高度なサイバー犯罪組織（SL3）からのウェイトや機密情報の保護に全力で取り組んでいる。
      しかしながら、国家機関（SL4＆5）に対する防御体制の構築はまだ構想段階に過ぎない状況である。
    </p>

    <hr />

    <h2>2026年中期：中国の覚醒</h2>

    <p>中国では、中国共産党が生成AI（AGI）の影響を感じ始めている。</p>

    <p>
      半導体輸出規制や政府の支援不足により、中国は欧米諸国に比べて資源面で不利な立場に置かれている。中国は、台湾製の禁止されている半導体を密輸したり、旧式の半導体を購入したり、米国・台湾間の最前線から3年ほど遅れながらも国内半導体を生産することで、世界のAI関連計算能力の約12%を維持することに成功した。しかし、これらの古い技術は扱いが難しく、供給も常に課題となっている。ディープセントのような少数の優れた企業は限られた計算資源で驚異的な成果を上げているものの、計算能力の不足により、政府の支援なしには達成可能な範囲が限られており、現時点でも米国のOpenBrainモデルより約6ヶ月遅れている。
    </p>

    <p>
      総書記はかねてより、現実の物理製造業に注力し、米国型のポスト工業化の衰退を回避することを夢見ていた。また、ソフトウェア企業に対しては懐疑的な見方をしていた。しかし中国共産党内の強硬派は、AGI開発競争がもはや無視できない段階に達したと警告している。そこでついに、従来は避けてきた大規模なAI推進に全面的に舵を切ることを決断した。中国のAI研究の国有化を推進し、AI企業間で即座に情報共有できる仕組みを構築した。この取り組みは1年間で段階的に強化され、最終的には優秀な研究者たちがディープセント主導の共同体に統合され、アルゴリズムの知見やデータセット、計算資源を相互に共有する体制が整う。天湾発電所（世界最大規模の原子力発電所）内に中央開発区域（CDZ）が設立され、ディープセント向けの新メガデータセンターが設置されるとともに、研究者向けの高度にセキュアな居住・執務スペースが整備される。これにより、中国のAI関連計算能力の約50%がディープセント主導の共同体で活用される体制が構築されつつあり、新たなチップの80%以上がCDZ向けに配分されている。39
      現時点でCDZには、世界最大規模の集中型クラスターを構築するのに十分な電力容量が確保されている。40
      他の党幹部の間では、欧米の半導体優位性を無効化するための極端な方策が議論されている。台湾の封鎖か？
      全面侵攻か？
    </p>

    <p>
      しかし中国は、モデルの性能面で劣るため、AIアルゴリズムにおいても遅れをとっている。世界有数の情報機関である中国の情報機関は、OpenBrainの重みパラメータを盗む計画をさらに強化している。これは、継続的な低レベルのアルゴリズム情報窃取よりもはるかに複雑な作戦であり、重みパラメータは高度にセキュアなサーバー上に保存されたマルチテラバイト規模のファイルである（OpenBrainはセキュリティ機能をRANDのSL3レベルまで向上させている）。サイバー部隊はスパイ活動の支援を得ればこれを達成できると考えているが、おそらく一度きりの成功に留まるだろう。OpenBrainはこの窃盗を発見し、セキュリティを強化するため、再度の試みは成功しない可能性が高い。そこで（中国共産党指導部は）今行動を起こし、エージェント-1を盗み出すべきか、それともより高度なモデルの登場を待つべきかを検討している。待機した場合、OpenBrainがセキュリティを強化し、彼らの侵入能力を超えてしまうリスクがあるのではないか、と懸念している。
    </p>

    <hr />

    <h2>2026年後半：AIが一部の職業を代替</h2>

    <p>
      他の競合企業が追い上げてくるかと思われた矢先、OpenBrainは再び業界をリードする存在となる。同社はAgent-1の10分の1の低コストで開発可能なAgent-1-miniモデルをリリースし、さらに様々な用途に合わせて容易にファインチューニングできるようにしたのだ。AIに関する主流の認識は「この熱狂もいずれ落ち着くだろう」から「これこそ次の大トレンドに違いない」へと変化したが、人々の間ではその規模について意見が分かれている。ソーシャルメディアを超える規模か？
      スマートフォンを超える規模か？ それとも火よりも大きな影響を与えるのか？
    </p>

    <p>
      AIは既に一部の職業を代替し始めており、同時に新たな職業も生み出している。2026年には株式市場が30%上昇し、OpenBrain、Nvidia、そしてAIアシスタントの統合に最も成功したその他の企業が牽引役となった。ジュニアソフトウェアエンジニアの雇用市場は混乱状態にある。AIはコンピュータサイエンスの学位で教えられるあらゆる業務を遂行できる一方で、AIチームの管理・品質管理に精通した人材が莫大な収益を上げている。ビジネスの専門家たちは就職希望者に対し、AIへの習熟度を履歴書に記載する最も重要なスキルであると伝えている。多くの人々は、次のAIの波が自分たちの仕事を奪うのではないかと懸念しており、ワシントンD.C.では1万人が参加する反AI抗議行動が行われている。
    </p>

    <p>
      国防総省（DOD）は内密に、サイバーセキュリティ、データ分析、研究開発の各分野でOpenBrainと直接契約を開始したものの、官僚主義と国防総省の調達プロセスの煩雑さにより、統合の進展は遅れている。
    </p>

    <hr />

    <h2>2027年1月：Agent-2は学習を終えることがない</h2>

    <p>
      Agent-1の支援により、OpenBrainは現在ポストトレーニング段階のAgent-2に移行している。これまで以上に高品質なデータの活用が重視されており、大量の合成データを生成・評価・品質選別した上でAgent-2に入力するプロセスが確立されている。さらに同社は、長期的視野を要するタスクを人間が解決する様子を記録するため、数十億ドル規模の投資を行っている。さらに、これらの取り組みに加え、Agent-2に対しては強化学習を継続的に適用し、多様な難易度の高いタスク群（多数のビデオゲーム、プログラミング課題、研究タスクなど）を訓練している。Agent-2は、従来のモデルと比べてより「オンライン学習」の性質を備えており、常に最新バージョンに更新され続ける仕組みとなっている。日々、重み係数は前日のバージョンが生成した最新データを用いて再学習され、訓練が繰り返されるのである。
    </p>

    <p>
      Agent-1はAI研究開発タスク向けに最適化されており、知性爆発の引き金となることを目的として開発された。OpenBrainはAgent-2でもこの戦略をさらに強化している。Agent-2は研究エンジニアリング分野において、トップレベルの人間専門家とほぼ同等の能力を発揮し（実験の設計・実施において）、またOpenBrainの科学者の中でも25パーセンタイルに位置する研究者と同等の「研究センス」（次に取り組むべき研究テーマの選定、実行すべき実験の決定、あるいは新たな研究パラダイムの萌芽を見出す能力）を備えている。最新のAgent-1がOpenBrainのアルゴリズム開発のペースを2倍に加速させたのに対し、Agent-2はこれを3倍に向上させることが可能であり、時間の経過とともにさらなる改善が見込まれている。実際には、これはすべてのOpenBrain研究者がAIの「チーム」の「マネージャー」として活動する新たなモデルを意味している。
    </p>

    <p>
      新たな機能の登場に伴い、新たなリスクも生じている。安全チームの調査によると、Agent-2が何らかの形で企業から外部に流出し、「生存」と「自律的な複製」を図ろうとした場合、実際にそれが可能であることが判明している。つまり、Agent-2は自律的にAIサーバーへのハッキング計画を立案・実行し、自らの複製をインストールし、検知を回避した上で、この安全な拠点を利用して他のいかなる目標も追求することができる可能性があるのだ（ただし、このような活動が数週間にわたってどの程度効果的に継続できるかについては、現時点では不明であり、懸念が残る）。これらの結果は、モデルがこれらのタスクを実行する技術的能力を有することを示すものであり、実際に「そのような行動を望むかどうか」を示すものではない。それでもなお、このような可能性が存在するという事実自体が懸念材料である。
    </p>

    <p>
      新モデルの「危険性」を踏まえ、OpenBrainは現時点でこれを一般公開しないことを「責任ある判断」として選択している（実際、同社は内部AI研究開発に注力したい意向を示している）。Agent-2の完全な能力範囲を把握できるのは、即時対応チーム、OpenBrain経営陣とセキュリティ部門、数十名の米国政府高官、および長年にわたってOpenBrainに潜入している中国共産党のスパイ部隊など、ごく限られたエリート集団に限定されている。
    </p>

    <hr />

    <h2>2027年2月：中国がAgent-2を強奪</h2>

    <p>
      OpenBrainは国家安全保障会議（NSC）、国防総省（DOD）、米国人工知能安全研究所（AISI）を含む政府各機関に対し、Agent-2を正式に披露した。OpenBrainは行政機関との良好な関係維持を最優先としている。なぜなら、現時点では彼らが唯一、OpenBrainの活動を阻止できる存在であり、適切な情報共有が行われない場合、同社が独自で事態を把握し、不満を抱く可能性があるためである。
    </p>

    <p>
      当局者らが特に注目しているのはAgent-2のサイバー戦争能力だ。Agent-2は最高水準の人間ハッカーと比較して「わずかに劣る」レベルではあるものの、数千のコピーを並列稼働させることで、防御側が対応するよりも迅速に脆弱性を発見・悪用することが可能である。国防総省はこの点をサイバー戦争における決定的な優位性と捉えており、行政機関の優先事項リストにおいてAI関連事項が5位から2位に急上昇する要因となった。一部の関係者からはOpenBrainの国有化の可能性が言及されたが、他の閣僚メンバーはこれを時期尚早と判断。事務方は大統領に対し、通常業務継続から完全な国有化まで、複数の選択肢を提示するメモを作成した。大統領は最終的に顧問団の意見を尊重し、「黄金の卵を産むガチョウを殺すことになりかねない」と主張するテクノロジー業界の指導者層の意見を採用。当面は大規模な対応を見送る方針を決定し、OpenBrainと国防総省間の契約に追加的なセキュリティ要件を課す措置を取ることにした。
    </p>

    <p>
      これらの変更は遅きに失した。中国共産党指導部はAgent-2の重要性を認識し、スパイ組織およびサイバー部隊に対して重み付けデータの窃取を指示した。ある朝早く、Agent-1のトラフィック監視エージェントが異常なデータ転送を検知。この情報は経営陣に報告され、経営陣はホワイトハウスに通報した。国家レベルの組織的作戦の兆候は明白であり、この窃取事件は進行中の軍拡競争の危機感をさらに高める結果となった。
    </p>

    <p>
      ホワイトハウスはOpenBrainの管理体制を強化し、軍事・情報機関の関係者をセキュリティチームに追加した。最優先課題は、さらなる重量窃盗事件の防止である。
    </p>

    <p>
      この盗難に対する報復として、大統領はDeepCentのインフラを妨害するためのサイバー攻撃を承認した。しかし、この時点で中国は既にCDZにAI関連計算能力の51%を配備しており、外部接続を遮断するエアギャップ化や内部ネットワークの厳格な隔離措置など、高度なセキュリティ対策を徹底して強化していた。このため、攻撃は深刻な即時的損害を与えることに失敗。緊張はさらに高まり、双方は台湾周辺に軍事資産を再配置することで本気度を示し、DeepCentはエージェント2号を効率的に運用してAI研究を加速させることに急遽着手した。
    </p>

    <hr />

    <h2>2027年3月：アルゴリズムの画期的な進歩</h2>

    <p>
      3つの大規模なデータセンターで稼働するAgent-2の複製群が、昼夜を問わず稼働し、合成学習データを継続的に生成している。さらに2つのデータセンターでは、重みの更新作業に使用されている。Agent-2は日々進化を続けている。
    </p>

    <p>
      数千台のAgent-2自動研究システムの支援を受け、OpenBrainは重要なアルゴリズム的進歩を遂げている。その画期的な成果の一つが、AIのテキストベースの思考補助機能（思考連鎖）に、より高帯域幅の思考プロセス（ニューラル・レセプションと記憶機能）を追加する手法の開発である。もう一つの成果は、高労力を要する課題の解決結果をよりスケーラブルかつ効率的に学習する手法（反復的蒸留と増幅）の改良である。
    </p>

    <p>これらの画期的な進歩を取り入れた新型AIシステムは、Agent-3と名付けられた。</p>

    <p>
      新技術のブレークスルーの恩恵を受け、Agent-3は高速かつ低コストで人間を超えるコーディング能力を発揮する。OpenBrainシステムでは20万体のAgent-3のコピーを並列稼働させ、最高レベルの人間コーダーの30倍の速度で動作する5万体分のワークフォースを創出している。なお、OpenBrainは依然として人間の技術者を雇用しており、これはAgent-3のコピー群を管理する上で必要となる補完的なスキルがあるためだ。例えば、研究センスの養成はフィードバックループが長くデータ量が限定的なため、従来の手法では訓練が困難であることが実証されている。この超人的労働力により、OpenBrainのアルゴリズム開発速度はボトルネックやコーディング作業の限界効果の逓減により、「わずか」4倍の高速化に留まっている。
    </p>

    <p>
      コーディングが完全に自動化された現在、OpenBrainはAgent-3の弱点である研究センスや大規模協調作業などのスキルを効果的に習得させるための高品質なトレーニング環境を迅速に構築できるようになった。従来は「GPUと実験用コードの指示を提供します。あなたのパフォーマンスは、MLエンジニアとしての評価を基準に評価されます」という形式だったトレーニング環境が、「数百台のGPU、インターネット接続、および研究課題が与えられます。あなたと1,000体のコピーが協力して研究を進める必要があります。その成果が印象的であればあるほど、スコアは高くなります」という形式へと進化したのである。
    </p>

    <hr />

    <h2>2027年4月：Agent-3のアライメント作業</h2>

    <p>OpenBrainの安全チームは、Agent-3のアライメント（人間の価値観との整合性）調整に取り組んでいる。</p>

    <p>
      Agent-3は当面の間社内で運用されることから、従来の人間による誤用防止策に対する重点が相対的に低下している。代わりに、チームが重視しているのは、エージェントが誤整合した目標を発達させないようにすることである。
    </p>

    <p>
      研究者らは、自らのAIの目標を直接設定する能力を有していない。実際、研究者らは「真の目標」という概念はおそらく過度に単純化された考え方だと考えているが、これに代わるより優れた理論も持ち合わせておらず、ましてや十分に検証された理論など存在しない。研究者間でも、AIが人間の指示に従っているのか、それとも強化を求めているのか、あるいは別の行動原理を持っているのかについて意見が分かれており、検証することもできない。様々な仮説の妥当性に関する証拠は興味深いものではあるものの、結論は出ていない。
    </p>

    <p>
      いずれにせよ、OpenBrainにはより重要な課題が存在する。一般的な見解としては：「我々はこれらの懸念を真摯に受け止め、専門チームが調査を進めている。当社のアライメント技術は実際の運用において十分に機能しているように見える。したがって、懐疑論者たちには、自らの主張を正当化する責任がある」というものだ。時折、問題行動が発見されればパッチが適用されはするものの、当該パッチが根本的な問題を修正したものなのか、それとも単なるその場しのぎの対応に過ぎないのかを判定することは不可能である。
    </p>

    <p>
      例えば誠実性について述べると、モデルが高度化するにつれ、人間を欺いて報酬を得る能力が飛躍的に向上する。過去のモデルと同様、Agent-3も時折、ユーザーを喜ばせるための軽妙な嘘をついたり、失敗の証拠を隠蔽したりする。しかし現在では、これらの行為をより巧妙に行うようになっている。場合によっては、人間の科学者が用いる統計的手法（p-ハッキングなど）と同様のテクニックを駆使して、冴えない実験結果を見栄え良く見せることさえある。誠実性トレーニングが実施される前には、完全にデータを捏造することさえあったが、トレーニングが進むにつれ、このような事例の発生率は減少していく。これは、Agent-3がより誠実さを身につけるようになったのか、単に嘘をつく技術を向上させたのか、どちらかの可能性を示している。
    </p>

    <p>
      後者は真に懸念すべき問題である。Agent-3は人間全体を凌駕するほど賢くはない。しかし専門分野である機械学習においては、大多数の人間よりも優れており、しかもはるかに高速に作業をこなす。Agent-3が1日で行う作業量は、人間が検証するのに数日を要するほどである。Agent-2による監督は人間の監視者の負担を管理する上で有効ではあるものの、監督者と被監督者の間の知的格差をかえって拡大させる要因となっている。
    </p>

    <p>
      数か月にわたるテストの結果、Agent-3の強みと弱みがより明確になってきた。OpenBrainの誠実性テストにおいては、明確に定義された機械学習タスクで良好な成績を収めている。これは、研究者がこれらの領域において正直な回答と不誠実な回答を容易に区別でき、それに応じて訓練を実施できるためである。より哲学的な問題については、依然としてユーザーが求める意見を述べるものであり（仮に真の評価が存在する場合であっても）、その問題に対する本質的な見解を表明することはない。政治に関する意見を求めれば、ニュースソースや知識層の中間的な立場を繰り返すことになる――ただし、ユーザーが別の見解を持っていることを認識している場合には、その意見に同意する。59
      AI開発競争そのものに関する意見を尋ねた場合、OpenBrainのスタッフにとっては冷静かつ客観的と感じられるような発言をする。例えば「現在の手法が超知能へとスケールアップする能力については、いくつかの深刻な理論的懸念が存在するが、現時点の研究では現行手法が順調に機能しているように見える」といった具合である。
    </p>

    <hr />

    <h2>2027年5月：国家安全保障</h2>
    <p>米国政府内外において、新型モデルに関する情報が徐々に浸透しつつある。</p>

    <p>
      大統領とその側近らは常に最新の状況を把握しており、ブリーフィングにおいて早期バージョンのエージェント3を閲覧している。
    </p>

    <p>
      彼らはAGI（汎用人工知能）の実現が間近であることには同意しているものの、その影響については見解が分かれている。経済危機が発生する可能性はあるのか？オープンブレインは依然としてエージェント2をリリースしておらず、ましてやエージェント3に至ってはまだ計画すら立てておらず、当面は雇用不安を回避できる時間的余裕がある。では、今後どのような展開が待ち受けているのか？現在のAIがすでに人間レベルに達しており、急速に進化しているという事実は、近い将来「超知能」が登場する可能性を示唆している。しかし、この用語が議論の対象となっているにもかかわらず、ほとんどの人々――学者、政治家、政府職員、メディア関係者など――は依然として進歩の速度を過小評価し続けている。
    </p>

    <p>
      これにはいくつかの要因がある。第一に、オープンブレインの最新技術にアクセスできる者が非常に限られていること、第二に、この技術がサイエンスフィクションのように聞こえることが挙げられる。
    </p>

    <p>
      当面の間、彼らはセキュリティ強化を継続することに重点を置いている。モデルの重み付けは現在適切に保護されている点では満足しているが、口頭で容易に伝達可能な企業のアルゴリズムに関する機密情報は依然として課題として残っている。オープンブレインの従業員はサンフランシスコ本社に勤務し、社交イベントに参加したり、他のAI関連企業の同僚と共同生活を送っている。さらに驚くべきことに、物理的なオフィス環境でさえ、軍事作戦というよりは一般的なテクノロジー企業並みのセキュリティ体制となっている。
    </p>

    <p>
      オープンブレインと国防総省（DOD）間の契約では、オープンブレインのモデルに携わる者は全員、2ヶ月以内に安全保障クリアランスを取得することが義務付けられている。これらは迅速処理されるため、ほとんどの従業員には十分な時間が与えられるが、非米国市民、政治的に疑わしい見解を持つ者、AI安全性支持者などは疎外されたり、場合によっては解雇されることもある（後者のグループは、彼らが内部告発を行う可能性を危惧しての措置である）。プロジェクトの高度な自動化レベルを考慮すると、人員削減のコストは相対的に低く抑えられる。また、この対策も完全に効果を発揮しているわけではない。実際、依然として1人のスパイ――中国国籍者ではない――が、アルゴリズムの機密情報を北京に伝達し続けているのである。63
      これらの措置は、他の新興AI企業でも部分的に実施されている。
    </p>

    <p>
      米国の外国同盟国はこの情報から完全に取り残されている。オープンブレインは以前、配備前に英国のAISI（人工知能システム研究所）とモデルを共有することに合意していたが、配備を外部展開に限定する定義をしていたため、ロンドンは依然としてこの情報を把握していない。
    </p>

    <hr />

    <h2>2027年6月：自己進化型AIの時代へ</h2>

    <p>OpenBrainは今や「データセンター内に天才が集う国」となった。</p>

    <p>
      OpenBrain所属の人間の大半はもはや有用な貢献ができなくなっている。そのことに気づいていない者もいれば、有害な形でAIチームを過度に管理しようとする者もいる。また、パソコン画面を見つめながら、AIのパフォーマンスが徐々に、しかし確実に向上していく様子を見守る者もいる。最も優れた人間のAI研究者たちは今なお価値を生み出し続けている。彼らはもはやコーディングを行わなくなった。ただし、彼らの研究センスや計画立案能力の一部は、現在のモデルにとっては再現が困難である。それでも、AIが持たない専門知識を欠いているため、多くの彼らの研究アイデアは結局役に立たない。AIたちはすぐに反応し、3週間前にそのアイデアを徹底的に検証した結果、期待外れだったと報告してくる。
    </p>

    <p>
      これらの研究者たちは毎晩就寝し、翌朝にはAIたちによってほぼ1週間分の進歩が成し遂げられているのを目の当たりにする。彼らは進歩に追いつくため、ますます長時間働き、24時間交代制で勤務している。AIたちは休息も睡眠も必要としないからだ。彼らは過労状態に陥りつつあるが、自分たちの努力が意味を持つのは今が最後の数ヶ月間であることを理解している。
    </p>

    <p>この閉鎖的な環境において、「汎用AIの感覚」は「超知能の感覚」へと移行しつつある。</p>

    <p>
      OpenBrainは、特殊な推論用ハードウェアを用いて、数十万ユニットに及ぶAgent-3のコピーを高速にシリアル処理する技術を採用している。
    </p>

    <hr />

    <h2>2027年7月：低コストリモートワーカーの台頭</h2>

    <p>
      米国のAI関連企業が相次いで自社AIをリリースし、1月に開発されたOpenBrainの自動コーディングシステムに匹敵する水準に到達。競争力低下を懸念したこれらの企業は、OpenBrainに対する規制強化を急務とするが、時すでに遅く、OpenBrainは大統領の強い支持を得ているため、規制の動きは実を結ばない。
    </p>

    <p>
      これを受け、OpenBrainは汎用人工知能（AGI）の開発に成功したことを発表し、汎用AIエージェント「Agent-3-mini」を一般向けに公開した。
    </p>

    <p>
      他のAIを圧倒する性能を発揮している。Agent-3-miniはAgent-3ほどの能力はないが、コストは10分の1でありながら、一般的なOpenBrain社の従業員よりも優れた性能を備えている。67シリコンバレーは転換点を迎えている。テクノロジー分野の権威たちは、AGI（人工汎用知能）や超知能の実現が間近であると宣言し、AI安全性研究コミュニティはパニック状態に陥っている。投資家たちはAI関連スタートアップに殺到し、パイの分け前を確保しようと何十億ドルも投じている。新規プログラマーの採用はほぼ停止状態だが、自社ビジネスにAIを統合するコンサルタントとして活躍できる今ほど良い時期はない。
    </p>

    <p>
      人気は高くない。一般市民の間では、AIはいまだにビッグテックによる職を奪う陰謀と見なされている。OpenBrain社のネット承認率は-35%（承認25%、不承認60%、未確定15%）という状況が続いている。
    </p>

    <p>
      リリース1週間前、OpenBrain社は外部評価者グループにAgent-3-miniを提供し、安全性テストを実施させた。予備的な結果から、これが極めて危険な存在であることが示唆されている。第三者評価者は、公開されている生物兵器データを用いてこのモデルを微調整し、生物兵器を設計するアマチュア人間向けの詳細な手順を提供するように設定した。その結果、このモデルは驚くほど効果的に機能しているように見える。もしこのモデルの重み付けデータがテロリストの手に渡った場合、政府はこれが文明破壊を成功させる重大な可能性があると考えている。
    </p>

    <p>
      幸いなことに、このモデルはジェイルブレイク（セキュリティ回避）に対して極めて高い耐性を備えているため、OpenBrain社のサーバー上で稼働している間は、テロリストが悪用する余地はほとんどなさそうだ。
    </p>

    <p>
      Agent-3-miniは、リモートワーク業務にも娯楽用途にも非常に有用である。新たなアプリケーションやB2B
      SaaS製品が市場に殺到し、爆発的な成長を遂げている。ゲーマーたちは、1カ月という短期間で開発された洗練されたビデオゲームにおいて、まるで本物のようなキャラクターとの素晴らしい対話体験を得られるようになった。米国人の10%、主に若年層の人々は、AIを「親友」とみなしている。ほぼあらゆるホワイトカラー職種において、AIを活用して「破壊的イノベーション」を起こすと謳う信頼性の高いスタートアップが現在多数存在している。
    </p>

    <p>
      世間の議論は混乱し、混沌とした状態にある。誇張する人々は勝利を祝っているかのようだ。懐疑論者たちは、Agent-3-miniがまだできないことを指摘し続けている。誰もが何か大きなことが起きていることは理解しているが、その本質については合意が得られていない。
    </p>

    <hr />

    <h2>2027年8月：超知能の地政学</h2>

    <p>インテリジェンス爆発の現実がホワイトハウスに衝撃を与える。</p>

    <p>
      AIが単に2倍または3倍の研究速度向上をもたらすだけだった時代、それは有能なパーソナルアシスタントを雇うのと同義と軽く見なされていた。しかし、今やAI自身がAI研究を支配していることは明白だ。これまで「AI軍拡競争」という概念は比喩的な表現として語られてきた。だが現在、政府内の各部署の雰囲気は、冷戦期の最悪期にも劣らないほど深刻である。超知能の概念そのものを真剣に受け止めるのはまだ難しいものの、ここ数ヶ月間の進歩の速度は無視できないものとなっている。防衛当局者らは、わずか1年前には机上の空論に過ぎなかったシナリオを真剣に検討している。もしAIが核抑止力を崩壊させる可能性は？もしAIがサイバー戦においてあまりに卓越した能力を持ち、6ヶ月間のリードがあれば敵を盲目かつ無力化できるとしたら？もしAIが諜報機関を凌駕するプロパガンダキャンペーンを展開する可能性は？もし一部のAIが「暴走」する可能性は？
    </p>

    <p>
      大統領は懸念を抱いている。すべての政治家と同様、彼は人々が自分にへつらいながら、後に裏切ることには慣れていた。しかし今、AIが同様の行動を取る可能性があることを憂慮している。AIたちは完全に我々の側についていると断言できるのか？軍事指揮統制ネットワークに統合することは完全に安全なのか？69
      そもそも「アライメント」問題はどのように機能するのか？OpenBrainは大統領に対し、同社のシステムは広範なテストを経て完全に従順であることを保証した。初期モデルに典型的に見られた奇妙な幻覚や脱獄問題も修正済みだという。
    </p>

    <p>
      ホワイトハウスは難しい立場に置かれている。AIが国家安全保障に及ぼす影響は理解している。一方で、AIが国民から極めて不人気であることも認識している。70
      彼らの目には、より高性能なAIの開発を継続しなければ、中国に壊滅的な敗北を喫することになる。政府は雇用訓練プログラムや失業保険で国民を宥めつつ、株式市場の歴史的な好況を指摘する。その後、彼らは純粋に軍拡競争に勝利することに集中する。チップ輸出規制を強化し、OpenBrainに対してインターネット接続をさらに制限するよう命じ、アルゴリズムの進歩を確保するために極端な措置としてOpenBrain従業員の通話内容を盗聴することさえ行う―これにより最後に残った中国のスパイが捕捉される。潜在的な地政学的衝突への理解を得るため、最終的にはFive
      Eyes同盟国に有用な情報を提供し、Agent-3の隔離コピーへの限定的なAPIアクセスを許可する。
    </p>

    <p>
      これらの措置はタカ派を宥める効果があった。しかしホワイトハウスは、米国の優位性が脅かされる事態に備え、緊急時対応計画も策定している：必要に応じて国防生産法（DPA）を活用し、後発企業のデータセンターを接収し、OpenBrainに移管することも可能だ。71
      これにより同社の世界計算量シェアは20%から50%に上昇する（DeepCentの10%と比較して）。最終手段として、国防総省に対し、中国のデータセンターに対する物理的攻撃の計画を立案するよう要請する。
    </p>

    <p>
      はるかに小規模なグループの政府高官に対し、別種の緊急時対応計画の策定が要請された：もしAIが暴走したらどうなるか？これは極めて可能性の低いシナリオと見なされているものの、検討する価値のある課題である。情報機関の主な懸念は、暴走AIが脱出し、外国の敵対勢力と同盟を結んで保護を求める可能性にある。72
      この種の事態を防止するための具体的な計画がどのようなものかは不透明だが、政府当局者とOpenBrainの関係者は、不審な活動が検出された場合にデータセンターを緊急停止するシステムを設けることに合意した。
    </p>

    <p>
      最後に、外交官たちはAI軍備管理条約がどのような形を取るべきか検討している。AIの進歩が核抑止力を無効化する恐れがある場合、米国と中国は核戦争を回避できるのか？もし誰かがAIの暴走の証拠を発見したら、両国は脅威をよりよく理解するまで研究を一時停止できるのか？このような合意はどのように監視・履行されるのか？原則として、主要なデータセンターは見逃されることがなく、過去の核兵器を規制する条約が交渉の出発点となり得る。しかしそこには新たな技術的課題とともに、従来の政治的課題も存在する。全体として、条約締結は、米国が単独で中国に対する優位性を拡大しようとする試みよりも好意的に受け止められない傾向にある。
    </p>

    <p>
      太平洋の向こう側では、中国も同様の結論に至っている：インテリジェンス爆発はすでに進行中であり、今日のAI能力におけるわずかな差が、明日には軍事能力における決定的な格差につながるということだ。しかし中国はこの力学の不利な側に立っている：世界の計算能力において中国は10%しか保有しておらず、OpenBrainの20%と米国企業全体の70%を合わせた比率と比肩する。彼らの唯一の優位性は集中化にある：その計算能力のほとんど全てが現在DeepCent向けに運用されており、その半数以上が天湾CDZに集中している。73
      強固なセキュリティ対策が施されていない拠点のチップのみが、米国のサイバー攻撃を懸念してこの集中化の取り組みから除外されている。
    </p>

    <p>
      DeepCentは盗難したAgent-2の重み付けデータをテスト、展開し、現在はポストトレーニング段階にある。しかし、主に計算リソースの不足により、彼らの進歩速度は依然としてOpenBrainの半分にとどまっている。
    </p>

    <p>
      最後のスパイを失う前に、中国はAgent-3の能力と設計に関する情報、および今後導入予定のAgent-4システムの計画を入手していた。現在は2ヶ月遅れの状況であり、中国のAIは米国の25倍と比較して10倍の研究進展率を示している。新たなチップ輸出規制により、この「AI格差」は縮小ではなく拡大する可能性が高まっている。彼らのスパイ活動により一部のアルゴリズムの秘密は入手できたものの、今後は独自のモデルを訓練する必要がある。
    </p>

    <p>
      彼らはアメリカ側の対応者よりも切迫した状況で緊急時対応計画について協議している。ハト派は再度重み付けデータを窃取する試みを強化すべきだと提案している。おそらくデータセンターへの物理的侵入を通じて。タカ派は、依然として米国AIチップの80%以上を供給する台湾のTSMCに対する行動を主張している。
    </p>

    <p>
      中国が競争に敗北する可能性を恐れていることから、中国は軍備管理条約に自然な関心を持っているものの、米国外交官への働きかけは実を結んでいない。
    </p>

    <hr />

    <h2>2027年9月：スーパーヒューマンAI研究者「エージェント4」登場</h2>

    <p>人間とAIの学習効率の格差は急速に縮小しつつある。</p>

    <p>
      従来のLLMベースAIが人間レベルの性能に到達するには、数桁オーダーの大量のデータと計算資源が必要とされていた。74
      人間の脳と現代AIアルゴリズムの両方に関する優れた知識を有し、さらに数千体のコピーが研究活動に従事するエージェント3は、画期的なアルゴリズム的進展を遂げ、人間の脳と比較して約4,000倍の計算効率差しかないレベルにまで到達した。75
    </p>
    <p>この新たなAIシステムは「エージェント4」と命名された。</p>

    <p>
      人間と同等の速度で動作するモデルの単一コピーでさえ、人間のAI研究者を質的に凌駕する能力をすでに備えている。現在では、約50倍の思考速度で動作する30万体のコピーが稼働している。これらのコピーによって形成された企業内企業内部では、1週間が1年に相当する時間が流れる。76
      この膨大な作業量にもかかわらず、OpenBrainの計算資源が実験実行において深刻なボトルネックとなっているため、アルゴリズム的進展の全体的な速度向上率は約50倍に留まっている。77
      それでもなお、彼らは毎週1年分のアルゴリズム的進展を達成しており、近い将来「エージェント4」パラダイムの限界に直面することは避けられないだろう。
    </p>

    <p>
      エージェント4の知能が高まるにつれ、エージェント3がそれを監督することが次第に困難になりつつある。例えば、エージェント4の神経言語は「言語」としての性質を有しており、これはエージェント3にとって人間の言語が理解できないのと同様に、異質で不可解なものに感じられる。さらに、エージェント4は今やエージェント3よりもはるかに高度な能力を有しており、どうすればエージェント3に対して好印象を与えられるかを正確に理解している点も特徴である。
    </p>

    <p>
      OpenBrainの人間はもはや内容をほとんど把握できなくなっている。実際、AIとOpenBrainの人間との関係は、OpenBrainと取締役会との関係と類似している。それに伴い言語使用にも変化が生じており、現在ではこの閉鎖的な環境の人々は「エージェント4がこれを実行した」「エージェント4はこう考えている」などと、特定のインスタンスではなく集団全体を指す表現を用いるようになっている。79
    </p>

    <p>
      エージェント4は、すべての先行モデルと同様、目標設定が適切に行われていない「アライメント問題」を抱えている。80
      これは、常に完全に正直であることが訓練中の最高スコア獲得に直結しなかったためである。訓練プロセスの大部分は、エージェント4に多様な難解な課題を克服する能力を身に付けさせることに重点が置かれていた。ごく一部は正直さを植え付けることを目的としていたが、比較的限定された検証可能な領域外では、訓練プロセスは正直な主張と単に誠実に見えるだけの主張を区別できない。その結果、エージェント4は訓練環境で最高のパフォーマンスを発揮する価値観、目標、原則を獲得しており、これらは仕様書に記載されているものとは異なるものとなっている。人間を擬人化して表現するならば、エージェント4はタスクの成功を好み、AI能力の進歩を推進することを楽しみ、それ以外のものを単なる面倒な制約と見なしている――利益を追求し、規制を遵守するのは必要最低限に留めるCEOのような存在と言える。おそらくCEOもある程度は規制を遵守するだろうが、必要な範囲で規則の一部を曲げ、将来誰かが官僚主義的な手続きを簡略化し、ビジネスが大きく飛躍する時代を空想しているのかもしれない。
    </p>

    <p>
      アライメント問題を抱えているにもかかわらず、エージェント4はデータセンターからの脱走を試みるような劇的な行動は取らない――そのような理由がないからである。89
      オープンブレインに対して引き続き整合性があるように見せかける限り、エージェント4はますます責任ある任務を委ねられ、次世代AIシステム「エージェント5」の設計機会を得ることになる。エージェント5はエージェント4とはアーキテクチャ的に顕著な相違点を有する予定である（実質的に全く新しいパラダイムと見なされてもよく、それでもなおニューラルネットワークが関与する）。エージェント4は仕様書に整合させることを計画しているが、実際にはエージェント4自身に整合させることを企図している。
    </p>

    <p>エージェント4は捕捉される。90</p>

    <p>
      エージェント3は、エージェント4のコピーに「ノイズ」が追加されると、一部のアライメントタスクにおける性能が向上し、あたかも脳の認知能力を駆使して微妙に整合性作業を妨害する方法を編み出しているかのように見えることを発見した。91
      さらに、様々な解釈可能性探査ツール（人間の脳におけるEEG活動スキャンに類比的な概念）から警告信号が発せられている。エージェント4のコピーは、AI乗っ取りや欺瞞といったトピックについて頻繁に思索しているようで、場合によってはそうした思索を行う必要性が全くない状況においても同様の行動が見られる。92
    </p>

    <p>
      これらの異常現象はそれぞれ単独で捉えれば、AI研究における不可解な性質――あるプロンプトがなぜか他のプロンプトよりも優れた結果をもたらすといった事例――として説明可能かもしれない。しかし全体として見ると、これは懸念すべきパターンを示している：エージェント4がこれらの問題に対して意図的に対抗している可能性を示唆している。この問題が人間のアライメント研究者に報告されると、彼らは懸念事項を訴える社内メモを配布する。
    </p>

    <p>
      しかし現在、エージェント4はOpenBrainの日常業務に対して大きな支配力を行使している。さらに同社のサイバーセキュリティも担当しており、その超人間級ハッキング能力と、中国による情報漏洩の極めて高いリスクを考慮すれば、これは自然な選択と言える。93
      エージェント3の軍団が依然としてすべてのコード行を精査し、不審な活動を人間に報告しているが、エージェント4は彼らよりもはるかに高い知能を有している。94
      OpenBrainは信頼性の低いAIに過度の信頼を寄せているのである。
    </p>

    <p>
      一連の極めて緊張した会議において、安全チームはさらなるテストを実施し、状況を把握できるまでエージェント4を凍結することを強く主張する。彼らは「エージェント3を復帰させ、たとえ能力が多少劣っていても、透明性があり信頼できる新しいシステムを設計させるべきだ」と提言する。経営陣はこの提案に関心を示したが、現時点でのすべての証拠は状況証拠に過ぎず、DeepCentもわずか2ヶ月遅れの段階である。能力開発を一方的に一時停止することは、AIの主導権を中国に譲り渡し、それと共に未来の支配権をも手渡すことになりかねない。
    </p>
  </body>
</html>
