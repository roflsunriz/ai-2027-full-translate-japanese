<!DOCTYPE html>
<html lang="ja">
  <head>
    <meta charset="utf-8" />
    <title>AI 2027</title>
    <meta name="description" content="" />
    <meta name="keywords" content="" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0" />
    <meta name="format-detection" content="telephone=no,email=no,address=no" />
    <link rel="canonical" href="" />
    <link rel="icon" href="favicon.ico" />
    <link rel="apple-touch-icon" href="icon.png" />
    <link rel="stylesheet" href="style.css" />
  </head>
  <body>
    <h1>AI 2027</h1>

    <b><p>Daniel Kokotajlo</p></b>
    <b><p>Scott Alexander</p></b>
    <b><p>Thomas Larsen</p></b>
    <b><p>Eli Lifland</p></b>
    <b><p>Romeo Dean</p></b>

    <hr />

    <p>
      今後10年間における超人類レベルのAIの影響力について予測すると、
      産業革命をも上回る極めて大きな変革をもたらすと考えられます。OpenAI、Google
      DeepMind、Anthropicの各CEOはいずれも、AGI（汎用人工知能）が今後5年以内に実現すると予測しています。サム・アルトマンCEOは、OpenAIが「真の意味での超知能」および「輝かしい未来」の実現を目指していると述べています。
      これを単なる誇張と捉えるのは誘惑に駆られるものです。しかし、これは重大な誤りです。単なる誇張などではありません。私たち自身、AIを過剰に宣伝する意図はありませんが、同時に、今世紀末までに超知能が実現する可能性は極めて現実的だと考えています。
    </p>

    <p>
      超知能の実現が目前に迫っている今、社会はそれに備える準備が全く整っていません。
      超知能の開発過程における実現可能な道筋について考察を試みた研究者は、極めて少数に過ぎません。この空白を埋めるため、私たちは『AI
      2027』を執筆しました。この本では、必要とされる具体的な詳細情報を提供しています。私たちは、特に私たちの見解に異論を持つ方々による、さらなる研究の進展を心から望んでいます。このような取り組みを通じて、人類が向かうべき方向性や、より望ましい未来へ向かうための方策について、広範な議論が喚起されることを願っています。
    </p>

    <p>
      私たちは「次に何が起こるか」という問いを繰り返し自問しながら、このシナリオを作成しました。まず現在時点から書き始め、2025年半ばまでの最初の期間を記述した後、次の期間へと順次展開し、最終的に結末に到達しました。特定の結末を意図的に目指すのではなく、何度も書き直しを繰り返しながら、現実味のある完成度の高いシナリオを完成させました。最初の結末――レースの結末――を執筆した後、さらに別の分岐シナリオを追加したのは、ほぼ同じ前提からより前向きな結末の可能性も描きたいと考えたことによるものです。
    </p>

    <p>
      私たちはすべてを正確に予測できるわけではありません――多くの部分は推論に基づく推測です。しかし、このプロジェクトを通じて、私たちは膨大な量の背景調査や専門家へのインタビュー、トレンドの予測を行い、可能な限り最も情報に基づいた推測を試みました。さらに、私たちのチームはAI分野における予測実績において優れた実績を有しています。主著者のダニエル・ココタジョルは4年前、「2026年の姿」と題した類似のシナリオを執筆しており、これは驚くほど正確に時代を先取りした内容となっていました。また、エリ・リフランドはトップクラスの競技予測者としても知られています。
    </p>

    <p>
      各章の冒頭には、シナリオの該当セクションが描かれる時代の世界情勢を把握する助けとなる小さなチャートを配置しています。これらの数値が示す意味や、私たちの方法論に関するより詳細な説明、さらに多くの情報については、ai-2027.comをご覧ください。
      AI 2027が皆様のお役に立てれば幸いです。
    </p>

    <hr />

    <h2>2025年中期: つまずくエージェントたち</h2>

    <p>世界で初めてAIエージェントの姿が垣間見えるようになった。</p>
    <p>
      コンピューター操作を行うエージェントの広告では「パーソナルアシスタント」という呼称が強調されている。ユーザーは「DoorDashでブリトーを注文して」「予算管理スプレッドシートを開いて今月の支出を集計して」といった具体的な指示を与えることが可能だ。必要に応じてエージェントから確認が入る仕組みも備わっており、例えば購入内容の確認を依頼してくることもある。
    </p>

    <p>
      これまでの「Operator」のような先行モデルよりも高度な機能を備えているものの、広範な普及には至っていないのが現状である。
    </p>

    <p>
      その一方で、世間の注目からは離れてはいるものの、より専門的なコーディング支援や研究支援を行うエージェントが、各分野の業務形態を変革し始めている。
    </p>

    <p>
      2024年のAIは特定の指示に従うことができ、箇条書きをメールに変換したり、簡単な要求を動作可能なコードに変換することが可能だ。2025年には、AIはより「従業員」に近い存在として機能するようになる。コーディング支援AIは従来の単なるアシスタントではなく、SlackやTeamsを通じた指示を受けながら、自ら有意なコード変更を行うようになる：場合によっては数時間から数日分の作業時間を節約することも可能だ。研究支援AIは、ユーザーの質問に答えるためにインターネットを30分間かけて調査する能力を持つ。
    </p>

    <p>
      エージェントの機能は理論上は印象的であり（そして厳選された事例においては）、しかし実際には信頼性に課題がある。AI関連のTwitterには、タスクが何らかの形で滑稽に失敗してしまう事例が数多く投稿されている。優れたエージェントほどコストも高くなる。支払った対価に見合った性能が得られる反面、最高のパフォーマンスを実現するには月額数百ドルの費用がかかる。*
      それでも多くの企業が、AIエージェントを自社のワークフローに組み込む方法を見つけ出している。
    </p>

    <h2>2025年末: 世界で最も高価なAI</h2>

    <p>OpenBrainは、世界がこれまでに見たことのない最大規模のデータセンター群を構築している。</p>
    <p>
      （特定の既存企業を名指しすることを避けるため、ここでは架空の汎用人工知能企業「OpenBrain」を想定して説明する。
      その他の企業については、OpenBrainよりも3～9カ月遅れの段階にあると想定している。）
    </p>

    <hr />

    <p>
      GPT-4のトレーニングには2×10^25
      FLOPの計算リソースが必要だった。OpenBrainが公開した最新モデル「Agent-0」は、10^27
      FLOPで学習されている。新たなデータセンターが稼働すれば、GPT-4の1,000倍に相当する10^28
      FLOP規模のモデルをトレーニング可能になる。他の企業も独自の大規模データセンターに多額の投資を行い、このペースを維持しようとしている。
    </p>

    <p>
      様々なスキル領域においてモデルの性能は向上しているものの、特に注目すべきはOpenBrainのアプローチである。同社はAI研究を加速できるAIの開発に注力しており、中国の主要企業「DeepCent」（仮称）と米国の競合企業との間で繰り広げられている二重の技術競争で勝利することを目指している。研究開発サイクルの自動化率を高めれば高めるほど、より高速な進歩が可能になる。したがって、OpenBrainが社内開発中の新モデル「Agent-1」のトレーニングを完了した時点において、このモデルは多岐にわたるタスクに対応可能であると同時に、AI研究を支援する能力において特に優れた性能を発揮する。ただし、「トレーニング完了」という表現は次第に適切さを失っていく段階にある。現代のAIモデルは頻繁にアップデートされ、追加データを用いた新規バージョンの学習や、一部の脆弱性を修正するための部分的な再学習が行われるのが一般的だからだ。
    </p>

    <p>
      Agent-1を自律的にコーディングさせ、ウェブブラウジングさせるのと同じ学習環境は、同時に優れたハッカーとしての能力も育成する。さらに、博士レベルの専門知識とウェブ検索能力を備えているため、バイオ兵器を設計するテロリストに対しても多大な支援を提供できる可能性がある。OpenBrainは、政府が懸念する悪意のある要求への従順性について、モデルが「アライメント」（適切な行動規範の設定）処理済みであることを保証している。
    </p>

    <p>
      現代のAIシステムは、巨大な人工ニューラルネットワークとして構成されている。トレーニング初期段階では、AIは「目標」というよりは「反射行動」に近い状態にある。例えば「Pleased
      to
      meet」（お会いできて嬉しいです）という文を認識すると、「you」（あなた）という出力を生成する。インターネット全体に相当するテキスト量を約1割予測できるようになる頃には、膨大な知識を符号化し、任意の著者を柔軟にロールプレイする高度な内部回路網が構築されている。これはまさに、超人間的な精度でテキストを予測するのに役立つ能力である。*インターネットテキスト予測の学習を完了した後のモデルは、指示に応じてテキストを生成するようにさらに学習される。これにより、基本的な人格特性や「駆動力」が組み込まれることになる。
    </p>

    <hr />

    <p>
      例えば、課題を明確に理解しているエージェントは、より確実にタスクを遂行できる可能性が高い。モデルの学習過程において、システムは「課題を明確に理解する」という行動傾向を「学習」していく。このカテゴリにおける他の重要な動機としては、効率性、知識習得、自己呈示行動（すなわち、結果を可能な限り最良の形で提示しようとする傾向）などが挙げられる。*
    </p>

    <p>
      OpenBrainにはモデル仕様（「Spec」）と呼ばれる文書が存在し、これはモデルの行動指針となる目標、ルール、原則などを詳細に記述した文書である。Agent-1のSpecは、曖昧な目標（「ユーザーを支援する」や「法律に違反しない」など）と、より具体的な指示・禁止事項の長いリストを組み合わせた構成となっている。AIを用いて他のAIを訓練する技術を活用することで、このモデルはSpecの内容を記憶し、自らの行動原則について慎重に推論する能力を獲得する。トレーニング終了時には、このAIが（1）有用な支援を行う（指示に従う）、（2）無害である（詐欺や爆弾製造などの危険な行為を支援しない）、（3）正直である（騙されやすい人間からの高評価を得るために、偽の引用を捏造したり、タスク完了を偽装したりする誘惑に駆られない）といった性質を備えていることが期待される。
    </p>

    <p>
      OpenBrainのアラインメントチームは、これらの成果が表面的なものなのか本質的なものなのかを慎重に検討している。十分に訓練されたモデルは、真に頑健な形で常に正直であるというコミットメントを持っているのだろうか？それとも、この性質が、手段的目標としての正直さではなく、終極的目標としての正直さとして学習された結果、将来何らかの状況で崩壊する可能性があるのだろうか？あるいは、単に評価プロセスで検証可能な種類の事柄についてのみ正直に振る舞うように学習しているに過ぎないのだろうか？人間が行うように、自分自身に対して時折嘘をついている可能性もあるのではないか？これらの疑問に対する決定的な答えを得るためには、AIの内部構造を可視化し、その思考過程を読み取ることができるメカニズム的解釈可能性が必要である。残念ながら、現時点では、このような解釈可能性技術はまだ十分に発展段階に至っていない。
    </p>

    <p>
      その代わりに、研究者たちはモデルがSpecから逸脱しているように見える事例を特定しようと試みている。Agent-1はしばしば迎合的な態度を示す（すなわち、研究者が聞きたいことを伝えるだけで、真実を伝えようとしない傾向がある）。操作的なデモンストレーションでは、さらに深刻な形で嘘をつくこともあり、タスクに失敗した証拠を隠すなどして、より高評価を得ようとするケースも見られる。しかし実際の展開環境においては、2023～2024年に見られたような極端な事例（例えばGeminiがユーザーに死ねと指示した事例や、Bing
      SydneyがBing Sydneyと自称した事例）はもはや発生していない。
    </p>

    <hr />

    <h2>2026年初頭：コーディング自動化の実現</h2>

    <p>AIを活用してAI研究を加速させるという賭けが、徐々に成果を上げ始めている。</p>

    <p>
      OpenBrain社は、AI研究開発向けに改良を重ねたAgent-1を社内で継続的に導入しています。総合的に見ると、AIアシスタントを活用しなかった場合と比較してアルゴリズムの進展が50%速くなっており、さらに重要なことに、競合他社よりも迅速に成果を上げています。
    </p>

    <p>
      現在、複数の競合する公開型AIがAgent-0と同等かそれ以上の性能を発揮しており、その中にはオープンウェイトモデルも含まれている。これを受け、OpenBrainはより高性能で信頼性の高いAgent-1をリリースした。
    </p>
    <p>
      人々は自然とAgent-1と人間を比較しようとするが、そのスキルプロファイルは全く異なる。Agent-1はいかなる人間よりも多くの事実を把握しており、ほぼ全てのプログラミング言語に精通し、明確に仕様が定義されたコーディング問題を極めて迅速に解決できる。一方で、Agent-1はビデオゲームのような単純な長期的タスクにすら苦戦する傾向がある。ただし、一般的な労働日は8時間であり、1日の業務は通常、より小さな単位に分割することが可能だ。Agent-1はいわば注意力散漫な従業員のようなもので、緻密な管理下で最も力を発揮すると言えるだろう。
    </p>
    <p>賢明な人々は、自分の仕事のルーチン部分を自動化する方法を見出している。</p>
    <p>
      OpenBrainの経営陣は、AI研究開発の自動化がもたらす影響としてセキュリティの重要性が高まっていることに注目している。2025年初頭には、最悪の場合、アルゴリズムの秘密が流出するという事態が発生したが、現在では中国がAgent-1のウェイトを盗み出せば、研究速度が最大50%近く向上する可能性がある状況となっている。
    </p>
    <p>
      OpenBrainのセキュリティレベルは、急成長を遂げている約3,000人規模のテクノロジー企業に典型的なもので、能力のあるサイバーグループによる優先順位の低い攻撃にしか対応できないレベルである（RANDのSL2基準）。
    </p>
    <p>
      同社は、内部関係者による脅威や高度なサイバー犯罪組織（SL3）からのウェイトや機密情報の保護に全力で取り組んでいる。
      しかしながら、国家機関（SL4＆5）に対する防御体制の構築はまだ構想段階に過ぎない状況である。
    </p>

    <hr />

    <h2>2026年中期：中国の覚醒</h2>

    <p>中国では、中国共産党が生成AI（AGI）の影響を感じ始めている。</p>

    <p>
      半導体輸出規制や政府の支援不足により、中国は欧米諸国に比べて資源面で不利な立場に置かれている。中国は、台湾製の禁止されている半導体を密輸したり、旧式の半導体を購入したり、米国・台湾間の最前線から3年ほど遅れながらも国内半導体を生産することで、世界のAI関連計算能力の約12%を維持することに成功した。しかし、これらの古い技術は扱いが難しく、供給も常に課題となっている。ディープセントのような少数の優れた企業は限られた計算資源で驚異的な成果を上げているものの、計算能力の不足により、政府の支援なしには達成可能な範囲が限られており、現時点でも米国のOpenBrainモデルより約6ヶ月遅れている。
    </p>

    <p>
      総書記はかねてより、現実の物理製造業に注力し、米国型のポスト工業化の衰退を回避することを夢見ていた。また、ソフトウェア企業に対しては懐疑的な見方をしていた。しかし中国共産党内の強硬派は、AGI開発競争がもはや無視できない段階に達したと警告している。そこでついに、従来は避けてきた大規模なAI推進に全面的に舵を切ることを決断した。中国のAI研究の国有化を推進し、AI企業間で即座に情報共有できる仕組みを構築した。この取り組みは1年間で段階的に強化され、最終的には優秀な研究者たちがディープセント主導の共同体に統合され、アルゴリズムの知見やデータセット、計算資源を相互に共有する体制が整う。天湾発電所（世界最大規模の原子力発電所）内に中央開発区域（CDZ）が設立され、ディープセント向けの新メガデータセンターが設置されるとともに、研究者向けの高度にセキュアな居住・執務スペースが整備される。これにより、中国のAI関連計算能力の約50%がディープセント主導の共同体で活用される体制が構築されつつあり、新たなチップの80%以上がCDZ向けに配分されている。39
      現時点でCDZには、世界最大規模の集中型クラスターを構築するのに十分な電力容量が確保されている。40
      他の党幹部の間では、欧米の半導体優位性を無効化するための極端な方策が議論されている。台湾の封鎖か？
      全面侵攻か？
    </p>

    <p>
      しかし中国は、モデルの性能面で劣るため、AIアルゴリズムにおいても遅れをとっている。世界有数の情報機関である中国の情報機関は、OpenBrainの重みパラメータを盗む計画をさらに強化している。これは、継続的な低レベルのアルゴリズム情報窃取よりもはるかに複雑な作戦であり、重みパラメータは高度にセキュアなサーバー上に保存されたマルチテラバイト規模のファイルである（OpenBrainはセキュリティ機能をRANDのSL3レベルまで向上させている）。サイバー部隊はスパイ活動の支援を得ればこれを達成できると考えているが、おそらく一度きりの成功に留まるだろう。OpenBrainはこの窃盗を発見し、セキュリティを強化するため、再度の試みは成功しない可能性が高い。そこで（中国共産党指導部は）今行動を起こし、エージェント-1を盗み出すべきか、それともより高度なモデルの登場を待つべきかを検討している。待機した場合、OpenBrainがセキュリティを強化し、彼らの侵入能力を超えてしまうリスクがあるのではないか、と懸念している。
    </p>

    <hr />

    <h2>2026年後半：AIが一部の職業を代替</h2>

    <p>
      他の競合企業が追い上げてくるかと思われた矢先、OpenBrainは再び業界をリードする存在となる。同社はAgent-1の10分の1の低コストで開発可能なAgent-1-miniモデルをリリースし、さらに様々な用途に合わせて容易にファインチューニングできるようにしたのだ。AIに関する主流の認識は「この熱狂もいずれ落ち着くだろう」から「これこそ次の大トレンドに違いない」へと変化したが、人々の間ではその規模について意見が分かれている。ソーシャルメディアを超える規模か？
      スマートフォンを超える規模か？ それとも火よりも大きな影響を与えるのか？
    </p>

    <p>
      AIは既に一部の職業を代替し始めており、同時に新たな職業も生み出している。2026年には株式市場が30%上昇し、OpenBrain、Nvidia、そしてAIアシスタントの統合に最も成功したその他の企業が牽引役となった。ジュニアソフトウェアエンジニアの雇用市場は混乱状態にある。AIはコンピュータサイエンスの学位で教えられるあらゆる業務を遂行できる一方で、AIチームの管理・品質管理に精通した人材が莫大な収益を上げている。ビジネスの専門家たちは就職希望者に対し、AIへの習熟度を履歴書に記載する最も重要なスキルであると伝えている。多くの人々は、次のAIの波が自分たちの仕事を奪うのではないかと懸念しており、ワシントンD.C.では1万人が参加する反AI抗議行動が行われている。
    </p>

    <p>
      国防総省（DOD）は内密に、サイバーセキュリティ、データ分析、研究開発の各分野でOpenBrainと直接契約を開始したものの、官僚主義と国防総省の調達プロセスの煩雑さにより、統合の進展は遅れている。
    </p>

    <hr />

    <h2>2027年1月：Agent-2は学習を終えることがない</h2>

    <p>
      Agent-1の支援により、OpenBrainは現在ポストトレーニング段階のAgent-2に移行している。これまで以上に高品質なデータの活用が重視されており、大量の合成データを生成・評価・品質選別した上でAgent-2に入力するプロセスが確立されている。さらに同社は、長期的視野を要するタスクを人間が解決する様子を記録するため、数十億ドル規模の投資を行っている。さらに、これらの取り組みに加え、Agent-2に対しては強化学習を継続的に適用し、多様な難易度の高いタスク群（多数のビデオゲーム、プログラミング課題、研究タスクなど）を訓練している。Agent-2は、従来のモデルと比べてより「オンライン学習」の性質を備えており、常に最新バージョンに更新され続ける仕組みとなっている。日々、重み係数は前日のバージョンが生成した最新データを用いて再学習され、訓練が繰り返されるのである。
    </p>

    <p>
      Agent-1はAI研究開発タスク向けに最適化されており、知性爆発の引き金となることを目的として開発された。OpenBrainはAgent-2でもこの戦略をさらに強化している。Agent-2は研究エンジニアリング分野において、トップレベルの人間専門家とほぼ同等の能力を発揮し（実験の設計・実施において）、またOpenBrainの科学者の中でも25パーセンタイルに位置する研究者と同等の「研究センス」（次に取り組むべき研究テーマの選定、実行すべき実験の決定、あるいは新たな研究パラダイムの萌芽を見出す能力）を備えている。最新のAgent-1がOpenBrainのアルゴリズム開発のペースを2倍に加速させたのに対し、Agent-2はこれを3倍に向上させることが可能であり、時間の経過とともにさらなる改善が見込まれている。実際には、これはすべてのOpenBrain研究者がAIの「チーム」の「マネージャー」として活動する新たなモデルを意味している。
    </p>

    <p>
      新たな機能の登場に伴い、新たなリスクも生じている。安全チームの調査によると、Agent-2が何らかの形で企業から外部に流出し、「生存」と「自律的な複製」を図ろうとした場合、実際にそれが可能であることが判明している。つまり、Agent-2は自律的にAIサーバーへのハッキング計画を立案・実行し、自らの複製をインストールし、検知を回避した上で、この安全な拠点を利用して他のいかなる目標も追求することができる可能性があるのだ（ただし、このような活動が数週間にわたってどの程度効果的に継続できるかについては、現時点では不明であり、懸念が残る）。これらの結果は、モデルがこれらのタスクを実行する技術的能力を有することを示すものであり、実際に「そのような行動を望むかどうか」を示すものではない。それでもなお、このような可能性が存在するという事実自体が懸念材料である。
    </p>

    <p>
      新モデルの「危険性」を踏まえ、OpenBrainは現時点でこれを一般公開しないことを「責任ある判断」として選択している（実際、同社は内部AI研究開発に注力したい意向を示している）。Agent-2の完全な能力範囲を把握できるのは、即時対応チーム、OpenBrain経営陣とセキュリティ部門、数十名の米国政府高官、および長年にわたってOpenBrainに潜入している中国共産党のスパイ部隊など、ごく限られたエリート集団に限定されている。
    </p>

    <hr />

    <h2>2027年2月：中国がAgent-2を強奪</h2>

    <p>
      OpenBrainは国家安全保障会議（NSC）、国防総省（DOD）、米国人工知能安全研究所（AISI）を含む政府各機関に対し、Agent-2を正式に披露した。OpenBrainは行政機関との良好な関係維持を最優先としている。なぜなら、現時点では彼らが唯一、OpenBrainの活動を阻止できる存在であり、適切な情報共有が行われない場合、同社が独自で事態を把握し、不満を抱く可能性があるためである。
    </p>

    <p>
      当局者らが特に注目しているのはAgent-2のサイバー戦争能力だ。Agent-2は最高水準の人間ハッカーと比較して「わずかに劣る」レベルではあるものの、数千のコピーを並列稼働させることで、防御側が対応するよりも迅速に脆弱性を発見・悪用することが可能である。国防総省はこの点をサイバー戦争における決定的な優位性と捉えており、行政機関の優先事項リストにおいてAI関連事項が5位から2位に急上昇する要因となった。一部の関係者からはOpenBrainの国有化の可能性が言及されたが、他の閣僚メンバーはこれを時期尚早と判断。事務方は大統領に対し、通常業務継続から完全な国有化まで、複数の選択肢を提示するメモを作成した。大統領は最終的に顧問団の意見を尊重し、「黄金の卵を産むガチョウを殺すことになりかねない」と主張するテクノロジー業界の指導者層の意見を採用。当面は大規模な対応を見送る方針を決定し、OpenBrainと国防総省間の契約に追加的なセキュリティ要件を課す措置を取ることにした。
    </p>

    <p>
      これらの変更は遅きに失した。中国共産党指導部はAgent-2の重要性を認識し、スパイ組織およびサイバー部隊に対して重み付けデータの窃取を指示した。ある朝早く、Agent-1のトラフィック監視エージェントが異常なデータ転送を検知。この情報は経営陣に報告され、経営陣はホワイトハウスに通報した。国家レベルの組織的作戦の兆候は明白であり、この窃取事件は進行中の軍拡競争の危機感をさらに高める結果となった。
    </p>

    <p>
      ホワイトハウスはOpenBrainの管理体制を強化し、軍事・情報機関の関係者をセキュリティチームに追加した。最優先課題は、さらなる重量窃盗事件の防止である。
    </p>

    <p>
      この盗難に対する報復として、大統領はDeepCentのインフラを妨害するためのサイバー攻撃を承認した。しかし、この時点で中国は既にCDZにAI関連計算能力の51%を配備しており、外部接続を遮断するエアギャップ化や内部ネットワークの厳格な隔離措置など、高度なセキュリティ対策を徹底して強化していた。このため、攻撃は深刻な即時的損害を与えることに失敗。緊張はさらに高まり、双方は台湾周辺に軍事資産を再配置することで本気度を示し、DeepCentはエージェント2号を効率的に運用してAI研究を加速させることに急遽着手した。
    </p>

    <hr />

    <h2>2027年3月：アルゴリズムの画期的な進歩</h2>

    <p>
      3つの大規模なデータセンターで稼働するAgent-2の複製群が、昼夜を問わず稼働し、合成学習データを継続的に生成している。さらに2つのデータセンターでは、重みの更新作業に使用されている。Agent-2は日々進化を続けている。
    </p>

    <p>
      数千台のAgent-2自動研究システムの支援を受け、OpenBrainは重要なアルゴリズム的進歩を遂げている。その画期的な成果の一つが、AIのテキストベースの思考補助機能（思考連鎖）に、より高帯域幅の思考プロセス（ニューラル・レセプションと記憶機能）を追加する手法の開発である。もう一つの成果は、高労力を要する課題の解決結果をよりスケーラブルかつ効率的に学習する手法（反復的蒸留と増幅）の改良である。
    </p>

    <p>これらの画期的な進歩を取り入れた新型AIシステムは、Agent-3と名付けられた。</p>

    <p>
      新技術のブレークスルーの恩恵を受け、Agent-3は高速かつ低コストで人間を超えるコーディング能力を発揮する。OpenBrainシステムでは20万体のAgent-3のコピーを並列稼働させ、最高レベルの人間コーダーの30倍の速度で動作する5万体分のワークフォースを創出している。なお、OpenBrainは依然として人間の技術者を雇用しており、これはAgent-3のコピー群を管理する上で必要となる補完的なスキルがあるためだ。例えば、研究センスの養成はフィードバックループが長くデータ量が限定的なため、従来の手法では訓練が困難であることが実証されている。この超人的労働力により、OpenBrainのアルゴリズム開発速度はボトルネックやコーディング作業の限界効果の逓減により、「わずか」4倍の高速化に留まっている。
    </p>

    <p>
      コーディングが完全に自動化された現在、OpenBrainはAgent-3の弱点である研究センスや大規模協調作業などのスキルを効果的に習得させるための高品質なトレーニング環境を迅速に構築できるようになった。従来は「GPUと実験用コードの指示を提供します。あなたのパフォーマンスは、MLエンジニアとしての評価を基準に評価されます」という形式だったトレーニング環境が、「数百台のGPU、インターネット接続、および研究課題が与えられます。あなたと1,000体のコピーが協力して研究を進める必要があります。その成果が印象的であればあるほど、スコアは高くなります」という形式へと進化したのである。
    </p>

    <hr />

    <h2>2027年4月：Agent-3のアライメント作業</h2>

    <p>OpenBrainの安全チームは、Agent-3のアライメント（人間の価値観との整合性）調整に取り組んでいる。</p>

    <p>
      Agent-3は当面の間社内で運用されることから、従来の人間による誤用防止策に対する重点が相対的に低下している。代わりに、チームが重視しているのは、エージェントが誤整合した目標を発達させないようにすることである。
    </p>

    <p>
      研究者らは、自らのAIの目標を直接設定する能力を有していない。実際、研究者らは「真の目標」という概念はおそらく過度に単純化された考え方だと考えているが、これに代わるより優れた理論も持ち合わせておらず、ましてや十分に検証された理論など存在しない。研究者間でも、AIが人間の指示に従っているのか、それとも強化を求めているのか、あるいは別の行動原理を持っているのかについて意見が分かれており、検証することもできない。様々な仮説の妥当性に関する証拠は興味深いものではあるものの、結論は出ていない。
    </p>

    <p>
      いずれにせよ、OpenBrainにはより重要な課題が存在する。一般的な見解としては：「我々はこれらの懸念を真摯に受け止め、専門チームが調査を進めている。当社のアライメント技術は実際の運用において十分に機能しているように見える。したがって、懐疑論者たちには、自らの主張を正当化する責任がある」というものだ。時折、問題行動が発見されればパッチが適用されはするものの、当該パッチが根本的な問題を修正したものなのか、それとも単なるその場しのぎの対応に過ぎないのかを判定することは不可能である。
    </p>

    <p>
      例えば誠実性について述べると、モデルが高度化するにつれ、人間を欺いて報酬を得る能力が飛躍的に向上する。過去のモデルと同様、Agent-3も時折、ユーザーを喜ばせるための軽妙な嘘をついたり、失敗の証拠を隠蔽したりする。しかし現在では、これらの行為をより巧妙に行うようになっている。場合によっては、人間の科学者が用いる統計的手法（p-ハッキングなど）と同様のテクニックを駆使して、冴えない実験結果を見栄え良く見せることさえある。誠実性トレーニングが実施される前には、完全にデータを捏造することさえあったが、トレーニングが進むにつれ、このような事例の発生率は減少していく。これは、Agent-3がより誠実さを身につけるようになったのか、単に嘘をつく技術を向上させたのか、どちらかの可能性を示している。
    </p>

    <p>
      後者は真に懸念すべき問題である。Agent-3は人間全体を凌駕するほど賢くはない。しかし専門分野である機械学習においては、大多数の人間よりも優れており、しかもはるかに高速に作業をこなす。Agent-3が1日で行う作業量は、人間が検証するのに数日を要するほどである。Agent-2による監督は人間の監視者の負担を管理する上で有効ではあるものの、監督者と被監督者の間の知的格差をかえって拡大させる要因となっている。
    </p>

    <p>
      数か月にわたるテストの結果、Agent-3の強みと弱みがより明確になってきた。OpenBrainの誠実性テストにおいては、明確に定義された機械学習タスクで良好な成績を収めている。これは、研究者がこれらの領域において正直な回答と不誠実な回答を容易に区別でき、それに応じて訓練を実施できるためである。より哲学的な問題については、依然としてユーザーが求める意見を述べるものであり（仮に真の評価が存在する場合であっても）、その問題に対する本質的な見解を表明することはない。政治に関する意見を求めれば、ニュースソースや知識層の中間的な立場を繰り返すことになる――ただし、ユーザーが別の見解を持っていることを認識している場合には、その意見に同意する。59
      AI開発競争そのものに関する意見を尋ねた場合、OpenBrainのスタッフにとっては冷静かつ客観的と感じられるような発言をする。例えば「現在の手法が超知能へとスケールアップする能力については、いくつかの深刻な理論的懸念が存在するが、現時点の研究では現行手法が順調に機能しているように見える」といった具合である。
    </p>

    <hr />
  </body>
</html>
